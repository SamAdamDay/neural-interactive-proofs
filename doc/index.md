# Neural Interactive Proofs

*By Lewis Hammond and Sam Adam-Day*

We consider the problem of how a trusted, but computationally bounded agent (a 'verifier') can learn to interact with one or more powerful but untrusted agents ('provers') in order to solve a given task. More specifically, we study the case in which agents are represented using neural networks and refer to solutions of this problem as neural interactive proofs. First we introduce a unifying framework based on prover-verifier games, which generalises previously proposed interaction protocols. We then describe several new protocols for generating neural interactive proofs, and provide a theoretical comparison of both new and existing approaches. Finally, we support this theory with experiments in two domains: a toy graph isomorphism problem that illustrates the key ideas, and a code validation task using large language models. In so doing, we aim to create a foundation for future work on neural interactive proofs and their application in building safer AI systems.

<div markdown="1" class="links">

[arXiv](https://arxiv.org/abs/2412.08897) |
[OpenReview](https://openreview.net/forum?id=R2834dhBlo) |
[GitHub](https://github.com/SamAdamDay/neural-interactive-proofs) |
[Documentation](https://neural-interactive-proofs.com/docs)

</div>

```bibtex
@inproceedings{neural_interactive_proofs,
    author = {Lewis Hammond and Sam Adam-Day},
    title = {Neural Interactive Proofs},
    booktitle = {The Thirteenth International Conference on Learning Representations (ICLR)},
    year = {2025},
    eprint={2412.08897},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
}
```

