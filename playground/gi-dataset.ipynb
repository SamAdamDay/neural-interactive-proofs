{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the graph isomorphism dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from hashlib import blake2b\n",
    "\n",
    "import networkx as nx\n",
    "from networkx import weisfeiler_lehman_graph_hash, erdos_renyi_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WL score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/networkx/networkx/blob/main/networkx/algorithms/graph_hashing.py\n",
    "\n",
    "def hash_label(label, digest_size):\n",
    "    return blake2b(label.encode(\"ascii\"), digest_size=digest_size).hexdigest()\n",
    "\n",
    "\n",
    "def init_node_labels(G):\n",
    "    return {u: str(deg) for u, deg in G.degree()}\n",
    "\n",
    "\n",
    "def neighborhood_aggregate(G, node, node_labels):\n",
    "    \"\"\"\n",
    "    Compute new labels for given node by aggregating\n",
    "    the labels of each node's neighbors.\n",
    "    \"\"\"\n",
    "    label_list = []\n",
    "    for nbr in G.neighbors(node):\n",
    "        label_list.append(node_labels[nbr])\n",
    "    return node_labels[node] + \"\".join(sorted(label_list))\n",
    "\n",
    "\n",
    "def weisfeiler_lehman_graph_score(\n",
    "    G_1, G_2, max_iterations=5, digest_size=16\n",
    "):\n",
    "    \n",
    "    if G_1.number_of_nodes() != G_2.number_of_nodes():\n",
    "        return 0\n",
    "\n",
    "    def weisfeiler_lehman_step(G, labels, edge_attr=None):\n",
    "        \"\"\"\n",
    "        Apply neighborhood aggregation to each node\n",
    "        in the graph.\n",
    "        Computes a dictionary with labels for each node.\n",
    "        \"\"\"\n",
    "        new_labels = {}\n",
    "        for node in G.nodes():\n",
    "            label = neighborhood_aggregate(G, node, labels, edge_attr=edge_attr)\n",
    "            new_labels[node] = hash_label(label, digest_size)\n",
    "        return new_labels\n",
    "    \n",
    "    G = [G_1, G_2]\n",
    "\n",
    "    # set initial node labels\n",
    "    node_labels = [init_node_labels(G[i]) for i in range(2)]\n",
    "\n",
    "    subgraph_hash_counts = [[] for _ in range(2)]\n",
    "    for iteration in range(max_iterations):\n",
    "        graph_hash = [[] for _ in range(2)]]\n",
    "        for i in range(2):\n",
    "            node_labels[i] = weisfeiler_lehman_step(G[i], node_labels[i])\n",
    "            counter = Counter(node_labels[i].values())\n",
    "            subgraph_hash_counts[i].extend(sorted(counter.items(), key=lambda x: x[0]))\n",
    "            graph_hash[i] = hash_label(str(tuple(subgraph_hash_counts[i])), digest_size)\n",
    "        if graph_hash[0] != graph_hash[1]:\n",
    "            return iteration + 1\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvg-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
