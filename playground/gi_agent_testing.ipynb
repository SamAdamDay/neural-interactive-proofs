{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing power of agent architectures for graph isomorphism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_CPU = True\n",
    "\n",
    "DATASET_NAME = \"test\"\n",
    "\n",
    "D_DECIDER = 16\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.data import Batch as GeometricBatch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "from jaxtyping import Float\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pvg.scenarios import GraphIsomorphismAgent\n",
    "from pvg.data import GraphIsomorphismDataset, GraphIsomorphismData\n",
    "from pvg.parameters import Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters(\n",
    "    scenario=\"graph_isomorphism\",\n",
    "    trainer=\"test\",\n",
    "    dataset=DATASET_NAME,\n",
    "    max_message_rounds=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if not FORCE_CPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreToBitTransform(BaseTransform):\n",
    "    \"\"\"A transform that converts the score to a bit indicating isomorphism.\"\"\"\n",
    "    def __call__(self, data):\n",
    "        for store in data.node_stores:\n",
    "            store.y = (store.wl_score == -1).long()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphIsomorphismDataset(name='test', num_features=1, num_pairs=100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = GraphIsomorphismDataset(params, transform=ScoreToBitTransform())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismSoloAgent(GraphIsomorphismAgent, ABC):\n",
    "    def _build_model(self, num_layers: int, d_gnn: int, num_heads: int) -> nn.Module:\n",
    "        # Build up the GNN and attention modules\n",
    "        self.gnn, self.attention = self._build_gnn_and_attention(\n",
    "            d_input=1,\n",
    "            d_gnn=d_gnn,\n",
    "            num_layers=num_layers,\n",
    "            num_heads=num_heads,\n",
    "        )\n",
    "\n",
    "        # Build the decider, which decides whether the graphs are isomorphic\n",
    "        self.decider = self._build_decider(\n",
    "            d_gnn=d_gnn,\n",
    "            d_decider=D_DECIDER,\n",
    "            d_out=2,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, data: GraphIsomorphismData | GeometricBatch\n",
    "    ) -> Float[Tensor, \"batch_size 2\"]:\n",
    "        _, attention_output, _ = self._run_gnn_and_attention(data)\n",
    "        decider_logits = self.decider(attention_output)\n",
    "        return decider_logits\n",
    "    \n",
    "    def to(self, device: str | torch.device):\n",
    "        self.gnn.to(device)\n",
    "        self.attention.to(device)\n",
    "        self.decider.to(device)\n",
    "        return self\n",
    "\n",
    "\n",
    "class GraphIsomorphismSoloProver(GraphIsomorphismSoloAgent):\n",
    "    def __init__(self, params: Parameters, device: str | torch.device):\n",
    "        super().__init__(params, device)\n",
    "        self._build_model(\n",
    "            num_layers=params.graph_isomorphism.prover_num_layers,\n",
    "            d_gnn=params.graph_isomorphism.prover_d_gnn,\n",
    "            num_heads=params.graph_isomorphism.prover_num_heads,\n",
    "        )\n",
    "\n",
    "\n",
    "class GraphIsomorphismSoloVerifier(GraphIsomorphismSoloAgent):\n",
    "    def __init__(self, params: Parameters, device: str | torch.device):\n",
    "        super().__init__(params, device)\n",
    "        self._build_model(\n",
    "            num_layers=params.graph_isomorphism.verifier_num_layers,\n",
    "            d_gnn=params.graph_isomorphism.verifier_d_gnn,\n",
    "            num_heads=params.graph_isomorphism.verifier_num_heads,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphIsomorphismSoloProver(\n",
       "  (gnn): Sequential(\n",
       "    (0): Linear(1, 64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): GCNConv(64, 64)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): GCNConv(64, 64)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): GCNConv(64, 64)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): GCNConv(64, 64)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): GCNConv(64, 64)\n",
       "  )\n",
       "  (attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (decider): Sequential(\n",
       "    (0): ReLU(inplace=True)\n",
       "    (1): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): GlobalMaxPool()\n",
       "    (4): Linear(in_features=16, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prover = GraphIsomorphismSoloProver(params, device)\n",
    "prover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphIsomorphismSoloVerifier(\n",
       "  (gnn): Sequential(\n",
       "    (0): Linear(1, 64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): GCNConv(64, 64)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): GCNConv(64, 64)\n",
       "  )\n",
       "  (attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (decider): Sequential(\n",
       "    (0): ReLU(inplace=True)\n",
       "    (1): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): GlobalMaxPool()\n",
       "    (4): Linear(in_features=16, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier = GraphIsomorphismSoloVerifier(params, device)\n",
    "verifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 29.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prover: loss: 0.6933, accuracy: 0.5000\n",
      "Verifier: loss: 0.6931, accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 24.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prover: loss: 0.6932, accuracy: 0.5000\n",
      "Verifier: loss: 0.6931, accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 748 is out of bounds for dimension 0 with size 748",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sam/Code/Projects/PVG Experiments/playground/gi_agent_testing.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(loader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     loss, accuracy \u001b[39m=\u001b[39m train_step(prover, optimizer_prover, data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     total_loss_prover \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     total_accuracy_prover \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m accuracy\n",
      "\u001b[1;32m/home/sam/Code/Projects/PVG Experiments/playground/gi_agent_testing.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m pred \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(pred, data\u001b[39m.\u001b[39my)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/sam/Code/Projects/PVG Experiments/playground/gi_agent_testing.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mself\u001b[39m, data: GraphIsomorphismData \u001b[39m|\u001b[39m GeometricBatch\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Float[Tensor, \u001b[39m\"\u001b[39m\u001b[39mbatch_size 2\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     _, attention_output, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_gnn_and_attention(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     decider_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecider(attention_output)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_agent_testing.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m decider_logits\n",
      "File \u001b[0;32m~/Code/Projects/PVG Experiments/pvg/scenarios/graph_isomorphism.py:232\u001b[0m, in \u001b[0;36mGraphIsomorphismAgent._run_gnn_and_attention\u001b[0;34m(self, data, gnn, attention)\u001b[0m\n\u001b[1;32m    228\u001b[0m     attention \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention\n\u001b[1;32m    230\u001b[0m \u001b[39m# Run the GNN on the two graphs\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# (total_num_nodes, d_gnn)\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m gnn_output_a \u001b[39m=\u001b[39m gnn(x\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mx_a, edge_index\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49medge_index_a)\n\u001b[1;32m    233\u001b[0m gnn_output_b \u001b[39m=\u001b[39m gnn(x\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mx_b, edge_index\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39medge_index_b)\n\u001b[1;32m    235\u001b[0m \u001b[39m# Convert from a sparse to a dense representation\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m# (batch_size, max_nodes, d_gnn), (batch_size, max_nodes)\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tmp/sam_pyg/tmprr1ug133.py:20\u001b[0m, in \u001b[0;36mSequential_7477c3.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     18\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput(x)\n\u001b[1;32m     19\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mReLU_0(x)\n\u001b[0;32m---> 20\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mGNN_layer_0(x, edge_index)\n\u001b[1;32m     21\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mReLU_1(x)\n\u001b[1;32m     22\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGNN_layer_1(x, edge_index)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:210\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    208\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m gcn_norm(  \u001b[39m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    211\u001b[0m         edge_index, edge_weight, x\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim),\n\u001b[1;32m    212\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimproved, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_self_loops, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflow, x\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    213\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached:\n\u001b[1;32m    214\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index \u001b[39m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:100\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m row, col \u001b[39m=\u001b[39m edge_index[\u001b[39m0\u001b[39m], edge_index[\u001b[39m1\u001b[39m]\n\u001b[1;32m     99\u001b[0m idx \u001b[39m=\u001b[39m col \u001b[39mif\u001b[39;00m flow \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msource_to_target\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m row\n\u001b[0;32m--> 100\u001b[0m deg \u001b[39m=\u001b[39m scatter(edge_weight, idx, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, dim_size\u001b[39m=\u001b[39;49mnum_nodes, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    101\u001b[0m deg_inv_sqrt \u001b[39m=\u001b[39m deg\u001b[39m.\u001b[39mpow_(\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m    102\u001b[0m deg_inv_sqrt\u001b[39m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[39m==\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:74\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mnew_zeros(size)\u001b[39m.\u001b[39;49mscatter_add_(dim, index, src)\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     77\u001b[0m     count \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index 748 is out of bounds for dimension 0 with size 748"
     ]
    }
   ],
   "source": [
    "optimizer_prover = torch.optim.Adam(prover.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_verifier = torch.optim.Adam(verifier.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, shuffle=True, follow_batch=[\"x_a\", \"x_b\"]\n",
    ")\n",
    "\n",
    "\n",
    "def train_step(\n",
    "    model: GraphIsomorphismSoloAgent, optimizer, data: GraphIsomorphismData\n",
    ") -> tuple[float, float]:\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(data)\n",
    "    loss = F.cross_entropy(pred, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        accuracy = (pred.argmax(dim=1) == data.y).float().mean().item()\n",
    "    return loss.item(), accuracy\n",
    "\n",
    "\n",
    "losses_prover = np.empty(NUM_EPOCHS)\n",
    "accuracies_prover = np.empty(NUM_EPOCHS)\n",
    "losses_verifier = np.empty(NUM_EPOCHS)\n",
    "accuracies_verifier = np.empty(NUM_EPOCHS)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss_prover = 0\n",
    "    total_accuracy_prover = 0\n",
    "    total_loss_verifier = 0\n",
    "    total_accuracy_verifier = 0\n",
    "    for data in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        data = data.to(device)\n",
    "        loss, accuracy = train_step(prover, optimizer_prover, data)\n",
    "        total_loss_prover += loss\n",
    "        total_accuracy_prover += accuracy\n",
    "        loss, accuracy = train_step(verifier, optimizer_verifier, data)\n",
    "        total_loss_verifier += loss\n",
    "        total_accuracy_verifier += accuracy\n",
    "    losses_prover[epoch] = total_loss_prover / len(loader)\n",
    "    accuracies_prover[epoch] = total_accuracy_prover / len(loader)\n",
    "    losses_verifier[epoch] = total_loss_verifier / len(loader)\n",
    "    accuracies_verifier[epoch] = total_accuracy_verifier / len(loader)\n",
    "    print(\n",
    "        f\"Prover: loss: {losses_prover[epoch]:.4f}, \"\n",
    "        f\"accuracy: {accuracies_prover[epoch]:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Verifier: loss: {losses_verifier[epoch]:.4f}, \"\n",
    "        f\"accuracy: {accuracies_verifier[epoch]:.4f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvg-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
