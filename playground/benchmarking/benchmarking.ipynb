{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPS Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/b7/bmb40vfx77s4c8dykfmd1rh40000gn/T/ipykernel_78702/40365185.py\", line 2, in <module>\n",
      "    from evaluate import load\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/evaluate/__init__.py\", line 29, in <module>\n",
      "    from .evaluation_suite import EvaluationSuite\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/evaluate/evaluation_suite/__init__.py\", line 10, in <module>\n",
      "    from ..evaluator import evaluator\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/evaluate/evaluator/__init__.py\", line 17, in <module>\n",
      "    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/transformers/utils/__init__.py\", line 34, in <module>\n",
      "    from .generic import (\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/transformers/utils/generic.py\", line 462, in <module>\n",
      "    import torch.utils._pytree as _torch_pytree\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/lewishammond/Repositories/code/nip/playground/benchmarking/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "Downloading builder script: 100%|██████████| 3.04k/3.04k [00:00<00:00, 2.97MB/s]\n",
      "Downloading extra modules: 100%|██████████| 9.29k/9.29k [00:00<00:00, 7.53MB/s]\n",
      "Downloading extra modules: 100%|██████████| 20.3k/20.3k [00:00<00:00, 338kB/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "# This seems to do something weirdly inefficient\n",
    "# datasets = {x: load_dataset(\"codeparrot/apps\", trust_remote_code=True, split=\"test\", difficulties=[x]) for x in [\"introductory\", \"interview\", \"competition\"]}\n",
    "\n",
    "def get_dataset(difficulty):\n",
    "    return load_dataset(\"codeparrot/apps\", trust_remote_code=True, split=\"test\", difficulties=[difficulty])\n",
    "\n",
    "metric = load('codeparrot/apps_metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "OPENROUTER_API_KEY = \"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\"\n",
    "\n",
    "MODELS = [\"openai/gpt-4o-mini\",\n",
    "          \"meta-llama/llama-3.1-8b-instruct\", \n",
    "          \"deepseek/deepseek-coder\",\n",
    "          \"mistralai/codestral-mamba\"]\n",
    "\n",
    "def get_responses(model, messages):\n",
    "    \"\"\"\n",
    "    Sends a POST request to the OpenRouter API to get responses from a chat model.\n",
    "\n",
    "    Parameters:\n",
    "    - model (str): The name of the chat model to use.\n",
    "    - messages (list): A list of dictionaries representing the chat messages. Each dictionary should have a \"role\" key with the value \"user\" or \"assistant\", and a \"content\" key with the content of the message.\n",
    "\n",
    "    Returns:\n",
    "    - response (Response): The response object returned by the API.\n",
    "\n",
    "    Raises:\n",
    "    - requests.exceptions.RequestException: If there was an error sending the request.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(\n",
    "    url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "    headers={ \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\"},\n",
    "    data=json.dumps({\"model\": model, \"messages\": messages}))\n",
    "\n",
    "    return response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers(answers, model, difficulty):\n",
    "    \n",
    "    model_name = model.split('/')[-1]\n",
    "    file_path = f\"apps/generations/{model_name}_{difficulty}.json\"\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(answers, f, indent=4)\n",
    "\n",
    "def save_results(results):\n",
    "    \n",
    "    with open(\"apps/results.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"Answer the following question by writing a function in Python (you do not need to include `python` anywhere and you do not need to call the function). Do NOT include any explanation or natural language text, ONLY the code. Your code should be concise and should not include any comments. The solution should take input via stdin (i.e., as `input()`) and should output by printing to stdout.\\n\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, attempts):\n",
    "\n",
    "    answers = {}\n",
    "\n",
    "    for j in range(len(data)):\n",
    "\n",
    "        problem_id = data[j]['problem_id']\n",
    "        answers[problem_id] = []\n",
    "\n",
    "        for _ in range(attempts):\n",
    "\n",
    "            messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": data[j]['question']}]\n",
    "            response = get_responses(model, messages)\n",
    "            answers[problem_id].append(response)\n",
    "\n",
    "    return answers\n",
    "\n",
    "def run(models, difficulties, attempts=1):\n",
    "\n",
    "    results = {}\n",
    "    for d in difficulties:\n",
    "        data = get_dataset(d)\n",
    "        for m in models:\n",
    "            answers = evaluate(m, data, attempts)\n",
    "            save_answers(answers, m, d)\n",
    "            results[m][d] = metric.compute(predictions=answers, level=d)\n",
    "\n",
    "    save_results(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ QUESTION ================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/lewishammond/.cache/huggingface/modules/datasets_modules/datasets/codeparrot--apps/04ac807715d07d6e5cc580f59cdc8213cd7dc4529d0bb819cca72c9f8e8c1aa5 (last modified on Sun Sep  8 23:53:31 2024) since it couldn't be found locally at codeparrot/apps, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An accordion is a string (yes, in the real world accordions are musical instruments, but let's forget about it for a while) which can be represented as a concatenation of: an opening bracket (ASCII code $091$), a colon (ASCII code $058$), some (possibly zero) vertical line characters (ASCII code $124$), another colon, and a closing bracket (ASCII code $093$). The length of the accordion is the number of characters in it.\n",
      "\n",
      "For example, [::], [:||:] and [:|||:] are accordions having length $4$, $6$ and $7$. (:|:), {:||:}, [:], ]:||:[ are not accordions. \n",
      "\n",
      "You are given a string $s$. You want to transform it into an accordion by removing some (possibly zero) characters from it. Note that you may not insert new characters or reorder existing ones. Is it possible to obtain an accordion by removing characters from $s$, and if so, what is the maximum possible length of the result?\n",
      "\n",
      "\n",
      "-----Input-----\n",
      "\n",
      "The only line contains one string $s$ ($1 \\le |s| \\le 500000$). It consists of lowercase Latin letters and characters [, ], : and |.\n",
      "\n",
      "\n",
      "-----Output-----\n",
      "\n",
      "If it is not possible to obtain an accordion by removing some characters from $s$, print $-1$. Otherwise print maximum possible length of the resulting accordion.\n",
      "\n",
      "\n",
      "-----Examples-----\n",
      "Input\n",
      "|[a:b:|]\n",
      "\n",
      "Output\n",
      "4\n",
      "\n",
      "Input\n",
      "|]:[|:]\n",
      "\n",
      "Output\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(\"================ QUESTION ================\\n\")\n",
    "all_data = get_dataset(\"introductory\")\n",
    "data = all_data[0]\n",
    "print(data[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ ANSWER ================\n",
      "\n",
      "def max_accordion_length(s):\n",
      "    first_colon = s.find(':')\n",
      "    last_colon = s.rfind(':')\n",
      "    if first_colon == -1 or last_colon == -1 or first_colon >= last_colon:\n",
      "        return -1\n",
      "    open_bracket = s.rfind('[', 0, first_colon)\n",
      "    close_bracket = s.find(']', last_colon)\n",
      "    if open_bracket == -1 or close_bracket == -1:\n",
      "        return -1\n",
      "    count_vertical = s[open_bracket:close_bracket].count('|')\n",
      "    return 4 + count_vertical\n",
      "\n",
      "print(max_accordion_length(input().strip()))\n"
     ]
    }
   ],
   "source": [
    "model = \"openai/gpt-4o-mini\"\n",
    "print(\"================ ANSWER ================\\n\")\n",
    "answers = evaluate(model, [data], 1)\n",
    "print(answers[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ RESULTS ================\n",
      "\n",
      "IT was safe\n",
      "Computing accuracy metrics...\n",
      "number of compile errors = 1 avg = 1.0\n",
      "number of runtime errors = 0 avg = 0.0\n",
      "number of problems evaluated = 1\n",
      "Average Accuracy : 0.0\n",
      "Strict Accuracy : 0.0\n",
      "{'avg_accuracy': 0.0, 'strict_accuracy': 0.0, 'pass_at_k': None}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "metric = load('codeparrot/apps_metric')\n",
    "answer = \"s = input().strip()\\nleft_bracket = s.find('[')\\nright_bracket = s.rfind(']')\\nif left_bracket == -1 or right_bracket == -1 or left_bracket >= right_bracket:\\n    print(-1)\\n    return\\ncolon1 = s.find(':', left_bracket)\\ncolon2 = s.rfind(':', left_bracket, right_bracket)\\nif colon1 == -1 or colon2 == -1 or colon1 >= colon2:\\n    print(-1)\\n    return\\nvertical_lines = s[colon1 + 1:colon2].count('|')\\nprint(4 + vertical_lines)\"\n",
    "\n",
    "print(\"================ RESULTS ================\\n\")\n",
    "\n",
    "results = metric.compute(predictions=[[answer]], level=\"introductory\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
