{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_CPU = True\n",
    "\n",
    "SEED = 349287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import VisionDataset, MNIST, CIFAR10, FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from tensordict.nn import (\n",
    "    TensorDictModule,\n",
    "    TensorDictModuleBase,\n",
    "    TensorDictSequential,\n",
    "    ProbabilisticTensorDictSequential,\n",
    ")\n",
    "from tensordict.nn.distributions import CompositeDistribution\n",
    "from tensordict.tensordict import TensorDict, TensorDictBase\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pvg import Parameters, ImageClassificationParameters, ScenarioType, TrainerType\n",
    "from pvg.experiment_settings import ExperimentSettings\n",
    "from pvg.scenario_base import DataLoader, Dataset\n",
    "from pvg.constants import IC_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch_generator = torch.Generator().manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if not FORCE_CPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameters(scenario=<ScenarioType.IMAGE_CLASSIFICATION: 'image_classification'>, trainer=<TrainerType.SOLO_AGENT: 'solo_agent'>, dataset='fashion-mnist', seed=6198, max_message_rounds=8, prover_reward=1.0, verifier_reward=1.0, verifier_terminated_penalty=-1.0, agents=None, ppo=None, solo_agent=SoloAgentParameters(num_epochs=500, batch_size=256, learning_rate=0.001, body_lr_factor=0.01, test_size=0.2), image_classification=ImageClassificationParameters(selected_classes=(0, 1)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = Parameters(\n",
    "    scenario=ScenarioType.IMAGE_CLASSIFICATION,\n",
    "    trainer=TrainerType.SOLO_AGENT,\n",
    "    dataset=\"fashion-mnist\",\n",
    "    image_classification=ImageClassificationParameters(\n",
    "        selected_classes=(0, 2),\n",
    "    ),\n",
    ")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = ExperimentSettings(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationDataset(Dataset):\n",
    "    \"\"\"A dataset for the image classification task.\n",
    "\n",
    "    Uses a torchvision dataset, and removes all the classes apart from two (determined\n",
    "    by `params.image_classification.selected_classes`).\n",
    "    \"\"\"\n",
    "\n",
    "    x_dtype = torch.float32\n",
    "    y_dtype = torch.int64\n",
    "\n",
    "    dataset_class_map: dict[str, VisionDataset] = {\n",
    "        \"mnist\": MNIST,\n",
    "        \"fashion-mnist\": FashionMNIST,\n",
    "        \"cifar10\": CIFAR10,\n",
    "    }\n",
    "\n",
    "    def _build_tensor_dict(self) -> TensorDict:\n",
    "        # Load the dataset\n",
    "        dataset_class = self.dataset_class_map[self.params.dataset]\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ]\n",
    "        )\n",
    "        torch_dataset = dataset_class(\n",
    "            self.raw_dir, train=True, transform=transform, download=True\n",
    "        )\n",
    "\n",
    "        # Get the whole dataset as a single batch\n",
    "        full_dataset_loader = TorchDataLoader(\n",
    "            torch_dataset, batch_size=len(torch_dataset)\n",
    "        )\n",
    "        images, labels = next(iter(full_dataset_loader))\n",
    "\n",
    "        # Select the classes we want for binary classification\n",
    "        selected_classes = self.params.image_classification.selected_classes\n",
    "        index = (labels == selected_classes[0]) | (labels == selected_classes[1])\n",
    "        images = images[index]\n",
    "        labels = labels[index]\n",
    "        labels = (labels == selected_classes[1]).to(self.y_dtype)\n",
    "\n",
    "        # Create the pixel features, which are all zeros\n",
    "        x = torch.zeros(\n",
    "            images.shape[0],\n",
    "            *images.shape[-2:],\n",
    "            self.params.max_message_rounds,\n",
    "            dtype=self.x_dtype,\n",
    "        )\n",
    "\n",
    "        return TensorDict(\n",
    "            dict(image=images, x=x, y=labels), batch_size=images.shape[0]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        \"\"\"The path to the directory containing the raw data.\"\"\"\n",
    "        return os.path.join(IC_DATA_DIR, self.params.dataset, \"raw\")\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        \"\"\"The path to the directory containing the processed data.\"\"\"\n",
    "        selected_classes = self.params.image_classification.selected_classes\n",
    "        return os.path.join(\n",
    "            IC_DATA_DIR,\n",
    "            self.params.dataset,\n",
    "            (\n",
    "                f\"processed_{self.params.max_message_rounds}\"\n",
    "                f\"_{selected_classes[0]},{selected_classes[1]}\"\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassificationDataset(\n",
       "    fields={\n",
       "        image: MemoryMappedTensor(shape=torch.Size([12000, 1, 28, 28]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "        x: MemoryMappedTensor(shape=torch.Size([12000, 28, 28, 8]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "        y: MemoryMappedTensor(shape=torch.Size([12000]), device=cpu, dtype=torch.int64, is_shared=True)},\n",
       "    batch_size=torch.Size([12000]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ImageClassificationDataset(params, settings)\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvg-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
