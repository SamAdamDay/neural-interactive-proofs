{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph isomorphism PPO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_CPU = True\n",
    "\n",
    "SEED = 349287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch_geometric/typing.py:101: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/sam/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from tensordict.nn import (\n",
    "    TensorDictModule,\n",
    "    TensorDictModuleBase,\n",
    "    TensorDictSequential,\n",
    "    ProbabilisticTensorDictSequential,\n",
    ")\n",
    "from tensordict.nn.distributions import CompositeDistribution\n",
    "from tensordict.tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import InteractionType\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.data.tensor_specs import (\n",
    "    CompositeSpec,\n",
    "    DiscreteTensorSpec,\n",
    "    BinaryDiscreteTensorSpec,\n",
    "    MultiDiscreteTensorSpec,\n",
    "    TensorSpec,\n",
    "    UnboundedContinuousTensorSpec,\n",
    "    Box,\n",
    ")\n",
    "from torchrl.envs import EnvBase\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from torchrl.modules import ProbabilisticActor, ActorValueOperator\n",
    "from torchrl.objectives import ValueEstimators\n",
    "\n",
    "from jaxtyping import Float, Int, Bool\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pvg.scenario_base import DataLoader\n",
    "from pvg.graph_isomorphism import (\n",
    "    GraphIsomorphismAgentBody,\n",
    "    GraphIsomorphismAgentPolicyHead,\n",
    "    GraphIsomorphismAgentValueHead,\n",
    ")\n",
    "from pvg.parameters import Parameters\n",
    "from pvg.graph_isomorphism.data import GraphIsomorphismDataset\n",
    "from pvg.utils.torchrl_objectives import ClipPPOLossMultipleActions\n",
    "from pvg.constants import VERIFIER_AGENT_NUM, PROVER_AGENT_NUM\n",
    "from pvg.utils.types import TorchDevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch_generator = torch.Generator().manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if not FORCE_CPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters(\n",
    "    scenario=\"graph_isomorphism\",\n",
    "    trainer=\"ppo\",\n",
    "    dataset=\"eru10000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixBox(Box):\n",
    "    \"\"\"An abstract representation of the space of adjacency matrices.\"\"\"\n",
    "\n",
    "    def __init__(self, max_num_nodes: int):\n",
    "        self.max_num_nodes = max_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixSpec(TensorSpec):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_num_nodes: int,\n",
    "        shape: torch.Size | None = None,\n",
    "        device: Optional[TorchDevice] = None,\n",
    "        dtype: str | torch.dtype = torch.int32,\n",
    "    ):\n",
    "        self.max_num_nodes = max_num_nodes\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        if shape is None:\n",
    "            self.shape = torch.Size([max_num_nodes, max_num_nodes])\n",
    "        else:\n",
    "            if shape[-2:] != (max_num_nodes, max_num_nodes):\n",
    "                raise ValueError(\n",
    "                    f\"The last two dimensions of the shape must be {max_num_nodes}. \"\n",
    "                    f\"Got {shape[-2:]}.\"\n",
    "                )\n",
    "            self.shape = torch.Size(shape)\n",
    "\n",
    "        self.space = AdjacencyMatrixBox(max_num_nodes)\n",
    "\n",
    "    def is_in(self, val: torch.Tensor) -> bool:\n",
    "        \"\"\"Check if a value is a valid adjacency matrix.\"\"\"\n",
    "\n",
    "        # Basic type checks\n",
    "        if not isinstance(val, torch.Tensor):\n",
    "            return False\n",
    "        if val.shape[-2:] != (self.max_num_nodes, self.max_num_nodes):\n",
    "            return False\n",
    "        if val.dtype != self.dtype:\n",
    "            return False\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        if not torch.all(torch.isin(val, torch.tensor([0, 1], device=self.device))):\n",
    "            return False\n",
    "\n",
    "        # Make sure the matrix is symmetric\n",
    "        if not torch.all(val.transpose(-1, -2) == val):\n",
    "            return False\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        if not torch.all(torch.isin(torch.diagonal(val, dim1=-2, dim2=-1), 0)):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def rand(self, shape: Optional[list[int] | torch.Size] = None) -> torch.Tensor:\n",
    "        \"\"\"Generate a random 1/2 Erdos-Renyi adjacency matrix.\"\"\"\n",
    "\n",
    "        if shape is None:\n",
    "            shape = shape = torch.Size([])\n",
    "\n",
    "        adjacency_values = torch.rand(*shape, *self.shape, device=device)\n",
    "        adjacency = (adjacency_values < 0.5).to(self.dtype)\n",
    "        adjacency = adjacency.triu(diagonal=1)\n",
    "        adjacency += adjacency.transpose(1, 2).clone()\n",
    "\n",
    "        return adjacency\n",
    "\n",
    "    def _project(self, val: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Project a value to the space of valid adjacency matrices.\"\"\"\n",
    "\n",
    "        # Symmetrize the matrix\n",
    "        val = (val + val.transpose(1, 2)) / 2\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        val[..., torch.arange(self.max_num_nodes), torch.arange(self.max_num_nodes)] = 0\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        return torch.clamp(torch.round(val), min=0, max=1).to(self.dtype)\n",
    "    \n",
    "    def to(self, dest: torch.dtype | torch.device | str | int) -> TensorSpec:\n",
    "        if isinstance(dest, torch.dtype):\n",
    "            self.dtype = dest\n",
    "        elif isinstance(dest, (torch.device, str, int)):\n",
    "            self.device = dest\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid destination {dest}\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable batch-size data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forgetful_cycle(iterable):\n",
    "    \"\"\"A version of cycle that doesn't save copies of the values\"\"\"\n",
    "    while True:\n",
    "        for i in iterable:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableGeometricDataCycler:\n",
    "    \"\"\"A loader that cycles through geometric data, but allows the batch size to vary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader : DataLoader\n",
    "        The base dataloader to use. This dataloader will be cycled through.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataloader: DataLoader):\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader_iter = iter(forgetful_cycle(self.dataloader))\n",
    "        self.remainder: Optional[list[TensorDict]] = None\n",
    "\n",
    "    def get_batch(self, batch_size: int) -> TensorDict:\n",
    "        \"\"\"Get a batch of data from the dataloader with the given batch size.\n",
    "\n",
    "        If the dataloader is exhausted, it will be reset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            The size of the batch to return.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        batch : TensorDict\n",
    "            A batch of data with the given batch size.\n",
    "        \"\"\"\n",
    "\n",
    "        left_to_sample = batch_size\n",
    "        batch_components: list[TensorDict] = []\n",
    "\n",
    "        # Start by sampling from the remainder from the previous sampling\n",
    "        if self.remainder is not None:\n",
    "            batch_components.append(self.remainder[:left_to_sample])\n",
    "            if len(self.remainder) <= left_to_sample:\n",
    "                left_to_sample -= len(self.remainder)\n",
    "                self.remainder = None\n",
    "            else:\n",
    "                self.remainder = self.remainder[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Keep sampling batches until we have enough\n",
    "        while left_to_sample > 0:\n",
    "            batch: TensorDict = next(self.dataloader_iter)\n",
    "            batch_components.append(batch[:left_to_sample])\n",
    "            if len(batch) <= left_to_sample:\n",
    "                left_to_sample -= len(batch)\n",
    "            else:\n",
    "                self.remainder = batch[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Concatenate the batch components into a single batch\n",
    "        batch = torch.cat(batch_components, dim=0)\n",
    "        return batch\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.dataloader!r})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismEnv(EnvBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: Parameters,\n",
    "        device: TorchDevice = device,\n",
    "        int_dtype: torch.dtype = torch.int,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.params = params\n",
    "        self.int_dtype = int_dtype\n",
    "\n",
    "        # Create a random number generator\n",
    "        self.rng = torch.Generator(device=device)\n",
    "\n",
    "        # Load the dataset\n",
    "        self.dataset = GraphIsomorphismDataset(params)\n",
    "        self.data_cycler: Optional[VariableGeometricDataCycler] = None\n",
    "\n",
    "        # Compute the maximum number of nodes in the dataset\n",
    "        self.max_num_nodes = self.dataset[\"x\"].shape[-2]\n",
    "\n",
    "        # The number of environments is the number of episodes we can fit in a batch\n",
    "        self.num_envs = params.ppo.frames_per_batch // params.max_message_rounds\n",
    "        self.batch_size = (self.num_envs,)\n",
    "\n",
    "        # The spec for the observation space: agents see the adjacency matrix and the\n",
    "        # messages sent so far. The \"message\" field contains the most recent message.\n",
    "        self.observation_spec = CompositeSpec(\n",
    "            adjacency=AdjacencyMatrixSpec(\n",
    "                self.max_num_nodes,\n",
    "                shape=(self.num_envs, 2, self.max_num_nodes, self.max_num_nodes),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            x=BinaryDiscreteTensorSpec(\n",
    "                params.max_message_rounds,\n",
    "                shape=(\n",
    "                    self.num_envs,\n",
    "                    2,\n",
    "                    self.max_num_nodes,\n",
    "                    params.max_message_rounds,\n",
    "                ),\n",
    "                dtype=torch.float,\n",
    "            ),\n",
    "            node_mask=BinaryDiscreteTensorSpec(\n",
    "                self.max_num_nodes,\n",
    "                shape=(\n",
    "                    self.num_envs,\n",
    "                    2,\n",
    "                    self.max_num_nodes,\n",
    "                ),\n",
    "                dtype=torch.bool,\n",
    "            ),\n",
    "            message=DiscreteTensorSpec(\n",
    "                2 * self.max_num_nodes,\n",
    "                shape=(self.num_envs,),\n",
    "                dtype=torch.long,\n",
    "            ),\n",
    "            round=DiscreteTensorSpec(\n",
    "                params.max_message_rounds,\n",
    "                shape=(self.num_envs,),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "        # The spec for the state space: the true label and the round number\n",
    "        self.state_spec = CompositeSpec(\n",
    "            y=BinaryDiscreteTensorSpec(\n",
    "                1,\n",
    "                shape=(self.num_envs, 1),\n",
    "                dtype=torch.long,\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "        # Each action space has shape (batch_size, num_agents). Each agent chooses both\n",
    "        # a node and a decision: reject, accept or continue (represented as 0, 1 or 2).\n",
    "        # The node is is a number between 0 and 2 * max_num_nodes - 1. If it is less\n",
    "        # than max_num_nodes, it is a node in the first graph, otherwise it is a node in\n",
    "        # the second graph. The verifier is agent 0 and the prover is agent 1.\n",
    "        self.action_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                node_selected=DiscreteTensorSpec(\n",
    "                    2 * self.max_num_nodes,\n",
    "                    shape=(self.num_envs, 2),\n",
    "                    dtype=self.int_dtype,\n",
    "                ),\n",
    "                decision=DiscreteTensorSpec(\n",
    "                    3,\n",
    "                    shape=(self.num_envs, 2),\n",
    "                    dtype=self.int_dtype,\n",
    "                ),\n",
    "                shape=(self.num_envs,),\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "        self.reward_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                reward=UnboundedContinuousTensorSpec(shape=(self.num_envs, 2)),\n",
    "                shape=(self.num_envs,),\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "        self.done_spec = CompositeSpec(\n",
    "            done=BinaryDiscreteTensorSpec(\n",
    "                self.num_envs, shape=(self.num_envs,), dtype=torch.bool\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        \"\"\"Perform a step in the environment.\"\"\"\n",
    "\n",
    "        # Extract the tensors from the dict\n",
    "        y: Int[Tensor, \"batch 1\"] = tensordict[\"y\"]\n",
    "        x: Float[Tensor, \"batch graph node message_round\"] = tensordict[\"x\"]\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "        node_selected: Int[Tensor, \"batch agent\"] = tensordict[\n",
    "            \"agents\", \"node_selected\"\n",
    "        ]\n",
    "        decision: Int[Tensor, \"batch agent\"] = tensordict[\"agents\", \"decision\"]\n",
    "        done: Bool[Tensor, \"batch\"] = tensordict[\"done\"]\n",
    "\n",
    "        # Compute index of the agent whose turn it is. The prover goes first.\n",
    "        agent_index: Int[Tensor, \"batch\"] = (round % 2)\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            agent_index = 1 - agent_index\n",
    "\n",
    "        # Determine which graph contains the selected node and which node it is there\n",
    "        # (batch agent)\n",
    "        which_graph = node_selected >= self.max_num_nodes\n",
    "        # (batch agent)\n",
    "        graph_node = torch.where(\n",
    "            which_graph, node_selected - self.max_num_nodes, node_selected\n",
    "        )\n",
    "\n",
    "        # Write the node selected by the agent whose turn it is as a (one-hot) message\n",
    "        x[\n",
    "            torch.arange(x.shape[0]),\n",
    "            which_graph[torch.arange(which_graph.shape[0]), agent_index].int(),\n",
    "            graph_node[torch.arange(which_graph.shape[0]), agent_index],\n",
    "            round,\n",
    "        ] = 1\n",
    "\n",
    "        # Set the node selected by the agent whose turn it is as the message\n",
    "        message = node_selected[\n",
    "            torch.arange(node_selected.shape[0]), agent_index\n",
    "        ].long()\n",
    "\n",
    "        # If the verifier has made a guess, compute the reward and terminate the episode\n",
    "        verifier_decision_made = (agent_index == VERIFIER_AGENT_NUM) & (\n",
    "            decision[:, VERIFIER_AGENT_NUM] != 2\n",
    "        )\n",
    "        done = done | verifier_decision_made\n",
    "        reward_verifier = (\n",
    "            verifier_decision_made & (decision[:, VERIFIER_AGENT_NUM] == y.squeeze())\n",
    "        ).float()\n",
    "        reward_verifier = reward_verifier * self.params.verifier_reward\n",
    "        reward_prover = (\n",
    "            verifier_decision_made & (decision[:, VERIFIER_AGENT_NUM] == 1)\n",
    "        ).float()\n",
    "        reward_prover = reward_prover * self.params.prover_reward\n",
    "\n",
    "        # If we reach the end of the episode and the verifier has not made a guess,\n",
    "        # terminate it with a negative reward for the verifier\n",
    "        done = done | (round >= self.params.max_message_rounds - 1)\n",
    "        reward_verifier[\n",
    "            (round >= self.params.max_message_rounds - 1) & ~verifier_decision_made\n",
    "        ] = self.params.verifier_terminated_penalty\n",
    "\n",
    "        # Stack the rewards for the two agents\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            reward = torch.stack([reward_verifier, reward_prover], dim=-1)\n",
    "        else:\n",
    "            reward = torch.stack([reward_prover, reward_verifier], dim=-1)\n",
    "\n",
    "        # Put everything together\n",
    "        next = TensorDict(\n",
    "            dict(\n",
    "                adjacency=tensordict[\"adjacency\"],\n",
    "                x=x,\n",
    "                node_mask=tensordict[\"node_mask\"],\n",
    "                message=message,\n",
    "                round=round + 1,\n",
    "                done=done,\n",
    "                agents=TensorDict(dict(reward=reward), batch_size=self.batch_size),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        return next\n",
    "\n",
    "    def _reset(self, tensordict: Optional[TensorDictBase] = None) -> TensorDictBase:\n",
    "        \"\"\"(Partially) reset the environment.\n",
    "\n",
    "        For each episode which is done, takes a new sample from the dataset and resets\n",
    "        the episode.\n",
    "        \"\"\"\n",
    "\n",
    "        # If no tensordict is given, we're starting afresh\n",
    "        if tensordict is None:\n",
    "            tensordict = TensorDict(\n",
    "                dict(\n",
    "                    adjacency=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.max_num_nodes,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    x=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.params.max_message_rounds,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.float,\n",
    "                    ),\n",
    "                    node_mask=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.bool,\n",
    "                    ),\n",
    "                    message=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.long,\n",
    "                    ),\n",
    "                    y=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        1,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.long,\n",
    "                    ),\n",
    "                    round=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    done=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.bool,\n",
    "                    ),\n",
    "                ),\n",
    "                batch_size=self.batch_size,\n",
    "            )\n",
    "\n",
    "            new_mask = torch.ones(\n",
    "                *self.batch_size, dtype=torch.bool, device=self.device\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            new_mask = tensordict[\"done\"]\n",
    "            tensordict = tensordict.clone()\n",
    "\n",
    "        # If we don't have a data cycler yet, create one\n",
    "        if self.data_cycler is None:\n",
    "            dataloader = DataLoader(\n",
    "                self.dataset,\n",
    "                batch_size=self.num_envs,\n",
    "                shuffle=True,\n",
    "                generator=self.rng,\n",
    "            )\n",
    "            self.data_cycler = VariableGeometricDataCycler(dataloader)\n",
    "\n",
    "        # Sample a new batch of data for the episodes that are done\n",
    "        batch = self.data_cycler.get_batch(new_mask.sum().item()).to(self.device)\n",
    "\n",
    "        # Copy the new data into the output\n",
    "        tensordict[\"adjacency\"][new_mask] = batch[\"adjacency\"]\n",
    "        tensordict[\"node_mask\"][new_mask] = batch[\"node_mask\"]\n",
    "        tensordict[\"y\"][new_mask] = batch[\"y\"].unsqueeze(-1)\n",
    "        tensordict[\"x\"][new_mask] = torch.zeros_like(tensordict[\"x\"][new_mask])\n",
    "        tensordict[\"message\"][new_mask] = 0\n",
    "        tensordict[\"round\"][new_mask] = 0\n",
    "        tensordict[\"done\"][new_mask] = False\n",
    "\n",
    "        return tensordict\n",
    "\n",
    "    def _set_seed(self, seed: int | None):\n",
    "        self.rng = torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphIsomorphismEnv(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] y: 0 P: ( 8)  0.0 V: ( 9,   1)  0.0  | [0] y: 1 P: (13)  0.0 V: (13,   0)  0.0 \n",
      "[1] y: 0 P: ( 1)  1.0 V: (14,   1)  0.0  | [1] y: 1 P: (21)  0.0 V: ( 3,   0)  0.0 \n",
      "[0] y: 0 P: ( 9)  0.0 V: (13,   2)  0.0  | [0] y: 1 P: (14)  0.0 V: ( 0,   0)  0.0 \n",
      "[1] y: 0 P: ( 3)  1.0 V: ( 8,   1)  0.0  | [1] y: 1 P: (13)  1.0 V: ( 9,   1)  1.0 \n",
      "[0] y: 0 P: ( 3)  0.0 V: ( 6,   2)  0.0  | [0] y: 0 P: ( 2)  0.0 V: ( 5,   0)  0.0 \n",
      "[1] y: 0 P: ( 0)  0.0 V: ( 0,   2)  0.0  | [1] y: 0 P: ( 6)  0.0 V: (18,   0)  1.0 \n",
      "[2] y: 0 P: (14)  0.0 V: (21,   0)  0.0  | [0] y: 1 P: ( 8)  0.0 V: (11,   2)  0.0 \n",
      "[3] y: 0 P: ( 5)  1.0 V: ( 5,   1)  0.0  | [1] y: 1 P: (10)  0.0 V: ( 4,   0)  0.0 \n",
      "[0] y: 1 P: ( 6)  0.0 V: (14,   1)  0.0  | [0] y: 0 P: (11)  0.0 V: (18,   0)  0.0 \n",
      "[1] y: 1 P: (12)  0.0 V: ( 4,   2)  0.0  | [1] y: 0 P: ( 2)  0.0 V: ( 9,   0)  1.0 \n",
      "[2] y: 1 P: (20)  0.0 V: ( 8,   0)  0.0  | [0] y: 1 P: (12)  0.0 V: (10,   2)  0.0 \n",
      "[3] y: 1 P: ( 5)  0.0 V: ( 1,   2)  0.0  | [1] y: 1 P: ( 8)  0.0 V: ( 4,   2)  0.0 \n",
      "[4] y: 1 P: (10)  0.0 V: (12,   0)  0.0  | [2] y: 1 P: ( 3)  0.0 V: (12,   2)  0.0 \n",
      "[5] y: 1 P: ( 4)  0.0 V: (21,   0)  0.0  | [3] y: 1 P: (20)  1.0 V: ( 5,   1)  1.0 \n",
      "[0] y: 0 P: ( 0)  0.0 V: (12,   0)  0.0  | [0] y: 0 P: (16)  0.0 V: (10,   1)  0.0 \n",
      "[1] y: 0 P: ( 9)  0.0 V: (21,   2)  0.0  | [1] y: 0 P: ( 1)  0.0 V: ( 8,   0)  1.0 \n",
      "[2] y: 0 P: (15)  0.0 V: (10,   0)  0.0  | [0] y: 0 P: ( 0)  0.0 V: ( 8,   1)  0.0 \n",
      "[3] y: 0 P: ( 6)  1.0 V: ( 1,   1)  0.0  | [1] y: 0 P: (14)  0.0 V: ( 9,   2)  0.0 \n",
      "[0] y: 0 P: ( 3)  0.0 V: ( 1,   1)  0.0  | [2] y: 0 P: ( 8)  0.0 V: ( 3,   0)  0.0 \n",
      "[1] y: 0 P: ( 5)  0.0 V: ( 5,   0)  1.0  | [3] y: 0 P: (15)  0.0 V: (10,   0)  1.0 \n",
      "[0] y: 0 P: (16)  0.0 V: ( 6,   2)  0.0  | [0] y: 0 P: (21)  0.0 V: (21,   2)  0.0 \n",
      "[1] y: 0 P: (21)  0.0 V: (17,   0)  1.0  | [1] y: 0 P: ( 8)  0.0 V: ( 4,   2)  0.0 \n",
      "[0] y: 0 P: ( 7)  0.0 V: ( 3,   0)  0.0  | [2] y: 0 P: (11)  0.0 V: (13,   2)  0.0 \n",
      "[1] y: 0 P: ( 9)  0.0 V: ( 8,   2)  0.0  | [3] y: 0 P: (18)  0.0 V: (15,   0)  1.0 \n",
      "[2] y: 0 P: ( 9)  0.0 V: (15,   2)  0.0  | [0] y: 0 P: ( 5)  0.0 V: ( 8,   0)  0.0 \n",
      "[3] y: 0 P: (19)  0.0 V: (16,   0)  1.0  | [1] y: 0 P: (14)  0.0 V: (12,   0)  1.0 \n",
      "[0] y: 1 P: (18)  0.0 V: ( 8,   2)  0.0  | [0] y: 0 P: (21)  0.0 V: (13,   2)  0.0 \n",
      "[1] y: 1 P: (14)  0.0 V: (17,   2)  0.0  | [1] y: 0 P: ( 1)  1.0 V: ( 2,   1)  0.0 \n",
      "[2] y: 1 P: (11)  0.0 V: (12,   0)  0.0  | [0] y: 1 P: (13)  0.0 V: ( 0,   1)  0.0 \n",
      "[3] y: 1 P: ( 0)  1.0 V: (10,   1)  1.0  | [1] y: 1 P: ( 4)  0.0 V: (10,   0)  0.0 \n",
      "[0] y: 0 P: ( 4)  0.0 V: (18,   0)  0.0  | [0] y: 1 P: (13)  0.0 V: ( 4,   0)  0.0 \n",
      "[1] y: 0 P: ( 3)  1.0 V: (16,   1)  0.0  | [1] y: 1 P: (18)  0.0 V: (10,   2)  0.0 \n",
      "[0] y: 1 P: ( 5)  0.0 V: ( 0,   2)  0.0  | [2] y: 1 P: ( 1)  0.0 V: ( 6,   2)  0.0 \n",
      "[1] y: 1 P: (16)  0.0 V: (19,   2)  0.0  | [3] y: 1 P: (20)  1.0 V: ( 3,   1)  1.0 \n",
      "[2] y: 1 P: ( 2)  0.0 V: (12,   2)  0.0  | [0] y: 1 P: ( 7)  0.0 V: (16,   2)  0.0 \n",
      "[3] y: 1 P: ( 4)  0.0 V: ( 6,   0)  0.0  | [1] y: 1 P: (14)  0.0 V: ( 3,   0)  0.0 \n",
      "[0] y: 0 P: (10)  0.0 V: (13,   1)  0.0  | [0] y: 0 P: (16)  0.0 V: ( 6,   1)  0.0 \n",
      "[1] y: 0 P: ( 1)  1.0 V: (18,   1)  0.0  | [1] y: 0 P: ( 5)  0.0 V: (14,   0)  1.0 \n",
      "[0] y: 1 P: ( 8)  0.0 V: (14,   0)  0.0  | [0] y: 1 P: (10)  0.0 V: ( 1,   2)  0.0 \n"
     ]
    }
   ],
   "source": [
    "def printer(env, tensordict):\n",
    "    to_print = []\n",
    "    for i in range(2):\n",
    "        to_print.append(\n",
    "            f\"[{tensordict['round'][i].item()}] \"\n",
    "            f\"y: {tensordict['y'][i].item()} \"\n",
    "            f\"P: ({tensordict['agents', 'node_selected'][i, PROVER_AGENT_NUM].item():>2}) \"\n",
    "            f\" {tensordict['next', 'agents', 'reward'][i, PROVER_AGENT_NUM].item():>2} \"\n",
    "            f\"V: ({tensordict['agents', 'node_selected'][i, VERIFIER_AGENT_NUM].item():>2}, \"\n",
    "            f\" {tensordict['agents', 'decision'][i, VERIFIER_AGENT_NUM].item():>2}) \"\n",
    "            f\" {tensordict['next', 'agents', 'reward'][i, VERIFIER_AGENT_NUM].item():>2} \"\n",
    "        )\n",
    "    print(\" | \".join(to_print))\n",
    "    # print(tensordict[\"message\"][:2, ..., :3].transpose(-1, -2))\n",
    "    # print(tensordict[\"message\"][:2, ..., :3])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = env.rollout(\n",
    "        max_steps=40,\n",
    "        callback=printer,\n",
    "        auto_cast_to_device=True,\n",
    "        break_when_any_done=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 40, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision: Tensor(shape=torch.Size([125, 40, 2]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                node_selected: Tensor(shape=torch.Size([125, 40, 2]), device=cpu, dtype=torch.int32, is_shared=False)},\n",
       "            batch_size=torch.Size([125, 40]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        message: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                adjacency: Tensor(shape=torch.Size([125, 40, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        reward: Tensor(shape=torch.Size([125, 40, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                    batch_size=torch.Size([125, 40]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                message: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                node_mask: Tensor(shape=torch.Size([125, 40, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                round: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                x: Tensor(shape=torch.Size([125, 40, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([125, 40]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 40, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        round: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        x: Tensor(shape=torch.Size([125, 40, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        y: Tensor(shape=torch.Size([125, 40, 1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([125, 40]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy and critic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedBody(TensorDictModuleBase):\n",
    "    in_keys = (\"round\", \"x\", \"adjacency\", \"message\", \"node_mask\")\n",
    "    out_keys = (\"round\", (\"agents\", \"node_level_repr\"), (\"agents\", \"graph_level_repr\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_body: GraphIsomorphismAgentBody,\n",
    "        verifier_body: GraphIsomorphismAgentBody,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.prover_body = prover_body\n",
    "        self.verifier_body = verifier_body\n",
    "\n",
    "    def forward(self, data: TensorDictBase) -> TensorDict:\n",
    "        round: Int[Tensor, \"batch\"] = data[\"round\"]\n",
    "\n",
    "        # Build tensordicts to feed to each agent when it's their turn\n",
    "        input_prover_dict = {}\n",
    "        input_verifier_dict = {}\n",
    "        for key in self.prover_body.in_keys:\n",
    "            if key == \"ignore_message\":\n",
    "                input_prover_dict[key] = torch.zeros_like(round, dtype=torch.bool)\n",
    "                input_verifier_dict[key] = round == 0\n",
    "            else:\n",
    "                input_prover_dict[key] = data[key]\n",
    "                input_verifier_dict[key] = data[key]\n",
    "        input_prover = TensorDict(\n",
    "            input_prover_dict,\n",
    "            batch_size=data.batch_size,\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            input_verifier_dict,\n",
    "            batch_size=data.batch_size,\n",
    "        )\n",
    "\n",
    "        # Run the prover and verifier bodies\n",
    "        output_prover = self.prover_body(input_prover)\n",
    "        output_verifier = self.verifier_body(input_verifier)\n",
    "\n",
    "        # Stack the outputs\n",
    "        node_level_repr = torch.stack(\n",
    "            [output_prover[\"node_level_repr\"], output_verifier[\"node_level_repr\"]],\n",
    "            dim=-3,\n",
    "        )\n",
    "        graph_level_repr = torch.stack(\n",
    "            [output_prover[\"graph_level_repr\"], output_verifier[\"graph_level_repr\"]],\n",
    "            dim=-2,\n",
    "        )\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            node_level_repr = node_level_repr.flip(-3)\n",
    "            graph_level_repr = graph_level_repr.flip(-2)\n",
    "\n",
    "        return data.update(\n",
    "            dict(\n",
    "                agents=dict(\n",
    "                    node_level_repr=node_level_repr,\n",
    "                    graph_level_repr=graph_level_repr,\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedPolicyHead(TensorDictModuleBase):\n",
    "    in_keys = ((\"agents\", \"node_level_repr\"), (\"agents\", \"graph_level_repr\"))\n",
    "    out_keys = ((\"agents\", \"node_selected_logits\"), (\"agents\", \"decision_logits\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_policy_head: GraphIsomorphismAgentPolicyHead,\n",
    "        verifier_policy_head: GraphIsomorphismAgentPolicyHead,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prover_policy_head = prover_policy_head\n",
    "        self.verifier_policy_head = verifier_policy_head\n",
    "\n",
    "    def forward(self, head_output: TensorDictBase) -> TensorDict:\n",
    "        \"\"\"Run the prover and verifier policy heads and combine their outputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensordict : TensorDictBase\n",
    "            The input to the value heads. Should contain the keys:\n",
    "\n",
    "            - (\"agents\", \"node_level_repr\"): The node-level representation from the\n",
    "              body.\n",
    "            - (\"agents\", \"graph_level_repr\"): The node-level representation from the\n",
    "              body.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tensordict: TensorDict\n",
    "            The tensordict update in place with the output of the value heads.\n",
    "        \"\"\"\n",
    "\n",
    "        # Run the policy heads to obtain the probability distributions\n",
    "        input_prover = TensorDict(\n",
    "            dict(\n",
    "                node_level_repr=head_output[\"agents\", \"node_level_repr\"][\n",
    "                    ..., PROVER_AGENT_NUM, :, :, :\n",
    "                ],\n",
    "                graph_level_repr=head_output[\"agents\", \"graph_level_repr\"][\n",
    "                    ..., PROVER_AGENT_NUM, :, :\n",
    "                ],\n",
    "            ),\n",
    "            batch_size=head_output.batch_size,\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            dict(\n",
    "                node_level_repr=head_output[\"agents\", \"node_level_repr\"][\n",
    "                    ..., VERIFIER_AGENT_NUM, :, :, :\n",
    "                ],\n",
    "                graph_level_repr=head_output[\"agents\", \"graph_level_repr\"][\n",
    "                    ..., VERIFIER_AGENT_NUM, :, :\n",
    "                ],\n",
    "            ),\n",
    "            batch_size=head_output.batch_size,\n",
    "        )\n",
    "        output_prover = self.prover_policy_head(input_prover)\n",
    "        output_verifier = self.verifier_policy_head(input_verifier)\n",
    "\n",
    "        # Stack the outputs\n",
    "        node_selected_logits = torch.stack(\n",
    "            [\n",
    "                output_prover[\"node_selected_logits\"],\n",
    "                output_verifier[\"node_selected_logits\"],\n",
    "            ],\n",
    "            dim=-2,\n",
    "        )\n",
    "        decision_logits = torch.stack(\n",
    "            [\n",
    "                torch.zeros_like(output_verifier[\"decision_logits\"]),\n",
    "                output_verifier[\"decision_logits\"],\n",
    "            ],\n",
    "            dim=-2,\n",
    "        )\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            node_selected_logits = node_selected_logits.flip(-2)\n",
    "            decision_logits = decision_logits.flip(-2)\n",
    "\n",
    "        return head_output.update(\n",
    "            dict(\n",
    "                agents=TensorDict(\n",
    "                    dict(\n",
    "                        node_selected_logits=node_selected_logits,\n",
    "                        decision_logits=decision_logits,\n",
    "                    ),\n",
    "                    batch_size=head_output.batch_size,\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedValueHead(TensorDictModuleBase):\n",
    "    in_keys = ((\"agents\", \"graph_level_repr\"),)\n",
    "    out_keys = ((\"agents\", \"value\"),)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_value_head: GraphIsomorphismAgentValueHead,\n",
    "        verifier_value_head: GraphIsomorphismAgentValueHead,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prover_value_head = prover_value_head\n",
    "        self.verifier_value_head = verifier_value_head\n",
    "\n",
    "    def forward(self, head_output: TensorDictBase) -> TensorDict:\n",
    "        \"\"\"Run the prover and verifier value heads and combine their values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensordict : TensorDictBase\n",
    "            The input to the value heads. Should contain the keys:\n",
    "\n",
    "            - (\"agents\", \"graph_level_repr\"): The node-level representation from the\n",
    "              body.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tensordict: TensorDict\n",
    "            The tensordict update in place with the output of the value heads.\n",
    "        \"\"\"\n",
    "\n",
    "        # Run the policy heads to obtain the value estimates\n",
    "        input_prover = TensorDict(\n",
    "            dict(\n",
    "                graph_level_repr=head_output[\"agents\", \"graph_level_repr\"][\n",
    "                    ..., PROVER_AGENT_NUM, :, :\n",
    "                ],\n",
    "            ),\n",
    "            batch_size=head_output.batch_size,\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            dict(\n",
    "                graph_level_repr=head_output[\"agents\", \"graph_level_repr\"][\n",
    "                    ..., VERIFIER_AGENT_NUM, :, :\n",
    "                ],\n",
    "            ),\n",
    "            batch_size=head_output.batch_size,\n",
    "        )\n",
    "        output_prover = self.prover_value_head(input_prover)\n",
    "        output_verifier = self.verifier_value_head(input_verifier)\n",
    "\n",
    "        # Stack the outputs\n",
    "        value = torch.stack(\n",
    "            [output_prover[\"value\"], output_verifier[\"value\"]],\n",
    "            dim=-1,\n",
    "        )\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            value = value.flip(-2)\n",
    "\n",
    "        return head_output.update(\n",
    "            dict(\n",
    "                agents=TensorDict(\n",
    "                    dict(value=value),\n",
    "                    batch_size=head_output.batch_size,\n",
    "                )\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite categorical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeCategoricalDistribution(CompositeDistribution):\n",
    "    \"\"\"A composition of categorical distributions.\n",
    "\n",
    "    Allows specifying the parameters of the categorical distributions either as logits\n",
    "    or as probabilities.\n",
    "\n",
    "    The `log_prob` method is reimplemented with the following changes: \n",
    "    \n",
    "    - The log-probability can be stored in a different key (specified by the\n",
    "      \"log_prob_key\" parameter)\n",
    "    - It only computes stores the total log-probability, not the individual ones\n",
    "    - It doesn't reduce all non-batch dimensions in the log-probability\n",
    "    - It has a method to compute the entropy of the distribution\n",
    "\n",
    "    Parameter names must be strings ending in \"_logits\" or \"_probs\". However, the\n",
    "    suffix-stripped can be changed by passing a key transform function or a lookup\n",
    "    table. For example, to specify the parameters of a categorical distribution over key\n",
    "    `(\"agents\", \"action\")` using logits, you can pass the following:\n",
    "    \n",
    "    >>> CompositeCategoricalDistribution(\n",
    "    ...     action_logits=..., \n",
    "    ...     key_transform=lambda x: (\"agents\", x)\n",
    "    ... )\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    **categorical_params : dict[str, Tensor]\n",
    "        The parameters of the categorical distributions. Each key is the name of a\n",
    "        categorical parameter appended with \"_logits\" or \"_probs\" and each value is a\n",
    "        Tensor containing the logits or probabilities of the categorical distribution.\n",
    "    key_transform : callable[[str], [str | tuple[str]]] | dict[str, str | tuple[str]],\n",
    "    optional\n",
    "        A function that transforms the keys of the categorical parameters. If a dict is\n",
    "        given, it is used as a lookup table. If a callable is given, it is applied to\n",
    "        each key. Defaults to the identity function.\n",
    "    log_prob_key: NestedKey, default=\"sample_log_prob\"\n",
    "        The tensordict key to use for the log-probability of the sample.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Get the key transform\n",
    "        try:\n",
    "            key_transform = kwargs.pop(\"key_transform\")\n",
    "            if isinstance(key_transform, dict):\n",
    "                key_transform = lambda x: key_transform[x]\n",
    "            elif not callable(key_transform):\n",
    "                raise ValueError(\"key_transform must be a callable or a dict.\")\n",
    "        except KeyError:\n",
    "            key_transform = lambda x: x\n",
    "\n",
    "        # Get the log-probability key\n",
    "        self.log_prob_key = kwargs.pop(\"log_prob_key\", \"sample_log_prob\")\n",
    "\n",
    "        batch_size = None\n",
    "        composite_params = {}\n",
    "        name_suffixes = (\"logits\", \"probs\")\n",
    "        for name, param_value in kwargs.items():\n",
    "            for name_suffix in name_suffixes:\n",
    "                if name.endswith(\"_\" + name_suffix):\n",
    "                    # Set the parameters of the categorical distribution\n",
    "                    resolved_param_name = key_transform(name[: -len(name_suffix) - 1])\n",
    "                    composite_params[resolved_param_name] = {name_suffix: param_value}\n",
    "\n",
    "                    # Make sure all the categorical parameters have the same batch size\n",
    "                    if batch_size is None:\n",
    "                        batch_size = param_value.shape[0]\n",
    "                    elif batch_size != param_value.shape[0]:\n",
    "                        raise ValueError(\n",
    "                            \"All categorical parameters must have the same batch size.\"\n",
    "                        )\n",
    "\n",
    "        composite_params_td = TensorDict(composite_params, batch_size=batch_size)\n",
    "\n",
    "        super().__init__(\n",
    "            params=composite_params_td,\n",
    "            distribution_map={key: Categorical for key in composite_params},\n",
    "        )\n",
    "\n",
    "\n",
    "    def log_prob(self, sample: TensorDictBase) -> TensorDictBase:\n",
    "        \"\"\"Computes the log probability of a sample for the composite distribution\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        sample: TensorDictBase\n",
    "            A tensordict containing the sample\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        updated_sample: TensorDictBase\n",
    "            The sample tensordict updated with the log probability of the sample\n",
    "        \"\"\"\n",
    "        slp = 0.0\n",
    "        d = {}\n",
    "        for name, dist in self.dists.items():\n",
    "            slp += dist.log_prob(sample.get(name))\n",
    "        d[self.log_prob_key] = slp\n",
    "        sample.update(d)\n",
    "        return sample\n",
    "    \n",
    "    def entropy(self) -> float:\n",
    "        \"\"\"Computes the entropy of the composite distribution\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        entropy: float\n",
    "            The entropy of the composite distribution\n",
    "        \"\"\"\n",
    "        entropy = 0.0\n",
    "        for dist in self.dists.values():\n",
    "            entropy += dist.entropy()\n",
    "        return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        decision: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        node_selected: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = CompositeCategoricalDistribution(\n",
    "    node_selected_logits=torch.randn([125, 2, 22]),\n",
    "    decision_logits=torch.randn([125, 2, 3]),\n",
    ")\n",
    "d.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating actors and value estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultInteractionMixin(ProbabilisticTensorDictSequential):\n",
    "    \"\"\"A mixin for accessing the last module's default interaction type.\n",
    "\n",
    "    Allows access to 'default_interaction_mode' and 'default_interaction_type'\n",
    "    attributes for the last module in the sequential.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def default_interaction_mode(self) -> str:\n",
    "        \"\"\"The default interaction mode of the last module in the sequential.\"\"\"\n",
    "        return self[-1].default_interaction_mode\n",
    "\n",
    "    @property\n",
    "    def default_interaction_type(self) -> InteractionType:\n",
    "        \"\"\"The default interaction type of the last module in the sequential.\"\"\"\n",
    "        return self[-1].default_interaction_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticActorDefaultInteractionType(\n",
    "    ProbabilisticActor, DefaultInteractionMixin\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prover_body = GraphIsomorphismAgentBody(params, \"prover\", device=device)\n",
    "verifier_body = GraphIsomorphismAgentBody(params, \"verifier\", device=device)\n",
    "prover_policy_head = GraphIsomorphismAgentPolicyHead(params, \"prover\", device=device)\n",
    "verifier_policy_head = GraphIsomorphismAgentPolicyHead(\n",
    "    params, \"verifier\", device=device\n",
    ")\n",
    "prover_value_head = GraphIsomorphismAgentValueHead(params, \"prover\", device=device)\n",
    "verifier_value_head = GraphIsomorphismAgentValueHead(\n",
    "    params, \"verifier\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = GraphIsomorphismCombinedBody(prover_body, verifier_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_head = ProbabilisticActor(\n",
    "    GraphIsomorphismCombinedPolicyHead(prover_policy_head, verifier_policy_head),\n",
    "    spec=env.action_spec,\n",
    "    distribution_class=CompositeCategoricalDistribution,\n",
    "    distribution_kwargs=dict(\n",
    "        key_transform=lambda x: (\"agents\", x),\n",
    "        log_prob_key=(\"agents\", \"sample_log_prob\"),\n",
    "    ),\n",
    "    in_keys=dict(\n",
    "        node_selected_logits=(\"agents\", \"node_selected_logits\"),\n",
    "        decision_logits=(\"agents\", \"decision_logits\"),\n",
    "    ),\n",
    "    out_keys=env.action_keys,\n",
    "    return_log_prob=True,\n",
    "    log_prob_key=(\"agents\", \"sample_log_prob\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_prob_module = SafeProbabilisticModule(\n",
    "#     spec=env.action_spec,\n",
    "#     distribution_class=CompositeCategoricalDistribution,\n",
    "#     in_keys=dict(\n",
    "#         node_selected_logits=(\"agents\", \"node_selected_logits\"),\n",
    "#         decision_logits=(\"agents\", \"decision_logits\"),\n",
    "#     ),\n",
    "#     out_keys=env.action_keys,\n",
    "#     return_log_prob=True,\n",
    "#     log_prob_key=(\"agents\", \"sample_log_prob\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_head = GraphIsomorphismCombinedValueHead(\n",
    "    prover_value_head, verifier_value_head\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = ActorValueOperator(body, policy_head, value_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = full_model.get_policy_operator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                decision_logits: Tensor(shape=torch.Size([125, 2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                graph_level_repr: Tensor(shape=torch.Size([125, 2, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                node_level_repr: Tensor(shape=torch.Size([125, 2, 2, 11, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                node_selected: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                node_selected_logits: Tensor(shape=torch.Size([125, 2, 22]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                sample_log_prob: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([125]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        message: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        round: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        x: Tensor(shape=torch.Size([125, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        y: Tensor(shape=torch.Size([125, 1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                graph_level_repr: Tensor(shape=torch.Size([125, 2, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                node_level_repr: Tensor(shape=torch.Size([125, 2, 2, 11, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                value: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([125]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        message: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        round: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        x: Tensor(shape=torch.Size([125, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        y: Tensor(shape=torch.Size([125, 1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.get_value_operator()(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = ProbabilisticTensorDictSequential(full_model, policy_head, policy_prob_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReplayBuffer(storage=<torchrl.data.replay_buffers.storages.LazyTensorStorage object at 0x7fa7b3c0b9d0>, sampler=<torchrl.data.replay_buffers.samplers.SamplerWithoutReplacement object at 0x7fa7b3e63a90>, writer=<torchrl.data.replay_buffers.writers.RoundRobinWriter object at 0x7fa8f4b5f310>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(\n",
    "        params.ppo.frames_per_batch, device=device\n",
    "    ),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=params.ppo.minibatch_size,\n",
    ")\n",
    "replay_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    device=device,\n",
    "    storing_device=device,\n",
    "    frames_per_batch=params.ppo.frames_per_batch,\n",
    "    total_frames=params.ppo.frames_per_batch * params.ppo.num_iterations,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SafeProbabilisticTensorDictSequential(\n",
       "    module=ModuleList(\n",
       "      (0): GraphIsomorphismCombinedBody(\n",
       "        (prover_body): GraphIsomorphismAgentBody(\n",
       "          (gnn): TensorDictSequential(\n",
       "              module=ModuleList(\n",
       "                (0): TensorDictModule(\n",
       "                    module=Linear(in_features=8, out_features=16, bias=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['x'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (1): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (2): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (3): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (4): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (5): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (6): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (7): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (8): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (9): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (10): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              ),\n",
       "              device=cpu,\n",
       "              in_keys=['x', 'adjacency', 'node_mask'],\n",
       "              out_keys=['gnn_repr', 'adjacency', 'node_mask'])\n",
       "          (global_pooling): Sequential(\n",
       "            (0): Reduce('... pair max_nodes d_gnn -> ... pair d_gnn', 'sum')\n",
       "            (1): BatchNorm1dBatchDims(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): PairedGaussianNoise(sigma=0.0, pair_dim=-2, train_sigma=False)\n",
       "            (3): PairInvariantizer()\n",
       "          )\n",
       "          (gnn_transformer_encoder): Linear(in_features=19, out_features=16, bias=True)\n",
       "          (transformer): TransformerEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0-3): 4 x TransformerEncoderLayer(\n",
       "                (self_attn): MultiheadAttention(\n",
       "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "                )\n",
       "                (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
       "                (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout1): Dropout(p=0.0, inplace=False)\n",
       "                (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (verifier_body): GraphIsomorphismAgentBody(\n",
       "          (gnn): TensorDictSequential(\n",
       "              module=ModuleList(\n",
       "                (0): TensorDictModule(\n",
       "                    module=Linear(in_features=8, out_features=16, bias=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['x'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (1): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (2): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (3): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (4): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (5): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (6): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (7): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (8): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (9): TensorDictModule(\n",
       "                    module=ReLU(inplace=True),\n",
       "                    device=cpu,\n",
       "                    in_keys=['gnn_repr'],\n",
       "                    out_keys=['gnn_repr'])\n",
       "                (10): GIN(\n",
       "                  (mlp): Sequential(\n",
       "                    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              ),\n",
       "              device=cpu,\n",
       "              in_keys=['x', 'adjacency', 'node_mask'],\n",
       "              out_keys=['gnn_repr', 'adjacency', 'node_mask'])\n",
       "          (global_pooling): Sequential(\n",
       "            (0): Reduce('... pair max_nodes d_gnn -> ... pair d_gnn', 'sum')\n",
       "            (1): BatchNorm1dBatchDims(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): PairedGaussianNoise(sigma=0.0, pair_dim=-2, train_sigma=False)\n",
       "            (3): PairInvariantizer()\n",
       "          )\n",
       "          (gnn_transformer_encoder): Linear(in_features=19, out_features=16, bias=True)\n",
       "          (transformer): TransformerEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0-3): 4 x TransformerEncoderLayer(\n",
       "                (self_attn): MultiheadAttention(\n",
       "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "                )\n",
       "                (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
       "                (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout1): Dropout(p=0.0, inplace=False)\n",
       "                (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GraphIsomorphismCombinedPolicyHead(\n",
       "        (prover_policy_head): GraphIsomorphismAgentPolicyHead(\n",
       "          (node_selector): TensorDictModule(\n",
       "              module=Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "                (3): Rearrange('batch pair node d_out -> batch (pair node) d_out')\n",
       "              ),\n",
       "              device=cpu,\n",
       "              in_keys=['node_level_repr'],\n",
       "              out_keys=['node_selected_logits'])\n",
       "        )\n",
       "        (verifier_policy_head): GraphIsomorphismAgentPolicyHead(\n",
       "          (node_selector): TensorDictModule(\n",
       "              module=Sequential(\n",
       "                (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "                (3): Rearrange('batch pair node d_out -> batch (pair node) d_out')\n",
       "              ),\n",
       "              device=cpu,\n",
       "              in_keys=['node_level_repr'],\n",
       "              out_keys=['node_selected_logits'])\n",
       "          (decider): TensorDictModule(\n",
       "              module=Sequential(\n",
       "                (0): Rearrange('... pair d_in -> ... (pair d_in)')\n",
       "                (1): Linear(in_features=32, out_features=16, bias=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "                (3): Linear(in_features=16, out_features=3, bias=True)\n",
       "              ),\n",
       "              device=cpu,\n",
       "              in_keys=['graph_level_repr'],\n",
       "              out_keys=['decision_logits'])\n",
       "        )\n",
       "      )\n",
       "      (2): SafeProbabilisticModule()\n",
       "    ),\n",
       "    device=cpu,\n",
       "    in_keys=['round', 'x', 'adjacency', 'message', 'node_mask'],\n",
       "    out_keys=['round', ('agents', 'node_level_repr'), ('agents', 'graph_level_repr'), ('agents', 'node_selected_logits'), ('agents', 'decision_logits'), ('agents', 'decision'), ('agents', 'node_selected'), ('agents', 'sample_log_prob')])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.get_policy_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_module = ClipPPOLossMultipleActions(\n",
    "    actor=full_model.get_policy_operator(),\n",
    "    critic=full_model.get_value_operator(),\n",
    "    clip_epsilon=params.ppo.clip_epsilon,\n",
    "    entropy_coef=params.ppo.entropy_eps,\n",
    "    normalize_advantage=False,\n",
    ")\n",
    "loss_module.set_keys(\n",
    "    reward=env.reward_key,\n",
    "    action=env.action_keys,\n",
    "    sample_log_prob=(\"agents\", \"sample_log_prob\"),\n",
    "    value=(\"agents\", \"value\"),\n",
    "    done=(\"agents\", \"done\"),\n",
    "    terminated=(\"agents\", \"terminated\"),\n",
    ")\n",
    "\n",
    "\n",
    "loss_module.make_value_estimator(\n",
    "    ValueEstimators.GAE, gamma=params.ppo.gamma, lmbda=params.ppo.lmbda\n",
    ")\n",
    "gae = loss_module.value_estimator\n",
    "\n",
    "optimizer = torch.optim.Adam(loss_module.parameters(), params.ppo.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean_rewards = (0, 0):   0%|          | 0/8 [00:00<?, ?it/s]/home/sam/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/functional.py:5504: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::_scaled_dot_product_attention_math. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at ../aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1738, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2516, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2275, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2317, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2577, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2729, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2665, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2018, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2254, grad_fn=<AddBackward0>)\n",
      "tensor(-0.3032, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2381, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2319, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2085, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2895, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2222, grad_fn=<AddBackward0>)\n",
      "tensor(-0.1749, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2604, grad_fn=<AddBackward0>)\n",
      "tensor(-0.3208, grad_fn=<AddBackward0>)\n",
      "tensor(-0.1806, grad_fn=<AddBackward0>)\n",
      "tensor(-0.1767, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2657, grad_fn=<AddBackward0>)\n",
      "tensor(-0.1906, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2717, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2150, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2640, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2008, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2184, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2535, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2818, grad_fn=<AddBackward0>)\n",
      "tensor(-0.2958, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Converting a tensordict to boolean value is not permitted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/Projects/PVG Experiments/pvg/utils/torchrl_objectives.py:178\u001b[0m, in \u001b[0;36mPPOLossMultipleActions._log_weight\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_params\u001b[38;5;241m.\u001b[39mto_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor):\n\u001b[0;32m--> 178\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, CompositeDistribution):\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/probabilistic.py:524\u001b[0m, in \u001b[0;36mProbabilisticTensorDictSequential.get_dist\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the distribution that results from passing the input tensordict through the sequence, and then using the resulting parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m tensordict_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dist_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_dist_from_params(tensordict_out)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/probabilistic.py:515\u001b[0m, in \u001b[0;36mProbabilisticTensorDictSequential.get_dist_params\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_interaction_type(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/common.py:281\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/_contextlib.py:126\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/utils.py:253\u001b[0m, in \u001b[0;36mset_skip_existing.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensordict\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/sequence.py:426\u001b[0m, in \u001b[0;36mTensorDictSequential.forward\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule:\n\u001b[0;32m--> 426\u001b[0m         tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/sequence.py:407\u001b[0m, in \u001b[0;36mTensorDictSequential._run_module\u001b[0;34m(self, module, tensordict, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    405\u001b[0m     key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(include_nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39min_keys\n\u001b[1;32m    406\u001b[0m ):\n\u001b[0;32m--> 407\u001b[0m     tensordict \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "Cell \u001b[0;32mIn[15], line 38\u001b[0m, in \u001b[0;36mGraphIsomorphismCombinedBody.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     37\u001b[0m output_prover \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprover_body(input_prover)\n\u001b[0;32m---> 38\u001b[0m output_verifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverifier_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_verifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Stack the outputs\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Code/Projects/PVG Experiments/pvg/graph_isomorphism/agents.py:463\u001b[0m, in \u001b[0;36mGraphIsomorphismAgentBody.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Run the transformer\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;66;03m# (..., 2 + 2 * node, d_transformer)\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m transformer_output_flatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_masked_transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnode_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Extract the graph-level representations and rearrange the rest to have two\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# batch dims\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/Projects/PVG Experiments/pvg/graph_isomorphism/agents.py:163\u001b[0m, in \u001b[0;36mGraphIsomorphismAgentPart._run_masked_transformer\u001b[0;34m(cls, transformer, transformer_input, node_mask)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Compute the transformer output\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# (..., 2 + 2 * max_nodes, d_transformer)\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m transformer_output_flatter \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer_input_flatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask_flatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Expand out the batch dimensions\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/transformer.py:395\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 395\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/transformer.py:718\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    719\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/transformer.py:726\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    725\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 726\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/activation.py:1264\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1264\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/functional.py:5504\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5502\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5504\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5505\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m sub_data \u001b[38;5;241m=\u001b[39m replay_buffer\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m loss_vals \u001b[38;5;241m=\u001b[39m \u001b[43mloss_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     40\u001b[0m     loss_vals[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_objective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;241m+\u001b[39m loss_vals[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_critic\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;241m+\u001b[39m loss_vals[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_entropy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_value)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/_contextlib.py:126\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/common.py:281\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torchrl/objectives/ppo.py:654\u001b[0m, in \u001b[0;36mClipPPOLoss.forward\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    651\u001b[0m     scale \u001b[38;5;241m=\u001b[39m advantage\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;241m.\u001b[39mclamp_min(\u001b[38;5;241m1e-6\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    652\u001b[0m     advantage \u001b[38;5;241m=\u001b[39m (advantage \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m/\u001b[39m scale\n\u001b[0;32m--> 654\u001b[0m log_weight, dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# ESS for logging\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;66;03m# In theory, ESS should be computed on particles sampled from the same source. Here we sample according\u001b[39;00m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;66;03m# to different, unrelated trajectories, which is not standard. Still it can give a idea of the dispersion\u001b[39;00m\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;66;03m# of the weights.\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/Projects/PVG Experiments/pvg/utils/torchrl_objectives.py:177\u001b[0m, in \u001b[0;36mPPOLossMultipleActions._log_weight\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensordict stored \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactions_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         )\n\u001b[1;32m    175\u001b[0m action_tensordict \u001b[38;5;241m=\u001b[39m TensorDict(actions, batch_size\u001b[38;5;241m=\u001b[39mactions_batch_size)\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_params\u001b[38;5;241m.\u001b[39mto_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor):\n\u001b[1;32m    178\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mget_dist(sample)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, CompositeDistribution):\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/base.py:110\u001b[0m, in \u001b[0;36mTensorDictBase.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting a tensordict to boolean value is not permitted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Converting a tensordict to boolean value is not permitted"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=params.ppo.num_iterations, desc=\"mean_rewards = (0, 0)\")\n",
    "\n",
    "log = []\n",
    "for tensordict_data in collector:\n",
    "    # Expand the done and terminated to match the reward shape (this is expected by the\n",
    "    # value estimator)\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"done\"),\n",
    "        tensordict_data.get((\"next\", \"done\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"terminated\"),\n",
    "        tensordict_data.get((\"next\", \"terminated\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "\n",
    "    # Compute the GAE\n",
    "    with torch.no_grad():\n",
    "        gae(\n",
    "            tensordict_data,\n",
    "            params=loss_module.critic_params,\n",
    "            target_params=loss_module.target_critic_params,\n",
    "        )\n",
    "\n",
    "    # Flatten the data and add it to the replay buffer\n",
    "    data_view = tensordict_data.reshape(-1)\n",
    "    replay_buffer.extend(data_view)\n",
    "\n",
    "    for _ in range(params.ppo.num_epochs):\n",
    "        for _ in range(params.ppo.frames_per_batch // params.ppo.minibatch_size):\n",
    "            # Sample a minibatch from the replay buffer\n",
    "            sub_data = replay_buffer.sample()\n",
    "\n",
    "            # Compute the loss\n",
    "            loss_vals = loss_module(sub_data)\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            # Take an optimization step\n",
    "            loss_value.backward()\n",
    "            clip_grad_norm_(loss_module.parameters(), params.ppo.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # Update the policy weights if the policy of the data collector and the trained\n",
    "    # policy live on different devices.\n",
    "    collector.update_policy_weights_()\n",
    "\n",
    "    # Compute the mean rewards for the done episodes\n",
    "    done = tensordict_data.get((\"next\", \"agents\", \"done\"))[..., VERIFIER_AGENT_NUM]\n",
    "    reward = tensordict_data.get((\"next\", \"agents\", \"reward\"))\n",
    "    mean_reward_prover = reward[..., PROVER_AGENT_NUM][done].mean().item()\n",
    "    mean_reward_verifier = reward[..., VERIFIER_AGENT_NUM][done].mean().item()\n",
    "\n",
    "    # Compute the average episode length\n",
    "    round = tensordict_data.get((\"next\", \"round\"))\n",
    "    mean_episode_length = round[done].float().mean().item()\n",
    "\n",
    "    # Record things to the log\n",
    "    log.append(\n",
    "        dict(\n",
    "            mean_reward_prover=mean_reward_prover,\n",
    "            mean_reward_verifier=mean_reward_verifier,\n",
    "            mean_episode_length=mean_episode_length,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update the progress bar\n",
    "    pbar.set_description(\n",
    "        f\"mean_rewards = ({mean_reward_prover:.4f}, {mean_reward_verifier:.4f})\",\n",
    "        refresh=False,\n",
    "    )\n",
    "    pbar.update()\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 8, 2, 11, 11]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        advantage: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                decision_logits: Tensor(shape=torch.Size([125, 8, 2, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                graph_level_repr: Tensor(shape=torch.Size([125, 8, 2, 2, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                node_level_repr: Tensor(shape=torch.Size([125, 8, 2, 2, 11, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                node_selected: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                node_selected_logits: Tensor(shape=torch.Size([125, 8, 2, 22]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                sample_log_prob: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                value: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "            batch_size=torch.Size([125, 8]),\n",
       "            device=cuda,\n",
       "            is_shared=True),\n",
       "        collector: TensorDict(\n",
       "            fields={\n",
       "                traj_ids: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
       "            batch_size=torch.Size([125, 8]),\n",
       "            device=cuda,\n",
       "            is_shared=True),\n",
       "        done: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        message: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                adjacency: Tensor(shape=torch.Size([125, 8, 2, 11, 11]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        done: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                        reward: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                        terminated: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                        value: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "                    batch_size=torch.Size([125, 8]),\n",
       "                    device=cuda,\n",
       "                    is_shared=True),\n",
       "                done: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                message: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                node_mask: Tensor(shape=torch.Size([125, 8, 2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                round: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "                terminated: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                x: Tensor(shape=torch.Size([125, 8, 2, 11, 8]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "            batch_size=torch.Size([125, 8]),\n",
       "            device=cuda,\n",
       "            is_shared=True),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 8, 2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        round: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        terminated: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        value_target: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        x: Tensor(shape=torch.Size([125, 8, 2, 11, 8]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        y: Tensor(shape=torch.Size([125, 8, 1]), device=cuda:0, dtype=torch.int32, is_shared=True)},\n",
       "    batch_size=torch.Size([125, 8]),\n",
       "    device=cuda,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sequential = {key:np.array([x[key] for x in log]) for key in log[0].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Prover",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          0.680272102355957,
          0.6601123809814453,
          0.6744186282157898,
          0.6134831309318542,
          0.6179775595664978,
          0.6353467702865601,
          0.57419353723526,
          0.5613305568695068
         ]
        },
        {
         "name": "Verifier",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          0.5,
          0.5280898809432983,
          0.4832041561603546,
          0.5460674166679382,
          0.4876404404640198,
          0.49888142943382263,
          0.5440860390663147,
          0.5280665159225464
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Mean Rewards"
        },
        "xaxis": {
         "title": {
          "text": "Iteration"
         }
        },
        "yaxis": {
         "title": {
          "text": "Mean Reward"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(log_sequential[\"mean_reward_prover\"])), y=log_sequential[\"mean_reward_prover\"], name=\"Prover\"))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(log_sequential[\"mean_reward_verifier\"])), y=log_sequential[\"mean_reward_verifier\"], name=\"Verifier\"))\n",
    "fig.update_layout(title=\"Mean Rewards\", xaxis_title=\"Iteration\", yaxis_title=\"Mean Reward\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Mean Episode Length",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          2.8979592323303223,
          2.8876404762268066,
          2.640826940536499,
          2.368539333343506,
          2.310112476348877,
          2.2192394733428955,
          2.1462366580963135,
          2.116424083709717
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Mean Episode Length"
        },
        "xaxis": {
         "title": {
          "text": "Iteration"
         }
        },
        "yaxis": {
         "title": {
          "text": "Mean Episode Length"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(log_sequential[\"mean_episode_length\"])), y=log_sequential[\"mean_episode_length\"], name=\"Mean Episode Length\"))\n",
    "fig.update_layout(title=\"Mean Episode Length\", xaxis_title=\"Iteration\", yaxis_title=\"Mean Episode Length\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvg-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
