{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph isomorphism PPO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_CPU = True\n",
    "\n",
    "SEED = 349287\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from tensordict.nn import (\n",
    "    TensorDictModule,\n",
    "    TensorDictModuleBase,\n",
    "    TensorDictSequential,\n",
    "    ProbabilisticTensorDictSequential,\n",
    ")\n",
    "from tensordict.nn.distributions import CompositeDistribution\n",
    "from tensordict.tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import InteractionType\n",
    "from torchrl.modules import ActorCriticOperator, SafeProbabilisticModule\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.data.tensor_specs import (\n",
    "    CompositeSpec,\n",
    "    DiscreteTensorSpec,\n",
    "    BinaryDiscreteTensorSpec,\n",
    "    MultiDiscreteTensorSpec,\n",
    "    TensorSpec,\n",
    "    UnboundedContinuousTensorSpec,\n",
    "    Box,\n",
    ")\n",
    "from torchrl.envs import EnvBase\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from torchrl.modules import ProbabilisticActor\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "\n",
    "from torch_geometric.loader import DataLoader as GeometricDataLoader\n",
    "from torch_geometric.data import Batch as GeometricBatch, Data as GeometricData\n",
    "\n",
    "from jaxtyping import Float, Int, Bool\n",
    "\n",
    "from pvg.graph_isomorphism import (\n",
    "    GraphIsomorphismAgentBody,\n",
    "    GraphIsomorphismAgentPolicyHead,\n",
    "    GraphIsomorphismAgentCriticHead,\n",
    ")\n",
    "from pvg.parameters import Parameters\n",
    "from pvg.graph_isomorphism.data import GraphIsomorphismData, GraphIsomorphismDataset\n",
    "from pvg.utils.data import gi_data_to_tensordict\n",
    "from pvg.constants import VERIFIER_AGENT_NUM, PROVER_AGENT_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch_generator = torch.Generator().manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if not FORCE_CPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters(\n",
    "    scenario=\"graph_isomorphism\",\n",
    "    trainer=\"ppo\",\n",
    "    dataset=\"eru10000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixBox(Box):\n",
    "    \"\"\"An abstract representation of the space of adjacency matrices.\"\"\"\n",
    "\n",
    "    def __init__(self, max_num_nodes: int):\n",
    "        self.max_num_nodes = max_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixSpec(TensorSpec):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_num_nodes: int,\n",
    "        shape: torch.Size | None = None,\n",
    "        device: Optional[torch.device | str | int] = None,\n",
    "        dtype: str | torch.dtype = torch.int32,\n",
    "    ):\n",
    "        self.max_num_nodes = max_num_nodes\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        if shape is None:\n",
    "            self.shape = torch.Size([max_num_nodes, max_num_nodes])\n",
    "        else:\n",
    "            if shape[-2:] != (max_num_nodes, max_num_nodes):\n",
    "                raise ValueError(\n",
    "                    f\"The last two dimensions of the shape must be {max_num_nodes}. \"\n",
    "                    f\"Got {shape[-2:]}.\"\n",
    "                )\n",
    "            self.shape = torch.Size(shape)\n",
    "\n",
    "        self.space = AdjacencyMatrixBox(max_num_nodes)\n",
    "\n",
    "    def is_in(self, val: torch.Tensor) -> bool:\n",
    "        \"\"\"Check if a value is a valid adjacency matrix.\"\"\"\n",
    "\n",
    "        # Basic type checks\n",
    "        if not isinstance(val, torch.Tensor):\n",
    "            return False\n",
    "        if val.shape[-2:] != (self.max_num_nodes, self.max_num_nodes):\n",
    "            return False\n",
    "        if val.dtype != self.dtype:\n",
    "            return False\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        if not torch.all(torch.isin(val, torch.tensor([0, 1], device=self.device))):\n",
    "            return False\n",
    "\n",
    "        # Make sure the matrix is symmetric\n",
    "        if not torch.all(val.transpose(-1, -2) == val):\n",
    "            return False\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        if not torch.all(torch.isin(torch.diagonal(val, dim1=-2, dim2=-1), 0)):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def rand(self, shape: Optional[list[int] | torch.Size] = None) -> torch.Tensor:\n",
    "        \"\"\"Generate a random 1/2 Erdos-Renyi adjacency matrix.\"\"\"\n",
    "\n",
    "        if shape is None:\n",
    "            shape = shape = torch.Size([])\n",
    "\n",
    "        adjacency_values = torch.rand(*shape, *self.shape, device=device)\n",
    "        adjacency = (adjacency_values < 0.5).to(self.dtype)\n",
    "        adjacency = adjacency.triu(diagonal=1)\n",
    "        adjacency += adjacency.transpose(1, 2).clone()\n",
    "\n",
    "        return adjacency\n",
    "\n",
    "    def _project(self, val: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Project a value to the space of valid adjacency matrices.\"\"\"\n",
    "\n",
    "        # Symmetrize the matrix\n",
    "        val = (val + val.transpose(1, 2)) / 2\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        val[..., torch.arange(self.max_num_nodes), torch.arange(self.max_num_nodes)] = 0\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        return torch.clamp(torch.round(val), min=0, max=1).to(self.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forgetful_cycle(iterable):\n",
    "    \"\"\"A version of cycle that doesn't save copies of the values\"\"\"\n",
    "    while True:\n",
    "        for i in iterable:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableGeometricDataCycler:\n",
    "    \"\"\"A loader that cycles through geometric data, but allows the batch size to vary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader : GeometricDataLoader\n",
    "        The base dataloader to use. This dataloader will be cycled through.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataloader: GeometricDataLoader):\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader_iter = iter(forgetful_cycle(self.dataloader))\n",
    "        self.remainder: Optional[list] = None\n",
    "\n",
    "    def get_batch(self, batch_size: int) -> GeometricBatch:\n",
    "        \"\"\"Get a batch of data from the dataloader with the given batch size.\n",
    "\n",
    "        If the dataloader is exhausted, it will be reset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            The size of the batch to return.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        batch : Tensor\n",
    "            A batch of data with the given batch size.\n",
    "        \"\"\"\n",
    "\n",
    "        left_to_sample = batch_size\n",
    "        batch_components = []\n",
    "\n",
    "        # Start by sampling from the remainder from the previous sampling\n",
    "        if self.remainder is not None:\n",
    "            batch_components.extend(self.remainder[:left_to_sample])\n",
    "            if len(self.remainder) <= left_to_sample:\n",
    "                left_to_sample -= len(self.remainder)\n",
    "                self.remainder = None\n",
    "            else:\n",
    "                self.remainder = self.remainder[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Keep sampling batches until we have enough\n",
    "        while left_to_sample > 0:\n",
    "            batch = next(self.dataloader_iter)\n",
    "            batch_components.extend(batch[:left_to_sample])\n",
    "            if len(batch) <= left_to_sample:\n",
    "                left_to_sample -= len(batch)\n",
    "            else:\n",
    "                self.remainder = batch[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Concatenate the batch components into a single batch\n",
    "        batch = GeometricBatch.from_data_list(\n",
    "            batch_components, follow_batch=self.dataloader.follow_batch\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.dataloader!r})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismEnv(EnvBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: Parameters,\n",
    "        device: torch.device | str = device,\n",
    "        int_dtype: torch.dtype = torch.int,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.params = params\n",
    "        self.int_dtype = int_dtype\n",
    "\n",
    "        # Create a random number generator\n",
    "        self.rng = torch.Generator(device=device)\n",
    "\n",
    "        # Load the dataset\n",
    "        self.dataset = GraphIsomorphismDataset(params)\n",
    "        self.data_cycler: Optional[VariableGeometricDataCycler] = None\n",
    "\n",
    "        # Compute the maximum number of nodes in the dataset\n",
    "        self.max_num_nodes = 0\n",
    "        for data in self.dataset:\n",
    "            self.max_num_nodes = max(\n",
    "                self.max_num_nodes, data.x_a.shape[0], data.x_b.shape[0]\n",
    "            )\n",
    "\n",
    "        # The number of environments is the number of episodes we can fit in a batch\n",
    "        self.num_envs = params.ppo.frames_per_batch // params.max_message_rounds\n",
    "        self.batch_size = (self.num_envs,)\n",
    "\n",
    "        # The spec for the observation space: agents see the adjacency matrix and the\n",
    "        # messages sent so far. The \"message\" field contains the most recent message.\n",
    "        self.observation_spec = CompositeSpec(\n",
    "            adjacency=AdjacencyMatrixSpec(\n",
    "                self.max_num_nodes,\n",
    "                shape=(self.num_envs, 2, self.max_num_nodes, self.max_num_nodes),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            x=BinaryDiscreteTensorSpec(\n",
    "                params.max_message_rounds,\n",
    "                shape=(\n",
    "                    self.num_envs,\n",
    "                    2,\n",
    "                    self.max_num_nodes,\n",
    "                    params.max_message_rounds,\n",
    "                ),\n",
    "                dtype=torch.float,\n",
    "            ),\n",
    "            node_mask=BinaryDiscreteTensorSpec(\n",
    "                self.max_num_nodes,\n",
    "                shape=(\n",
    "                    self.num_envs,\n",
    "                    2,\n",
    "                    self.max_num_nodes,\n",
    "                ),\n",
    "                dtype=torch.bool,\n",
    "            ),\n",
    "            message=DiscreteTensorSpec(\n",
    "                2 * self.max_num_nodes,\n",
    "                shape=(self.num_envs,),\n",
    "                dtype=torch.long,\n",
    "            ),\n",
    "            round=DiscreteTensorSpec(\n",
    "                params.max_message_rounds,\n",
    "                shape=(self.num_envs,),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # The spec for the state space: the true label and the round number\n",
    "        self.state_spec = CompositeSpec(\n",
    "            y=BinaryDiscreteTensorSpec(\n",
    "                1,\n",
    "                shape=(self.num_envs, 1),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Each action space has shape (batch_size, num_agents). Each agent chooses both\n",
    "        # a node and a decision: reject, accept or continue (represented as 0, 1 or 2).\n",
    "        # The node is is a number between 0 and 2 * max_num_nodes - 1. If it is less\n",
    "        # than max_num_nodes, it is a node in the first graph, otherwise it is a node in\n",
    "        # the second graph. The verifier is agent 0 and the prover is agent 1.\n",
    "        self.action_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                node_selected=DiscreteTensorSpec(\n",
    "                    2 * self.max_num_nodes,\n",
    "                    shape=(self.num_envs, 2),\n",
    "                    dtype=self.int_dtype,\n",
    "                ),\n",
    "                decision=DiscreteTensorSpec(\n",
    "                    3,\n",
    "                    shape=(self.num_envs, 2),\n",
    "                    dtype=self.int_dtype,\n",
    "                ),\n",
    "                shape=(self.num_envs,),\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.reward_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                reward=UnboundedContinuousTensorSpec(shape=(self.num_envs, 2)),\n",
    "                shape=(self.num_envs,),\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.done_spec = CompositeSpec(\n",
    "            done=BinaryDiscreteTensorSpec(\n",
    "                self.num_envs, shape=(self.num_envs,), dtype=torch.bool\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        \"\"\"Perform a step in the environment.\"\"\"\n",
    "\n",
    "        # Extract the tensors from the dict\n",
    "        y: Int[Tensor, \"batch\"] = tensordict[\"y\"]\n",
    "        x: Float[Tensor, \"batch graph node message_round\"] = tensordict[\"x\"]\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "        node_selected: Int[Tensor, \"batch agent\"] = tensordict[\n",
    "            \"agents\", \"node_selected\"\n",
    "        ]\n",
    "        decision: Int[Tensor, \"batch agent\"] = tensordict[\"agents\", \"decision\"]\n",
    "        done: Bool[Tensor, \"batch\"] = tensordict[\"done\"]\n",
    "\n",
    "        # Compute index of the agent whose turn it is\n",
    "        agent_index: Int[Tensor, \"batch\"] = round % 2\n",
    "        if PROVER_AGENT_NUM == 0:\n",
    "            agent_index = 1 - agent_index\n",
    "\n",
    "        # Determine which graph contains the selected node and which node it is there\n",
    "        # (batch agent)\n",
    "        which_graph = node_selected >= self.max_num_nodes\n",
    "        # (batch agent)\n",
    "        graph_node = torch.where(\n",
    "            which_graph, node_selected - self.max_num_nodes, node_selected\n",
    "        )\n",
    "\n",
    "        # Write the node selected by the agent whose turn it is as a (one-hot) message\n",
    "        x[\n",
    "            torch.arange(x.shape[0]),\n",
    "            which_graph[torch.arange(which_graph.shape[0]), agent_index].int(),\n",
    "            graph_node[torch.arange(which_graph.shape[0]), agent_index],\n",
    "            round,\n",
    "        ] = 1\n",
    "\n",
    "        # Set the node selected by the agent whose turn it is as the message\n",
    "        message = node_selected[\n",
    "            torch.arange(node_selected.shape[0]), agent_index\n",
    "        ].long()\n",
    "\n",
    "        # If the verifier has made a guess, compute the reward and terminate the episode\n",
    "        verifier_decision_made = (agent_index == VERIFIER_AGENT_NUM) & (\n",
    "            decision[:, VERIFIER_AGENT_NUM] != 2\n",
    "        )\n",
    "        done = done | verifier_decision_made\n",
    "        reward_verifier = (\n",
    "            verifier_decision_made & (decision[:, VERIFIER_AGENT_NUM] == y.squeeze())\n",
    "        ).float()\n",
    "        reward_verifier = reward_verifier * self.params.verifier_reward\n",
    "        reward_prover = (\n",
    "            verifier_decision_made & (decision[:, VERIFIER_AGENT_NUM] == 1)\n",
    "        ).float()\n",
    "        reward_prover = reward_prover * self.params.prover_reward\n",
    "\n",
    "        # If we reach the end of the episode and the verifier has not made a guess,\n",
    "        # terminate it with a negative reward for the verifier\n",
    "        done = done | (round >= self.params.max_message_rounds - 1)\n",
    "        reward_verifier[\n",
    "            (round >= self.params.max_message_rounds - 1) & ~verifier_decision_made\n",
    "        ] = self.params.verifier_terminated_penalty\n",
    "\n",
    "        # Stack the rewards for the two agents\n",
    "        reward = torch.stack([reward_verifier, reward_prover], dim=-1)\n",
    "\n",
    "        # Put everything together\n",
    "        next = TensorDict(\n",
    "            dict(\n",
    "                adjacency=tensordict[\"adjacency\"],\n",
    "                x=x,\n",
    "                node_mask=tensordict[\"node_mask\"],\n",
    "                message=message,\n",
    "                round=round + 1,\n",
    "                done=done,\n",
    "                agents=TensorDict(dict(reward=reward), batch_size=self.batch_size),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        return next\n",
    "\n",
    "    def _reset(self, tensordict: Optional[TensorDictBase] = None) -> TensorDictBase:\n",
    "        \"\"\"(Partially) reset the environment.\n",
    "\n",
    "        For each episode which is done, takes a new sample from the dataset and resets\n",
    "        the episode.\n",
    "        \"\"\"\n",
    "\n",
    "        # If no tensordict is given, we're starting afresh\n",
    "        if tensordict is None:\n",
    "            tensordict = TensorDict(\n",
    "                dict(\n",
    "                    adjacency=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.max_num_nodes,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    x=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.params.max_message_rounds,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.float,\n",
    "                    ),\n",
    "                    node_mask=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.bool,\n",
    "                    ),\n",
    "                    message=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.long,\n",
    "                    ),\n",
    "                    y=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        1,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    round=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    done=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.bool,\n",
    "                    ),\n",
    "                ),\n",
    "                batch_size=self.batch_size,\n",
    "            )\n",
    "\n",
    "            new_mask = torch.ones(\n",
    "                *self.batch_size, dtype=torch.bool, device=self.device\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            new_mask = tensordict[\"done\"]\n",
    "            tensordict = tensordict.clone()\n",
    "\n",
    "        # If we don't have a data cycler yet, create one\n",
    "        if self.data_cycler is None:\n",
    "            dataloader = GeometricDataLoader(\n",
    "                self.dataset,\n",
    "                batch_size=self.num_envs,\n",
    "                follow_batch=[\"x_a\", \"x_b\"],\n",
    "                shuffle=True,\n",
    "                generator=self.rng,\n",
    "            )\n",
    "            self.data_cycler = VariableGeometricDataCycler(dataloader)\n",
    "\n",
    "        # Sample a new batch of data for the episodes that are done\n",
    "        batch = self.data_cycler.get_batch(new_mask.sum().item())\n",
    "        batch_tensordict = gi_data_to_tensordict(\n",
    "            batch, node_dim_size=self.max_num_nodes\n",
    "        )\n",
    "\n",
    "        # Copy the new data into the output\n",
    "        tensordict[\"adjacency\"][new_mask] = batch_tensordict[\"adjacency\"]\n",
    "        tensordict[\"x\"][new_mask] = torch.zeros_like(tensordict[\"x\"][new_mask])\n",
    "        tensordict[\"node_mask\"][new_mask] = batch_tensordict[\"node_mask\"]\n",
    "        tensordict[\"message\"][new_mask] = 0\n",
    "        tensordict[\"y\"][new_mask] = (batch.wl_score == -1).int().unsqueeze(-1)\n",
    "        tensordict[\"round\"][new_mask] = 0\n",
    "        tensordict[\"done\"][new_mask] = False\n",
    "\n",
    "        return tensordict\n",
    "\n",
    "    def _set_seed(self, seed: int | None):\n",
    "        self.rng.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphIsomorphismEnv(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] y: 0 P: (16)  0.0 V: (15,   2)  0.0  | [0] y: 1 P: (16)  1.0 V: (11,   1)  1.0 \n",
      "[1] y: 0 P: ( 5)  0.0 V: (11,   0)  0.0  | [0] y: 0 P: (12)  0.0 V: (12,   2)  0.0 \n",
      "[2] y: 0 P: ( 1)  0.0 V: ( 9,   0)  1.0  | [1] y: 0 P: (18)  0.0 V: (14,   1)  0.0 \n",
      "[0] y: 0 P: ( 5)  0.0 V: (17,   0)  1.0  | [2] y: 0 P: (13)  0.0 V: ( 0,   2)  0.0 \n",
      "[0] y: 0 P: (11)  0.0 V: (21,   0)  1.0  | [3] y: 0 P: (16)  0.0 V: (19,   2)  0.0 \n",
      "[0] y: 1 P: (14)  0.0 V: ( 3,   2)  0.0  | [4] y: 0 P: (10)  0.0 V: (13,   0)  1.0 \n",
      "[1] y: 1 P: (11)  0.0 V: ( 3,   2)  0.0  | [0] y: 0 P: ( 7)  1.0 V: (17,   1)  0.0 \n",
      "[2] y: 1 P: (13)  0.0 V: ( 6,   2)  0.0  | [0] y: 1 P: (16)  0.0 V: (16,   2)  0.0 \n",
      "[3] y: 1 P: ( 0)  0.0 V: (17,   1)  0.0  | [1] y: 1 P: (15)  0.0 V: ( 9,   0)  0.0 \n",
      "[4] y: 1 P: (21)  1.0 V: (17,   1)  1.0  | [2] y: 1 P: (10)  0.0 V: (16,   0)  0.0 \n",
      "[0] y: 0 P: ( 2)  0.0 V: (17,   0)  1.0  | [0] y: 0 P: ( 3)  1.0 V: ( 0,   1)  0.0 \n",
      "[0] y: 1 P: (20)  1.0 V: (17,   1)  1.0  | [0] y: 0 P: ( 9)  0.0 V: ( 1,   2)  0.0 \n",
      "[0] y: 1 P: ( 0)  0.0 V: (12,   0)  0.0  | [1] y: 0 P: (16)  0.0 V: ( 6,   0)  0.0 \n",
      "[0] y: 0 P: ( 0)  1.0 V: (18,   1)  0.0  | [2] y: 0 P: ( 4)  0.0 V: ( 8,   0)  1.0 \n",
      "[0] y: 1 P: ( 7)  1.0 V: ( 2,   1)  1.0  | [0] y: 0 P: (13)  0.0 V: (15,   0)  1.0 \n",
      "[0] y: 0 P: (13)  1.0 V: (13,   1)  0.0  | [0] y: 1 P: ( 9)  1.0 V: (20,   1)  1.0 \n",
      "[0] y: 0 P: ( 4)  1.0 V: ( 9,   1)  0.0  | [0] y: 1 P: ( 7)  0.0 V: (20,   0)  0.0 \n",
      "[0] y: 0 P: (21)  0.0 V: ( 1,   0)  1.0  | [0] y: 0 P: (17)  1.0 V: (16,   1)  0.0 \n",
      "[0] y: 0 P: (15)  1.0 V: ( 3,   1)  0.0  | [0] y: 1 P: (12)  1.0 V: ( 7,   1)  1.0 \n",
      "[0] y: 1 P: (14)  0.0 V: (16,   2)  0.0  | [0] y: 0 P: ( 8)  0.0 V: ( 5,   2)  0.0 \n",
      "[1] y: 1 P: (18)  0.0 V: (19,   2)  0.0  | [1] y: 0 P: ( 5)  0.0 V: ( 3,   1)  0.0 \n",
      "[2] y: 1 P: ( 8)  0.0 V: ( 8,   0)  0.0  | [2] y: 0 P: (13)  1.0 V: ( 9,   1)  0.0 \n",
      "[0] y: 0 P: ( 1)  0.0 V: (10,   0)  1.0  | [0] y: 0 P: (21)  1.0 V: (14,   1)  0.0 \n",
      "[0] y: 0 P: ( 9)  0.0 V: (16,   2)  0.0  | [0] y: 1 P: (14)  0.0 V: (13,   2)  0.0 \n",
      "[1] y: 0 P: ( 3)  0.0 V: (20,   0)  0.0  | [1] y: 1 P: (13)  0.0 V: ( 8,   1)  0.0 \n",
      "[2] y: 0 P: ( 3)  1.0 V: ( 8,   1)  0.0  | [2] y: 1 P: ( 2)  0.0 V: ( 6,   2)  0.0 \n",
      "[0] y: 1 P: ( 0)  0.0 V: ( 9,   2)  0.0  | [3] y: 1 P: ( 6)  0.0 V: ( 0,   2)  0.0 \n",
      "[1] y: 1 P: (14)  0.0 V: ( 2,   2)  0.0  | [4] y: 1 P: ( 8)  0.0 V: (21,   0)  0.0 \n",
      "[2] y: 1 P: ( 5)  0.0 V: (10,   2)  0.0  | [0] y: 1 P: (10)  1.0 V: ( 5,   1)  1.0 \n",
      "[3] y: 1 P: ( 6)  0.0 V: (11,   2)  0.0  | [0] y: 0 P: (11)  1.0 V: (14,   1)  0.0 \n",
      "[4] y: 1 P: (12)  0.0 V: (15,   2)  0.0  | [0] y: 0 P: ( 2)  0.0 V: ( 4,   2)  0.0 \n",
      "[5] y: 1 P: (20)  0.0 V: ( 7,   1)  0.0  | [1] y: 0 P: (12)  0.0 V: ( 8,   0)  0.0 \n",
      "[6] y: 1 P: ( 5)  0.0 V: (21,   2)  0.0  | [2] y: 0 P: ( 8)  0.0 V: ( 1,   2)  0.0 \n",
      "[7] y: 1 P: (10)  0.0 V: ( 5,   1)  -1.0  | [3] y: 0 P: ( 3)  0.0 V: (12,   0)  0.0 \n",
      "[0] y: 0 P: ( 4)  0.0 V: (11,   2)  0.0  | [4] y: 0 P: (20)  0.0 V: (21,   0)  1.0 \n",
      "[1] y: 0 P: ( 0)  0.0 V: ( 5,   1)  0.0  | [0] y: 0 P: (16)  0.0 V: (12,   0)  1.0 \n",
      "[2] y: 0 P: ( 9)  0.0 V: (17,   0)  1.0  | [0] y: 1 P: ( 1)  0.0 V: (21,   2)  0.0 \n",
      "[0] y: 1 P: (15)  0.0 V: (12,   0)  0.0  | [1] y: 1 P: ( 0)  0.0 V: (10,   0)  0.0 \n",
      "[0] y: 0 P: ( 6)  0.0 V: (14,   2)  0.0  | [2] y: 1 P: (14)  1.0 V: ( 1,   1)  1.0 \n"
     ]
    }
   ],
   "source": [
    "def printer(env, tensordict):\n",
    "    to_print = []\n",
    "    for i in range(2):\n",
    "        to_print.append(\n",
    "            f\"[{tensordict['round'][i].item()}] \"\n",
    "            f\"y: {tensordict['y'][i].item()} \"\n",
    "            f\"P: ({tensordict['agents', 'node_selected'][i, 1].item():>2}) \"\n",
    "            f\" {tensordict['next', 'agents', 'reward'][i, 1].item():>2} \"\n",
    "            f\"V: ({tensordict['agents', 'node_selected'][i, 0].item():>2}, \"\n",
    "            f\" {tensordict['agents', 'decision'][i, 0].item():>2}) \"\n",
    "            f\" {tensordict['next', 'agents', 'reward'][i, 0].item():>2} \"\n",
    "        )\n",
    "    print(\" | \".join(to_print))\n",
    "    # print(tensordict[\"message\"][:2, ..., :3].transpose(-1, -2))\n",
    "    # print(tensordict[\"message\"][:2, ..., :3])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = env.rollout(\n",
    "        max_steps=40,\n",
    "        callback=printer,\n",
    "        auto_cast_to_device=True,\n",
    "        break_when_any_done=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 40, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision: Tensor(shape=torch.Size([125, 40, 2]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                node_selected: Tensor(shape=torch.Size([125, 40, 2]), device=cpu, dtype=torch.int32, is_shared=False)},\n",
       "            batch_size=torch.Size([125, 40]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        message: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                adjacency: Tensor(shape=torch.Size([125, 40, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        reward: Tensor(shape=torch.Size([125, 40, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                    batch_size=torch.Size([125, 40]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                message: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                node_mask: Tensor(shape=torch.Size([125, 40, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                round: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                x: Tensor(shape=torch.Size([125, 40, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([125, 40]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 40, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        round: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([125, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        x: Tensor(shape=torch.Size([125, 40, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        y: Tensor(shape=torch.Size([125, 40, 1]), device=cpu, dtype=torch.int32, is_shared=False)},\n",
       "    batch_size=torch.Size([125, 40]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy and critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedBody(TensorDictModuleBase):\n",
    "    in_keys = (\"round\", \"x\", \"adjacency\", \"message\")\n",
    "    out_keys = (\"round\", \"node_level_repr\", \"graph_level_repr\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_body: GraphIsomorphismAgentBody,\n",
    "        verifier_body: GraphIsomorphismAgentBody,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.prover_body = prover_body\n",
    "        self.verifier_body = verifier_body\n",
    "\n",
    "    def forward(self, tensordict: TensorDictBase) -> TensorDict:\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "\n",
    "        # Compute the index of the agent whose turn it is\n",
    "        prover_turn: Int[Tensor, \"batch\"] = round % 2 == 0\n",
    "\n",
    "        batch_size = tensordict.batch_size[0]\n",
    "\n",
    "        # Build tensordicts to feed to each agent when it's their turn\n",
    "        input_prover_dict = {}\n",
    "        input_verifier_dict = {}\n",
    "        for key in self.prover_body.in_keys:\n",
    "            if key == \"ignore_message\":\n",
    "                input_prover_dict[key] = torch.zeros(\n",
    "                    prover_turn.sum().item(), device=tensordict.device, dtype=torch.bool\n",
    "                )\n",
    "                input_verifier_dict[key] = round[~prover_turn] == 0\n",
    "            else:\n",
    "                input_prover_dict[key] = tensordict[key][prover_turn]\n",
    "                input_verifier_dict[key] = tensordict[key][~prover_turn]\n",
    "        input_prover = TensorDict(\n",
    "            input_prover_dict,\n",
    "            batch_size=(prover_turn.sum().item()),\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            input_verifier_dict,\n",
    "            batch_size=((~prover_turn).sum().item()),\n",
    "        )\n",
    "\n",
    "        # Run the prover and verifier on the inputs to get the hidden representations\n",
    "        out_prover = self.prover_body(input_prover)\n",
    "        out_verifier = self.verifier_body(input_verifier)\n",
    "\n",
    "        # Combine the representations of the two agents\n",
    "        node_level_repr = torch.zeros(\n",
    "            batch_size,\n",
    "            *out_prover[\"node_level_repr\"].shape[1:],\n",
    "            dtype=out_prover[\"node_level_repr\"].dtype,\n",
    "            device=out_prover[\"node_level_repr\"].device,\n",
    "        )\n",
    "        node_level_repr[prover_turn] = out_prover[\"node_level_repr\"]\n",
    "        node_level_repr[~prover_turn] = out_verifier[\"node_level_repr\"]\n",
    "        graph_level_repr = torch.zeros(\n",
    "            batch_size,\n",
    "            *out_prover[\"graph_level_repr\"].shape[1:],\n",
    "            dtype=out_prover[\"graph_level_repr\"].dtype,\n",
    "            device=out_prover[\"graph_level_repr\"].device,\n",
    "        )\n",
    "        graph_level_repr[prover_turn] = out_prover[\"graph_level_repr\"]\n",
    "        graph_level_repr[~prover_turn] = out_verifier[\"graph_level_repr\"]\n",
    "\n",
    "        return tensordict.update(\n",
    "            dict(node_level_repr=node_level_repr, graph_level_repr=graph_level_repr)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedPolicyHead(TensorDictModuleBase):\n",
    "    in_keys = (\"round\", \"node_level_repr\", \"graph_level_repr\")\n",
    "    out_keys = ((\"agents\", \"node_selected_logits\"), (\"agents\", \"decision_logits\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_policy_head: GraphIsomorphismAgentPolicyHead,\n",
    "        verifier_policy_head: GraphIsomorphismAgentPolicyHead,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prover_policy_head = prover_policy_head\n",
    "        self.verifier_policy_head = verifier_policy_head\n",
    "\n",
    "    def forward(self, tensordict: TensorDictBase) -> TensorDict:\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "        batch_size = round.shape[0]\n",
    "\n",
    "        # Compute the index of the agent whose turn it is\n",
    "        prover_turn: Int[Tensor, \"batch\"] = (round % 2 == 1)\n",
    "\n",
    "        # Build tensordicts to feed to each agent when it's their turn\n",
    "        input_prover = TensorDict(\n",
    "            {\n",
    "                key: tensordict[key][prover_turn]\n",
    "                for key in self.prover_policy_head.in_keys\n",
    "            },\n",
    "            batch_size=(prover_turn.sum().item()),\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            {\n",
    "                key: tensordict[key][~prover_turn]\n",
    "                for key in self.verifier_policy_head.in_keys\n",
    "            },\n",
    "            batch_size=((~prover_turn).sum().item()),\n",
    "        )\n",
    "\n",
    "        # Run the policy heads to obtain the probability distributions\n",
    "        out_prover = self.prover_policy_head(input_prover)\n",
    "        out_verifier = self.verifier_policy_head(input_verifier)\n",
    "\n",
    "        # The combined action distribution logits of the two agents, which defaults to\n",
    "        # zeros\n",
    "        node_selected_logits = torch.zeros(\n",
    "            batch_size,\n",
    "            2,\n",
    "            *out_prover[\"node_selected_logits\"].shape[1:],\n",
    "            dtype=out_prover[\"node_selected_logits\"].dtype,\n",
    "            device=out_prover.device,\n",
    "        )\n",
    "        decision_logits = torch.zeros(\n",
    "            batch_size,\n",
    "            2,\n",
    "            *out_verifier[\"decision_logits\"].shape[1:],\n",
    "            dtype=out_verifier[\"decision_logits\"].dtype,\n",
    "            device=out_verifier.device,\n",
    "        )\n",
    "\n",
    "        # Inset the agents' action distributions into the combined action distribution\n",
    "        # logits\n",
    "        node_selected_logits[prover_turn, PROVER_AGENT_NUM] = out_prover[\n",
    "            \"node_selected_logits\"\n",
    "        ]\n",
    "        node_selected_logits[~prover_turn, VERIFIER_AGENT_NUM] = out_verifier[\n",
    "            \"node_selected_logits\"\n",
    "        ]\n",
    "        decision_logits[~prover_turn, VERIFIER_AGENT_NUM] = out_verifier[\n",
    "            \"decision_logits\"\n",
    "        ]\n",
    "\n",
    "        return tensordict.update(\n",
    "            dict(\n",
    "                agents=TensorDict(\n",
    "                    dict(\n",
    "                        node_selected_logits=node_selected_logits,\n",
    "                        decision_logits=decision_logits,\n",
    "                    ),\n",
    "                    batch_size=tensordict.batch_size,\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedCriticHead(TensorDictModuleBase):\n",
    "    in_keys = (\"round\", \"node_level_repr\", \"graph_level_repr\")\n",
    "    out_keys = ((\"agents\", \"value\"), )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_critic_head: GraphIsomorphismAgentCriticHead,\n",
    "        verifier_critic_head: GraphIsomorphismAgentCriticHead,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prover_critic_head = prover_critic_head\n",
    "        self.verifier_critic_head = verifier_critic_head\n",
    "\n",
    "    def forward(self, tensordict: TensorDictBase) -> TensorDict:\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "        batch_size = round.shape[0]\n",
    "\n",
    "        # Compute the index of the agent whose turn it is\n",
    "        prover_turn: Int[Tensor, \"batch\"] = (round % 2 == 1)\n",
    "\n",
    "        # Build tensordicts to feed to each agent when it's their turn\n",
    "        input_prover = TensorDict(\n",
    "            {\n",
    "                key: tensordict[key][prover_turn]\n",
    "                for key in self.prover_critic_head.in_keys\n",
    "            },\n",
    "            batch_size=(prover_turn.sum().item()),\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            {\n",
    "                key: tensordict[key][~prover_turn]\n",
    "                for key in self.verifier_critic_head.in_keys\n",
    "            },\n",
    "            batch_size=((~prover_turn).sum().item()),\n",
    "        )\n",
    "\n",
    "        # Run the critic heads to obtain the probability distributions\n",
    "        out_prover = self.prover_critic_head(input_prover)\n",
    "        out_verifier = self.verifier_critic_head(input_verifier)\n",
    "\n",
    "        # # If we don't have a cached value, or if the batch size is different, initialise\n",
    "        # # a new one with zeros.\n",
    "        # if self.value_cache is None or self.value_cache.shape[0] != batch_size:\n",
    "        #     self.value_cache = torch.zeros(\n",
    "        #         batch_size,\n",
    "        #         2,\n",
    "        #         dtype=out_prover.dtype,\n",
    "        #         device=out_prover.device,\n",
    "        #     )\n",
    "\n",
    "        value = torch.zeros(\n",
    "            batch_size,\n",
    "            2,\n",
    "            dtype=out_prover[\"value\"].dtype,\n",
    "            device=out_prover.device,\n",
    "        )\n",
    "\n",
    "        # Inset the agents' values when it's their turn\n",
    "        value[prover_turn, PROVER_AGENT_NUM] = out_prover[\"value\"]\n",
    "        value[~prover_turn, VERIFIER_AGENT_NUM] = out_verifier[\"value\"]\n",
    "\n",
    "        return tensordict.update(\n",
    "            dict(\n",
    "                agents=TensorDict(\n",
    "                    dict(value=value),\n",
    "                    batch_size=tensordict.batch_size,\n",
    "                )\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeCategoricalDistribution(CompositeDistribution):\n",
    "    def __init__(self, **categorical_params):\n",
    "        batch_size = None\n",
    "        composite_params = {}\n",
    "        cat_param_kwargs_names = (\"logits\", \"probs\")\n",
    "        for name, param in categorical_params.items():\n",
    "            for kwarg_name in cat_param_kwargs_names:\n",
    "                if name.endswith(\"_\" + kwarg_name):\n",
    "                    composite_params[name[: -len(kwarg_name) - 1]] = {kwarg_name: param}\n",
    "\n",
    "                    # Make sure all the categorical parameters have the same batch size\n",
    "                    if batch_size is None:\n",
    "                        batch_size = param.shape[0]\n",
    "                    elif batch_size != param.shape[0]:\n",
    "                        raise ValueError(\n",
    "                            \"All categorical parameters must have the same batch size.\"\n",
    "                        )\n",
    "\n",
    "        composite_params_td = TensorDict(composite_params, batch_size=batch_size)\n",
    "\n",
    "        super().__init__(\n",
    "            params=composite_params_td,\n",
    "            distribution_map={key: Categorical for key in composite_params},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prover_body = GraphIsomorphismAgentBody(params, \"prover\", device=device)\n",
    "verifier_body = GraphIsomorphismAgentBody(params, \"verifier\", device=device)\n",
    "prover_policy_head = GraphIsomorphismAgentPolicyHead(params, \"prover\", device=device)\n",
    "verifier_policy_head = GraphIsomorphismAgentPolicyHead(\n",
    "    params, \"verifier\", device=device\n",
    ")\n",
    "prover_critic_head = GraphIsomorphismAgentCriticHead(params, \"prover\", device=device)\n",
    "verifier_critic_head = GraphIsomorphismAgentCriticHead(\n",
    "    params, \"verifier\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = GraphIsomorphismCombinedBody(prover_body, verifier_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_head = GraphIsomorphismCombinedPolicyHead(prover_policy_head, verifier_policy_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_prob_module = SafeProbabilisticModule(\n",
    "    spec=env.action_spec,\n",
    "    distribution_class=CompositeCategoricalDistribution,\n",
    "    in_keys=dict(\n",
    "        node_selected_logits=(\"agents\", \"node_selected_logits\"),\n",
    "        decision_logits=(\"agents\", \"decision_logits\"),\n",
    "    ),\n",
    "    out_keys=env.action_keys,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_head = GraphIsomorphismCombinedCriticHead(\n",
    "    prover_critic_head, verifier_critic_head\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = ActorCriticOperator(body, policy_head, critic_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision_logits: Tensor(shape=torch.Size([125, 2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                node_selected_logits: Tensor(shape=torch.Size([125, 2, 22]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([125]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        graph_level_repr: Tensor(shape=torch.Size([125, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        message: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        node_level_repr: Tensor(shape=torch.Size([125, 2, 11, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        round: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        x: Tensor(shape=torch.Size([125, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        y: Tensor(shape=torch.Size([125, 1]), device=cpu, dtype=torch.int32, is_shared=False)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.get_policy_operator()(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        message: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        round: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        x: Tensor(shape=torch.Size([125, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        y: Tensor(shape=torch.Size([125, 1]), device=cpu, dtype=torch.int32, is_shared=False)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision_logits: Tensor(shape=torch.Size([125, 2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                node_selected_logits: Tensor(shape=torch.Size([125, 2, 22]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                value: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([125]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        graph_level_repr: Tensor(shape=torch.Size([125, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        message: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        node_level_repr: Tensor(shape=torch.Size([125, 2, 11, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        round: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        x: Tensor(shape=torch.Size([125, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        y: Tensor(shape=torch.Size([125, 1]), device=cpu, dtype=torch.int32, is_shared=False)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.get_critic_operator()(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphIsomorphismCombinedPolicyHead(\n",
       "  (prover_policy_head): GraphIsomorphismAgentPolicyHead(\n",
       "    (node_selector): TensorDictModule(\n",
       "        module=Sequential(\n",
       "          (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): Rearrange('batch pair node d_out -> batch (pair node) d_out')\n",
       "        ),\n",
       "        device=cpu,\n",
       "        in_keys=['node_level_repr'],\n",
       "        out_keys=['node_selected_logits'])\n",
       "  )\n",
       "  (verifier_policy_head): GraphIsomorphismAgentPolicyHead(\n",
       "    (node_selector): TensorDictModule(\n",
       "        module=Sequential(\n",
       "          (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): Rearrange('batch pair node d_out -> batch (pair node) d_out')\n",
       "        ),\n",
       "        device=cpu,\n",
       "        in_keys=['node_level_repr'],\n",
       "        out_keys=['node_selected_logits'])\n",
       "    (decider): TensorDictModule(\n",
       "        module=Sequential(\n",
       "          (0): Rearrange('batch pair d_in -> batch (pair d_in)')\n",
       "          (1): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Linear(in_features=16, out_features=3, bias=True)\n",
       "        ),\n",
       "        device=cpu,\n",
       "        in_keys=['graph_level_repr'],\n",
       "        out_keys=['decision_logits'])\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = ProbabilisticTensorDictSequential(full_model, policy_head, policy_prob_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision_logits: Tensor(shape=torch.Size([125, 2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                node_selected_logits: Tensor(shape=torch.Size([125, 2, 22]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                value: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([125]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        decision: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        graph_level_repr: Tensor(shape=torch.Size([125, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        message: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        node_level_repr: Tensor(shape=torch.Size([125, 2, 11, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        node_selected: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        round: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([125]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        x: Tensor(shape=torch.Size([125, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        y: Tensor(shape=torch.Size([125, 1]), device=cpu, dtype=torch.int32, is_shared=False)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy(env.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReplayBuffer(storage=<torchrl.data.replay_buffers.storages.LazyTensorStorage object at 0x7f974327fed0>, sampler=<torchrl.data.replay_buffers.samplers.SamplerWithoutReplacement object at 0x7f974327e450>, writer=<torchrl.data.replay_buffers.writers.RoundRobinWriter object at 0x7f97749932d0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(\n",
    "        params.ppo.frames_per_batch, device=device\n",
    "    ),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=params.ppo.minibatch_size,\n",
    ")\n",
    "replay_buffer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvg-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
