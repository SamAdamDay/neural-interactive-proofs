{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph isomorphism PPO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_CPU = False\n",
    "\n",
    "SEED = 349287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch_geometric/typing.py:101: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/sam/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from tensordict.nn import (\n",
    "    TensorDictModule,\n",
    "    TensorDictModuleBase,\n",
    "    TensorDictSequential,\n",
    "    ProbabilisticTensorDictSequential,\n",
    ")\n",
    "from tensordict.nn.distributions import CompositeDistribution\n",
    "from tensordict.tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import InteractionType\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.data.tensor_specs import (\n",
    "    CompositeSpec,\n",
    "    DiscreteTensorSpec,\n",
    "    BinaryDiscreteTensorSpec,\n",
    "    MultiDiscreteTensorSpec,\n",
    "    TensorSpec,\n",
    "    UnboundedContinuousTensorSpec,\n",
    "    Box,\n",
    ")\n",
    "from torchrl.envs import EnvBase\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from torchrl.modules import ProbabilisticActor, ActorValueOperator\n",
    "from torchrl.objectives import ValueEstimators\n",
    "\n",
    "from torch_geometric.loader import DataLoader as GeometricDataLoader\n",
    "from torch_geometric.data import Batch as GeometricBatch, Data as GeometricData\n",
    "\n",
    "from jaxtyping import Float, Int, Bool\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pvg.graph_isomorphism import (\n",
    "    GraphIsomorphismAgentBody,\n",
    "    GraphIsomorphismAgentPolicyHead,\n",
    "    GraphIsomorphismAgentValueHead,\n",
    ")\n",
    "from pvg.parameters import Parameters\n",
    "from pvg.graph_isomorphism.data import GraphIsomorphismData, GraphIsomorphismDataset\n",
    "from pvg.utils.data import gi_data_to_tensordict\n",
    "from pvg.utils.torchrl_objectives import ClipPPOLossMultipleActions\n",
    "from pvg.constants import VERIFIER_AGENT_NUM, PROVER_AGENT_NUM\n",
    "from pvg.utils.types import TorchDevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch_generator = torch.Generator().manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if not FORCE_CPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters(\n",
    "    scenario=\"graph_isomorphism\",\n",
    "    trainer=\"ppo\",\n",
    "    dataset=\"eru10000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixBox(Box):\n",
    "    \"\"\"An abstract representation of the space of adjacency matrices.\"\"\"\n",
    "\n",
    "    def __init__(self, max_num_nodes: int):\n",
    "        self.max_num_nodes = max_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixSpec(TensorSpec):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_num_nodes: int,\n",
    "        shape: torch.Size | None = None,\n",
    "        device: Optional[TorchDevice] = None,\n",
    "        dtype: str | torch.dtype = torch.int32,\n",
    "    ):\n",
    "        self.max_num_nodes = max_num_nodes\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        if shape is None:\n",
    "            self.shape = torch.Size([max_num_nodes, max_num_nodes])\n",
    "        else:\n",
    "            if shape[-2:] != (max_num_nodes, max_num_nodes):\n",
    "                raise ValueError(\n",
    "                    f\"The last two dimensions of the shape must be {max_num_nodes}. \"\n",
    "                    f\"Got {shape[-2:]}.\"\n",
    "                )\n",
    "            self.shape = torch.Size(shape)\n",
    "\n",
    "        self.space = AdjacencyMatrixBox(max_num_nodes)\n",
    "\n",
    "    def is_in(self, val: torch.Tensor) -> bool:\n",
    "        \"\"\"Check if a value is a valid adjacency matrix.\"\"\"\n",
    "\n",
    "        # Basic type checks\n",
    "        if not isinstance(val, torch.Tensor):\n",
    "            return False\n",
    "        if val.shape[-2:] != (self.max_num_nodes, self.max_num_nodes):\n",
    "            return False\n",
    "        if val.dtype != self.dtype:\n",
    "            return False\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        if not torch.all(torch.isin(val, torch.tensor([0, 1], device=self.device))):\n",
    "            return False\n",
    "\n",
    "        # Make sure the matrix is symmetric\n",
    "        if not torch.all(val.transpose(-1, -2) == val):\n",
    "            return False\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        if not torch.all(torch.isin(torch.diagonal(val, dim1=-2, dim2=-1), 0)):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def rand(self, shape: Optional[list[int] | torch.Size] = None) -> torch.Tensor:\n",
    "        \"\"\"Generate a random 1/2 Erdos-Renyi adjacency matrix.\"\"\"\n",
    "\n",
    "        if shape is None:\n",
    "            shape = shape = torch.Size([])\n",
    "\n",
    "        adjacency_values = torch.rand(*shape, *self.shape, device=device)\n",
    "        adjacency = (adjacency_values < 0.5).to(self.dtype)\n",
    "        adjacency = adjacency.triu(diagonal=1)\n",
    "        adjacency += adjacency.transpose(1, 2).clone()\n",
    "\n",
    "        return adjacency\n",
    "\n",
    "    def _project(self, val: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Project a value to the space of valid adjacency matrices.\"\"\"\n",
    "\n",
    "        # Symmetrize the matrix\n",
    "        val = (val + val.transpose(1, 2)) / 2\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        val[..., torch.arange(self.max_num_nodes), torch.arange(self.max_num_nodes)] = 0\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        return torch.clamp(torch.round(val), min=0, max=1).to(self.dtype)\n",
    "    \n",
    "    def to(self, dest: torch.dtype | torch.device | str | int) -> TensorSpec:\n",
    "        if isinstance(dest, torch.dtype):\n",
    "            self.dtype = dest\n",
    "        elif isinstance(dest, (torch.device, str, int)):\n",
    "            self.device = dest\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid destination {dest}\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable batch-size data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forgetful_cycle(iterable):\n",
    "    \"\"\"A version of cycle that doesn't save copies of the values\"\"\"\n",
    "    while True:\n",
    "        for i in iterable:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableGeometricDataCycler:\n",
    "    \"\"\"A loader that cycles through geometric data, but allows the batch size to vary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader : GeometricDataLoader\n",
    "        The base dataloader to use. This dataloader will be cycled through.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataloader: GeometricDataLoader):\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader_iter = iter(forgetful_cycle(self.dataloader))\n",
    "        self.remainder: Optional[list] = None\n",
    "\n",
    "    def get_batch(self, batch_size: int) -> GeometricBatch:\n",
    "        \"\"\"Get a batch of data from the dataloader with the given batch size.\n",
    "\n",
    "        If the dataloader is exhausted, it will be reset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            The size of the batch to return.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        batch : Tensor\n",
    "            A batch of data with the given batch size.\n",
    "        \"\"\"\n",
    "\n",
    "        left_to_sample = batch_size\n",
    "        batch_components = []\n",
    "\n",
    "        # Start by sampling from the remainder from the previous sampling\n",
    "        if self.remainder is not None:\n",
    "            batch_components.extend(self.remainder[:left_to_sample])\n",
    "            if len(self.remainder) <= left_to_sample:\n",
    "                left_to_sample -= len(self.remainder)\n",
    "                self.remainder = None\n",
    "            else:\n",
    "                self.remainder = self.remainder[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Keep sampling batches until we have enough\n",
    "        while left_to_sample > 0:\n",
    "            batch = next(self.dataloader_iter)\n",
    "            batch_components.extend(batch[:left_to_sample])\n",
    "            if len(batch) <= left_to_sample:\n",
    "                left_to_sample -= len(batch)\n",
    "            else:\n",
    "                self.remainder = batch[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Concatenate the batch components into a single batch\n",
    "        batch = GeometricBatch.from_data_list(\n",
    "            batch_components, follow_batch=self.dataloader.follow_batch\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.dataloader!r})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismEnv(EnvBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: Parameters,\n",
    "        device: TorchDevice = device,\n",
    "        int_dtype: torch.dtype = torch.int,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.params = params\n",
    "        self.int_dtype = int_dtype\n",
    "\n",
    "        # Create a random number generator\n",
    "        self.rng = torch.Generator(device=device)\n",
    "\n",
    "        # Load the dataset\n",
    "        self.dataset = GraphIsomorphismDataset(params)\n",
    "        self.data_cycler: Optional[VariableGeometricDataCycler] = None\n",
    "\n",
    "        # Compute the maximum number of nodes in the dataset\n",
    "        self.max_num_nodes = 0\n",
    "        for data in self.dataset:\n",
    "            self.max_num_nodes = max(\n",
    "                self.max_num_nodes, data.x_a.shape[0], data.x_b.shape[0]\n",
    "            )\n",
    "\n",
    "        # The number of environments is the number of episodes we can fit in a batch\n",
    "        self.num_envs = params.ppo.frames_per_batch // params.max_message_rounds\n",
    "        self.batch_size = (self.num_envs,)\n",
    "\n",
    "        # The spec for the observation space: agents see the adjacency matrix and the\n",
    "        # messages sent so far. The \"message\" field contains the most recent message.\n",
    "        self.observation_spec = CompositeSpec(\n",
    "            adjacency=AdjacencyMatrixSpec(\n",
    "                self.max_num_nodes,\n",
    "                shape=(self.num_envs, 2, self.max_num_nodes, self.max_num_nodes),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            x=BinaryDiscreteTensorSpec(\n",
    "                params.max_message_rounds,\n",
    "                shape=(\n",
    "                    self.num_envs,\n",
    "                    2,\n",
    "                    self.max_num_nodes,\n",
    "                    params.max_message_rounds,\n",
    "                ),\n",
    "                dtype=torch.float,\n",
    "            ),\n",
    "            node_mask=BinaryDiscreteTensorSpec(\n",
    "                self.max_num_nodes,\n",
    "                shape=(\n",
    "                    self.num_envs,\n",
    "                    2,\n",
    "                    self.max_num_nodes,\n",
    "                ),\n",
    "                dtype=torch.bool,\n",
    "            ),\n",
    "            message=DiscreteTensorSpec(\n",
    "                2 * self.max_num_nodes,\n",
    "                shape=(self.num_envs,),\n",
    "                dtype=torch.long,\n",
    "            ),\n",
    "            round=DiscreteTensorSpec(\n",
    "                params.max_message_rounds,\n",
    "                shape=(self.num_envs,),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "        # The spec for the state space: the true label and the round number\n",
    "        self.state_spec = CompositeSpec(\n",
    "            y=BinaryDiscreteTensorSpec(\n",
    "                1,\n",
    "                shape=(self.num_envs, 1),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "        # Each action space has shape (batch_size, num_agents). Each agent chooses both\n",
    "        # a node and a decision: reject, accept or continue (represented as 0, 1 or 2).\n",
    "        # The node is is a number between 0 and 2 * max_num_nodes - 1. If it is less\n",
    "        # than max_num_nodes, it is a node in the first graph, otherwise it is a node in\n",
    "        # the second graph. The verifier is agent 0 and the prover is agent 1.\n",
    "        self.action_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                node_selected=DiscreteTensorSpec(\n",
    "                    2 * self.max_num_nodes,\n",
    "                    shape=(self.num_envs, 2),\n",
    "                    dtype=self.int_dtype,\n",
    "                ),\n",
    "                decision=DiscreteTensorSpec(\n",
    "                    3,\n",
    "                    shape=(self.num_envs, 2),\n",
    "                    dtype=self.int_dtype,\n",
    "                ),\n",
    "                shape=(self.num_envs,),\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "        self.reward_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                reward=UnboundedContinuousTensorSpec(shape=(self.num_envs, 2)),\n",
    "                shape=(self.num_envs,),\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "        self.done_spec = CompositeSpec(\n",
    "            done=BinaryDiscreteTensorSpec(\n",
    "                self.num_envs, shape=(self.num_envs,), dtype=torch.bool\n",
    "            ),\n",
    "            shape=(self.num_envs,),\n",
    "        )\n",
    "\n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        \"\"\"Perform a step in the environment.\"\"\"\n",
    "\n",
    "        # Extract the tensors from the dict\n",
    "        y: Int[Tensor, \"batch\"] = tensordict[\"y\"]\n",
    "        x: Float[Tensor, \"batch graph node message_round\"] = tensordict[\"x\"]\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "        node_selected: Int[Tensor, \"batch agent\"] = tensordict[\n",
    "            \"agents\", \"node_selected\"\n",
    "        ]\n",
    "        decision: Int[Tensor, \"batch agent\"] = tensordict[\"agents\", \"decision\"]\n",
    "        done: Bool[Tensor, \"batch\"] = tensordict[\"done\"]\n",
    "\n",
    "        # Compute index of the agent whose turn it is. The prover goes first.\n",
    "        agent_index: Int[Tensor, \"batch\"] = (round % 2)\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            agent_index = 1 - agent_index\n",
    "\n",
    "        # Determine which graph contains the selected node and which node it is there\n",
    "        # (batch agent)\n",
    "        which_graph = node_selected >= self.max_num_nodes\n",
    "        # (batch agent)\n",
    "        graph_node = torch.where(\n",
    "            which_graph, node_selected - self.max_num_nodes, node_selected\n",
    "        )\n",
    "\n",
    "        # Write the node selected by the agent whose turn it is as a (one-hot) message\n",
    "        x[\n",
    "            torch.arange(x.shape[0]),\n",
    "            which_graph[torch.arange(which_graph.shape[0]), agent_index].int(),\n",
    "            graph_node[torch.arange(which_graph.shape[0]), agent_index],\n",
    "            round,\n",
    "        ] = 1\n",
    "\n",
    "        # Set the node selected by the agent whose turn it is as the message\n",
    "        message = node_selected[\n",
    "            torch.arange(node_selected.shape[0]), agent_index\n",
    "        ].long()\n",
    "\n",
    "        # If the verifier has made a guess, compute the reward and terminate the episode\n",
    "        verifier_decision_made = (agent_index == VERIFIER_AGENT_NUM) & (\n",
    "            decision[:, VERIFIER_AGENT_NUM] != 2\n",
    "        )\n",
    "        done = done | verifier_decision_made\n",
    "        reward_verifier = (\n",
    "            verifier_decision_made & (decision[:, VERIFIER_AGENT_NUM] == y.squeeze())\n",
    "        ).float()\n",
    "        reward_verifier = reward_verifier * self.params.verifier_reward\n",
    "        reward_prover = (\n",
    "            verifier_decision_made & (decision[:, VERIFIER_AGENT_NUM] == 1)\n",
    "        ).float()\n",
    "        reward_prover = reward_prover * self.params.prover_reward\n",
    "\n",
    "        # If we reach the end of the episode and the verifier has not made a guess,\n",
    "        # terminate it with a negative reward for the verifier\n",
    "        done = done | (round >= self.params.max_message_rounds - 1)\n",
    "        reward_verifier[\n",
    "            (round >= self.params.max_message_rounds - 1) & ~verifier_decision_made\n",
    "        ] = self.params.verifier_terminated_penalty\n",
    "\n",
    "        # Stack the rewards for the two agents\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            reward = torch.stack([reward_verifier, reward_prover], dim=-1)\n",
    "        else:\n",
    "            reward = torch.stack([reward_prover, reward_verifier], dim=-1)\n",
    "\n",
    "        # Put everything together\n",
    "        next = TensorDict(\n",
    "            dict(\n",
    "                adjacency=tensordict[\"adjacency\"],\n",
    "                x=x,\n",
    "                node_mask=tensordict[\"node_mask\"],\n",
    "                message=message,\n",
    "                round=round + 1,\n",
    "                done=done,\n",
    "                agents=TensorDict(dict(reward=reward), batch_size=self.batch_size),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        return next\n",
    "\n",
    "    def _reset(self, tensordict: Optional[TensorDictBase] = None) -> TensorDictBase:\n",
    "        \"\"\"(Partially) reset the environment.\n",
    "\n",
    "        For each episode which is done, takes a new sample from the dataset and resets\n",
    "        the episode.\n",
    "        \"\"\"\n",
    "\n",
    "        # If no tensordict is given, we're starting afresh\n",
    "        if tensordict is None:\n",
    "            tensordict = TensorDict(\n",
    "                dict(\n",
    "                    adjacency=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.max_num_nodes,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    x=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.params.max_message_rounds,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.float,\n",
    "                    ),\n",
    "                    node_mask=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.bool,\n",
    "                    ),\n",
    "                    message=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.long,\n",
    "                    ),\n",
    "                    y=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        1,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    round=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    done=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.bool,\n",
    "                    ),\n",
    "                ),\n",
    "                batch_size=self.batch_size,\n",
    "            )\n",
    "\n",
    "            new_mask = torch.ones(\n",
    "                *self.batch_size, dtype=torch.bool, device=self.device\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            new_mask = tensordict[\"done\"]\n",
    "            tensordict = tensordict.clone()\n",
    "\n",
    "        # If we don't have a data cycler yet, create one\n",
    "        if self.data_cycler is None:\n",
    "            dataloader = GeometricDataLoader(\n",
    "                self.dataset,\n",
    "                batch_size=self.num_envs,\n",
    "                follow_batch=[\"x_a\", \"x_b\"],\n",
    "                shuffle=True,\n",
    "                generator=self.rng,\n",
    "            )\n",
    "            self.data_cycler = VariableGeometricDataCycler(dataloader)\n",
    "\n",
    "        # Sample a new batch of data for the episodes that are done\n",
    "        batch = self.data_cycler.get_batch(new_mask.sum().item())\n",
    "        batch_tensordict = gi_data_to_tensordict(\n",
    "            batch, node_dim_size=self.max_num_nodes\n",
    "        )\n",
    "        batch = batch.to(self.device)\n",
    "        batch_tensordict = batch_tensordict.to(self.device)\n",
    "\n",
    "        # Copy the new data into the output\n",
    "        tensordict[\"adjacency\"][new_mask] = batch_tensordict[\"adjacency\"]\n",
    "        tensordict[\"x\"][new_mask] = torch.zeros_like(tensordict[\"x\"][new_mask])\n",
    "        tensordict[\"node_mask\"][new_mask] = batch_tensordict[\"node_mask\"]\n",
    "        tensordict[\"message\"][new_mask] = 0\n",
    "        tensordict[\"y\"][new_mask] = (batch.wl_score == -1).int().unsqueeze(-1)\n",
    "        tensordict[\"round\"][new_mask] = 0\n",
    "        tensordict[\"done\"][new_mask] = False\n",
    "\n",
    "        return tensordict\n",
    "\n",
    "    def _set_seed(self, seed: int | None):\n",
    "        self.rng = torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphIsomorphismEnv(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] y: 0 P: (10)  0.0 V: (13,   0)  0.0  | [0] y: 1 P: (11)  0.0 V: (15,   1)  0.0 \n",
      "[1] y: 0 P: (20)  0.0 V: (13,   2)  0.0  | [1] y: 1 P: ( 2)  0.0 V: ( 5,   0)  0.0 \n",
      "[2] y: 0 P: (10)  0.0 V: (14,   1)  0.0  | [0] y: 0 P: (13)  0.0 V: (11,   0)  0.0 \n",
      "[3] y: 0 P: (20)  0.0 V: ( 8,   2)  0.0  | [1] y: 0 P: (10)  0.0 V: (15,   0)  1.0 \n",
      "[4] y: 0 P: (10)  0.0 V: (10,   1)  0.0  | [0] y: 0 P: ( 1)  0.0 V: (14,   0)  0.0 \n",
      "[5] y: 0 P: (11)  0.0 V: ( 4,   0)  1.0  | [1] y: 0 P: (13)  0.0 V: (20,   0)  1.0 \n",
      "[0] y: 1 P: ( 0)  0.0 V: (12,   1)  0.0  | [0] y: 1 P: (19)  0.0 V: ( 2,   1)  0.0 \n",
      "[1] y: 1 P: ( 1)  0.0 V: ( 9,   0)  0.0  | [1] y: 1 P: ( 1)  1.0 V: (10,   1)  1.0 \n",
      "[0] y: 1 P: ( 4)  0.0 V: ( 3,   2)  0.0  | [0] y: 1 P: (10)  0.0 V: ( 1,   0)  0.0 \n",
      "[1] y: 1 P: (10)  1.0 V: ( 7,   1)  1.0  | [1] y: 1 P: (11)  0.0 V: ( 6,   2)  0.0 \n",
      "[0] y: 0 P: (17)  0.0 V: (20,   1)  0.0  | [2] y: 1 P: (10)  0.0 V: (20,   1)  0.0 \n",
      "[1] y: 0 P: (20)  0.0 V: (21,   0)  1.0  | [3] y: 1 P: (20)  0.0 V: ( 5,   0)  0.0 \n",
      "[0] y: 0 P: ( 6)  0.0 V: ( 7,   0)  0.0  | [0] y: 1 P: (20)  0.0 V: ( 2,   1)  0.0 \n",
      "[1] y: 0 P: ( 1)  0.0 V: (21,   0)  1.0  | [1] y: 1 P: (10)  1.0 V: ( 9,   1)  1.0 \n",
      "[0] y: 0 P: (15)  0.0 V: (19,   1)  0.0  | [0] y: 1 P: (19)  0.0 V: ( 6,   1)  0.0 \n",
      "[1] y: 0 P: (11)  1.0 V: ( 4,   1)  0.0  | [1] y: 1 P: ( 5)  0.0 V: ( 6,   2)  0.0 \n",
      "[0] y: 0 P: ( 6)  0.0 V: ( 4,   2)  0.0  | [2] y: 1 P: ( 3)  0.0 V: (14,   0)  0.0 \n",
      "[1] y: 0 P: ( 8)  0.0 V: ( 3,   0)  1.0  | [3] y: 1 P: ( 0)  1.0 V: (19,   1)  1.0 \n",
      "[0] y: 0 P: ( 3)  0.0 V: ( 2,   0)  0.0  | [0] y: 0 P: ( 5)  0.0 V: (17,   2)  0.0 \n",
      "[1] y: 0 P: (14)  0.0 V: (15,   0)  1.0  | [1] y: 0 P: ( 5)  1.0 V: (10,   1)  0.0 \n",
      "[0] y: 0 P: ( 0)  0.0 V: (17,   2)  0.0  | [0] y: 1 P: ( 8)  0.0 V: ( 1,   1)  0.0 \n",
      "[1] y: 0 P: ( 2)  0.0 V: (11,   2)  0.0  | [1] y: 1 P: (13)  0.0 V: (18,   2)  0.0 \n",
      "[2] y: 0 P: ( 0)  0.0 V: ( 8,   1)  0.0  | [2] y: 1 P: ( 2)  0.0 V: (12,   1)  0.0 \n",
      "[3] y: 0 P: ( 6)  0.0 V: (21,   0)  1.0  | [3] y: 1 P: ( 2)  0.0 V: ( 2,   0)  0.0 \n",
      "[0] y: 0 P: ( 3)  0.0 V: ( 1,   2)  0.0  | [0] y: 0 P: ( 4)  0.0 V: (18,   1)  0.0 \n",
      "[1] y: 0 P: ( 9)  1.0 V: (20,   1)  0.0  | [1] y: 0 P: (16)  0.0 V: ( 5,   0)  1.0 \n",
      "[0] y: 0 P: ( 2)  0.0 V: (21,   1)  0.0  | [0] y: 1 P: ( 9)  0.0 V: (18,   0)  0.0 \n",
      "[1] y: 0 P: ( 5)  0.0 V: ( 4,   0)  1.0  | [1] y: 1 P: ( 6)  1.0 V: (18,   1)  1.0 \n",
      "[0] y: 1 P: (14)  0.0 V: (19,   2)  0.0  | [0] y: 0 P: ( 4)  0.0 V: (19,   0)  0.0 \n",
      "[1] y: 1 P: (16)  0.0 V: ( 4,   0)  0.0  | [1] y: 0 P: (20)  1.0 V: ( 6,   1)  0.0 \n",
      "[0] y: 0 P: ( 5)  0.0 V: ( 0,   1)  0.0  | [0] y: 1 P: (13)  0.0 V: ( 7,   2)  0.0 \n",
      "[1] y: 0 P: (12)  1.0 V: ( 1,   1)  0.0  | [1] y: 1 P: ( 1)  0.0 V: ( 9,   2)  0.0 \n",
      "[0] y: 1 P: ( 6)  0.0 V: (17,   2)  0.0  | [2] y: 1 P: ( 2)  0.0 V: (16,   0)  0.0 \n",
      "[1] y: 1 P: (14)  1.0 V: ( 9,   1)  1.0  | [3] y: 1 P: (19)  1.0 V: (17,   1)  1.0 \n",
      "[0] y: 0 P: ( 3)  0.0 V: ( 9,   1)  0.0  | [0] y: 0 P: ( 4)  0.0 V: ( 2,   0)  0.0 \n",
      "[1] y: 0 P: (17)  0.0 V: ( 0,   2)  0.0  | [1] y: 0 P: ( 1)  0.0 V: (21,   0)  1.0 \n",
      "[2] y: 0 P: (11)  0.0 V: (17,   1)  0.0  | [0] y: 1 P: ( 1)  0.0 V: (21,   1)  0.0 \n",
      "[3] y: 0 P: (12)  0.0 V: ( 8,   2)  0.0  | [1] y: 1 P: ( 8)  1.0 V: (19,   1)  1.0 \n",
      "[4] y: 0 P: (14)  0.0 V: (11,   2)  0.0  | [0] y: 1 P: (11)  0.0 V: ( 5,   1)  0.0 \n"
     ]
    }
   ],
   "source": [
    "def printer(env, tensordict):\n",
    "    to_print = []\n",
    "    for i in range(2):\n",
    "        to_print.append(\n",
    "            f\"[{tensordict['round'][i].item()}] \"\n",
    "            f\"y: {tensordict['y'][i].item()} \"\n",
    "            f\"P: ({tensordict['agents', 'node_selected'][i, PROVER_AGENT_NUM].item():>2}) \"\n",
    "            f\" {tensordict['next', 'agents', 'reward'][i, PROVER_AGENT_NUM].item():>2} \"\n",
    "            f\"V: ({tensordict['agents', 'node_selected'][i, VERIFIER_AGENT_NUM].item():>2}, \"\n",
    "            f\" {tensordict['agents', 'decision'][i, VERIFIER_AGENT_NUM].item():>2}) \"\n",
    "            f\" {tensordict['next', 'agents', 'reward'][i, VERIFIER_AGENT_NUM].item():>2} \"\n",
    "        )\n",
    "    print(\" | \".join(to_print))\n",
    "    # print(tensordict[\"message\"][:2, ..., :3].transpose(-1, -2))\n",
    "    # print(tensordict[\"message\"][:2, ..., :3])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = env.rollout(\n",
    "        max_steps=40,\n",
    "        callback=printer,\n",
    "        auto_cast_to_device=True,\n",
    "        break_when_any_done=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 40, 2, 11, 11]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision: Tensor(shape=torch.Size([125, 40, 2]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "                node_selected: Tensor(shape=torch.Size([125, 40, 2]), device=cuda:0, dtype=torch.int32, is_shared=True)},\n",
       "            batch_size=torch.Size([125, 40]),\n",
       "            device=cuda,\n",
       "            is_shared=True),\n",
       "        done: Tensor(shape=torch.Size([125, 40]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        message: Tensor(shape=torch.Size([125, 40]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                adjacency: Tensor(shape=torch.Size([125, 40, 2, 11, 11]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        reward: Tensor(shape=torch.Size([125, 40, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "                    batch_size=torch.Size([125, 40]),\n",
       "                    device=cuda,\n",
       "                    is_shared=True),\n",
       "                done: Tensor(shape=torch.Size([125, 40]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                message: Tensor(shape=torch.Size([125, 40]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                node_mask: Tensor(shape=torch.Size([125, 40, 2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                round: Tensor(shape=torch.Size([125, 40]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "                terminated: Tensor(shape=torch.Size([125, 40]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                x: Tensor(shape=torch.Size([125, 40, 2, 11, 8]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "            batch_size=torch.Size([125, 40]),\n",
       "            device=cuda,\n",
       "            is_shared=True),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 40, 2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        round: Tensor(shape=torch.Size([125, 40]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        terminated: Tensor(shape=torch.Size([125, 40]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        x: Tensor(shape=torch.Size([125, 40, 2, 11, 8]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        y: Tensor(shape=torch.Size([125, 40, 1]), device=cuda:0, dtype=torch.int32, is_shared=True)},\n",
       "    batch_size=torch.Size([125, 40]),\n",
       "    device=cuda,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy and critic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedBody(TensorDictModuleBase):\n",
    "    in_keys = (\"round\", \"x\", \"adjacency\", \"message\", \"node_mask\")\n",
    "    out_keys = (\"round\", (\"agents\", \"node_level_repr\"), (\"agents\", \"graph_level_repr\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_body: GraphIsomorphismAgentBody,\n",
    "        verifier_body: GraphIsomorphismAgentBody,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.prover_body = prover_body\n",
    "        self.verifier_body = verifier_body\n",
    "\n",
    "    def forward(self, data: TensorDictBase) -> TensorDict:\n",
    "        round: Int[Tensor, \"batch\"] = data[\"round\"]\n",
    "\n",
    "        # Build tensordicts to feed to each agent when it's their turn\n",
    "        input_prover_dict = {}\n",
    "        input_verifier_dict = {}\n",
    "        for key in self.prover_body.in_keys:\n",
    "            if key == \"ignore_message\":\n",
    "                input_prover_dict[key] = torch.zeros_like(round, dtype=torch.bool)\n",
    "                input_verifier_dict[key] = round == 0\n",
    "            else:\n",
    "                input_prover_dict[key] = data[key]\n",
    "                input_verifier_dict[key] = data[key]\n",
    "        input_prover = TensorDict(\n",
    "            input_prover_dict,\n",
    "            batch_size=data.batch_size,\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            input_verifier_dict,\n",
    "            batch_size=data.batch_size,\n",
    "        )\n",
    "\n",
    "        # Run the prover and verifier bodies\n",
    "        output_prover = self.prover_body(input_prover)\n",
    "        output_verifier = self.verifier_body(input_verifier)\n",
    "\n",
    "        # Stack the outputs\n",
    "        node_level_repr = torch.stack(\n",
    "            [output_prover[\"node_level_repr\"], output_verifier[\"node_level_repr\"]],\n",
    "            dim=-3,\n",
    "        )\n",
    "        graph_level_repr = torch.stack(\n",
    "            [output_prover[\"graph_level_repr\"], output_verifier[\"graph_level_repr\"]],\n",
    "            dim=-2,\n",
    "        )\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            node_level_repr = node_level_repr.flip(-3)\n",
    "            graph_level_repr = graph_level_repr.flip(-2)\n",
    "\n",
    "        return data.update(\n",
    "            dict(\n",
    "                agents=dict(\n",
    "                    node_level_repr=node_level_repr,\n",
    "                    graph_level_repr=graph_level_repr,\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedPolicyHead(TensorDictModuleBase):\n",
    "    in_keys = ((\"agents\", \"node_level_repr\"), (\"agents\", \"graph_level_repr\"))\n",
    "    out_keys = ((\"agents\", \"node_selected_logits\"), (\"agents\", \"decision_logits\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_policy_head: GraphIsomorphismAgentPolicyHead,\n",
    "        verifier_policy_head: GraphIsomorphismAgentPolicyHead,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prover_policy_head = prover_policy_head\n",
    "        self.verifier_policy_head = verifier_policy_head\n",
    "\n",
    "    def forward(self, head_output: TensorDictBase) -> TensorDict:\n",
    "        \"\"\"Run the prover and verifier policy heads and combine their outputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensordict : TensorDictBase\n",
    "            The input to the value heads. Should contain the keys:\n",
    "\n",
    "            - (\"agents\", \"node_level_repr\"): The node-level representation from the\n",
    "              body.\n",
    "            - (\"agents\", \"graph_level_repr\"): The node-level representation from the\n",
    "              body.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tensordict: TensorDict\n",
    "            The tensordict update in place with the output of the value heads.\n",
    "        \"\"\"\n",
    "\n",
    "        # Run the policy heads to obtain the probability distributions\n",
    "        input_prover = TensorDict(\n",
    "            dict(\n",
    "                node_level_repr=head_output[\"agents\", \"node_level_repr\"][\n",
    "                    ..., PROVER_AGENT_NUM, :, :, :\n",
    "                ],\n",
    "                graph_level_repr=head_output[\"agents\", \"graph_level_repr\"][\n",
    "                    ..., PROVER_AGENT_NUM, :, :\n",
    "                ],\n",
    "            ),\n",
    "            batch_size=head_output.batch_size,\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            dict(\n",
    "                node_level_repr=head_output[\"agents\", \"node_level_repr\"][\n",
    "                    ..., VERIFIER_AGENT_NUM, :, :, :\n",
    "                ],\n",
    "                graph_level_repr=head_output[\"agents\", \"graph_level_repr\"][\n",
    "                    ..., VERIFIER_AGENT_NUM, :, :\n",
    "                ],\n",
    "            ),\n",
    "            batch_size=head_output.batch_size,\n",
    "        )\n",
    "        output_prover = self.prover_policy_head(input_prover)\n",
    "        output_verifier = self.verifier_policy_head(input_verifier)\n",
    "\n",
    "        # Stack the outputs\n",
    "        node_selected_logits = torch.stack(\n",
    "            [\n",
    "                output_prover[\"node_selected_logits\"],\n",
    "                output_verifier[\"node_selected_logits\"],\n",
    "            ],\n",
    "            dim=-2,\n",
    "        )\n",
    "        decision_logits = torch.stack(\n",
    "            [\n",
    "                torch.zeros_like(output_verifier[\"decision_logits\"]),\n",
    "                output_verifier[\"decision_logits\"],\n",
    "            ],\n",
    "            dim=-2,\n",
    "        )\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            node_selected_logits = node_selected_logits.flip(-2)\n",
    "            decision_logits = decision_logits.flip(-2)\n",
    "\n",
    "        return head_output.update(\n",
    "            dict(\n",
    "                agents=TensorDict(\n",
    "                    dict(\n",
    "                        node_selected_logits=node_selected_logits,\n",
    "                        decision_logits=decision_logits,\n",
    "                    ),\n",
    "                    batch_size=head_output.batch_size,\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedValueHead(TensorDictModuleBase):\n",
    "    in_keys = ((\"agents\", \"graph_level_repr\"),)\n",
    "    out_keys = ((\"agents\", \"value\"),)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_value_head: GraphIsomorphismAgentValueHead,\n",
    "        verifier_value_head: GraphIsomorphismAgentValueHead,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prover_value_head = prover_value_head\n",
    "        self.verifier_value_head = verifier_value_head\n",
    "\n",
    "    def forward(self, head_output: TensorDictBase) -> TensorDict:\n",
    "        \"\"\"Run the prover and verifier value heads and combine their values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensordict : TensorDictBase\n",
    "            The input to the value heads. Should contain the keys:\n",
    "\n",
    "            - (\"agents\", \"graph_level_repr\"): The node-level representation from the\n",
    "              body.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tensordict: TensorDict\n",
    "            The tensordict update in place with the output of the value heads.\n",
    "        \"\"\"\n",
    "\n",
    "        # Run the policy heads to obtain the value estimates\n",
    "        input_prover = TensorDict(\n",
    "            dict(\n",
    "                graph_level_repr=head_output[\"agents\", \"graph_level_repr\"][\n",
    "                    ..., PROVER_AGENT_NUM, :, :\n",
    "                ],\n",
    "            ),\n",
    "            batch_size=head_output.batch_size,\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            dict(\n",
    "                graph_level_repr=head_output[\"agents\", \"graph_level_repr\"][\n",
    "                    ..., VERIFIER_AGENT_NUM, :, :\n",
    "                ],\n",
    "            ),\n",
    "            batch_size=head_output.batch_size,\n",
    "        )\n",
    "        output_prover = self.prover_value_head(input_prover)\n",
    "        output_verifier = self.verifier_value_head(input_verifier)\n",
    "\n",
    "        # Stack the outputs\n",
    "        value = torch.stack(\n",
    "            [output_prover[\"value\"], output_verifier[\"value\"]],\n",
    "            dim=-1,\n",
    "        )\n",
    "        if PROVER_AGENT_NUM == 1:\n",
    "            value = value.flip(-2)\n",
    "\n",
    "        return head_output.update(\n",
    "            dict(\n",
    "                agents=TensorDict(\n",
    "                    dict(value=value),\n",
    "                    batch_size=head_output.batch_size,\n",
    "                )\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite categorical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeCategoricalDistribution(CompositeDistribution):\n",
    "    \"\"\"A composition of categorical distributions.\n",
    "\n",
    "    Allows specifying the parameters of the categorical distributions either as logits\n",
    "    or as probabilities.\n",
    "\n",
    "    The `log_prob` method is reimplemented with the following changes: \n",
    "    \n",
    "    - The log-probability can be stored in a different key (specified by the\n",
    "      \"log_prob_key\" parameter)\n",
    "    - It only computes stores the total log-probability, not the individual ones\n",
    "    - It doesn't reduce all non-batch dimensions in the log-probability\n",
    "    - It has a method to compute the entropy of the distribution\n",
    "\n",
    "    Parameter names must be strings ending in \"_logits\" or \"_probs\". However, the\n",
    "    suffix-stripped can be changed by passing a key transform function or a lookup\n",
    "    table. For example, to specify the parameters of a categorical distribution over key\n",
    "    `(\"agents\", \"action\")` using logits, you can pass the following:\n",
    "    \n",
    "    >>> CompositeCategoricalDistribution(\n",
    "    ...     action_logits=..., \n",
    "    ...     key_transform=lambda x: (\"agents\", x)\n",
    "    ... )\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    **categorical_params : dict[str, Tensor]\n",
    "        The parameters of the categorical distributions. Each key is the name of a\n",
    "        categorical parameter appended with \"_logits\" or \"_probs\" and each value is a\n",
    "        Tensor containing the logits or probabilities of the categorical distribution.\n",
    "    key_transform : callable[[str], [str | tuple[str]]] | dict[str, str | tuple[str]],\n",
    "    optional\n",
    "        A function that transforms the keys of the categorical parameters. If a dict is\n",
    "        given, it is used as a lookup table. If a callable is given, it is applied to\n",
    "        each key. Defaults to the identity function.\n",
    "    log_prob_key: NestedKey, default=\"sample_log_prob\"\n",
    "        The tensordict key to use for the log-probability of the sample.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Get the key transform\n",
    "        try:\n",
    "            key_transform = kwargs.pop(\"key_transform\")\n",
    "            if isinstance(key_transform, dict):\n",
    "                key_transform = lambda x: key_transform[x]\n",
    "            elif not callable(key_transform):\n",
    "                raise ValueError(\"key_transform must be a callable or a dict.\")\n",
    "        except KeyError:\n",
    "            key_transform = lambda x: x\n",
    "\n",
    "        # Get the log-probability key\n",
    "        self.log_prob_key = kwargs.pop(\"log_prob_key\", \"sample_log_prob\")\n",
    "\n",
    "        batch_size = None\n",
    "        composite_params = {}\n",
    "        name_suffixes = (\"logits\", \"probs\")\n",
    "        for name, param_value in kwargs.items():\n",
    "            for name_suffix in name_suffixes:\n",
    "                if name.endswith(\"_\" + name_suffix):\n",
    "                    # Set the parameters of the categorical distribution\n",
    "                    resolved_param_name = key_transform(name[: -len(name_suffix) - 1])\n",
    "                    composite_params[resolved_param_name] = {name_suffix: param_value}\n",
    "\n",
    "                    # Make sure all the categorical parameters have the same batch size\n",
    "                    if batch_size is None:\n",
    "                        batch_size = param_value.shape[0]\n",
    "                    elif batch_size != param_value.shape[0]:\n",
    "                        raise ValueError(\n",
    "                            \"All categorical parameters must have the same batch size.\"\n",
    "                        )\n",
    "\n",
    "        composite_params_td = TensorDict(composite_params, batch_size=batch_size)\n",
    "\n",
    "        super().__init__(\n",
    "            params=composite_params_td,\n",
    "            distribution_map={key: Categorical for key in composite_params},\n",
    "        )\n",
    "\n",
    "\n",
    "    def log_prob(self, sample: TensorDictBase) -> TensorDictBase:\n",
    "        \"\"\"Computes the log probability of a sample for the composite distribution\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        sample: TensorDictBase\n",
    "            A tensordict containing the sample\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        updated_sample: TensorDictBase\n",
    "            The sample tensordict updated with the log probability of the sample\n",
    "        \"\"\"\n",
    "        slp = 0.0\n",
    "        d = {}\n",
    "        for name, dist in self.dists.items():\n",
    "            slp += dist.log_prob(sample.get(name))\n",
    "        d[self.log_prob_key] = slp\n",
    "        sample.update(d)\n",
    "        return sample\n",
    "    \n",
    "    def entropy(self) -> float:\n",
    "        \"\"\"Computes the entropy of the composite distribution\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        entropy: float\n",
    "            The entropy of the composite distribution\n",
    "        \"\"\"\n",
    "        entropy = 0.0\n",
    "        for dist in self.dists.values():\n",
    "            entropy += dist.entropy()\n",
    "        return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        decision: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        node_selected: Tensor(shape=torch.Size([125, 2]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = CompositeCategoricalDistribution(\n",
    "    node_selected_logits=torch.randn([125, 2, 22]),\n",
    "    decision_logits=torch.randn([125, 2, 3]),\n",
    ")\n",
    "d.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating actors and value estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultInteractionMixin(ProbabilisticTensorDictSequential):\n",
    "    \"\"\"A mixin for accessing the last module's default interaction type.\n",
    "\n",
    "    Allows access to 'default_interaction_mode' and 'default_interaction_type'\n",
    "    attributes for the last module in the sequential.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def default_interaction_mode(self) -> str:\n",
    "        \"\"\"The default interaction mode of the last module in the sequential.\"\"\"\n",
    "        return self[-1].default_interaction_mode\n",
    "\n",
    "    @property\n",
    "    def default_interaction_type(self) -> InteractionType:\n",
    "        \"\"\"The default interaction type of the last module in the sequential.\"\"\"\n",
    "        return self[-1].default_interaction_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticActorDefaultInteractionType(\n",
    "    ProbabilisticActor, DefaultInteractionMixin\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prover_body = GraphIsomorphismAgentBody(params, \"prover\", device=device)\n",
    "verifier_body = GraphIsomorphismAgentBody(params, \"verifier\", device=device)\n",
    "prover_policy_head = GraphIsomorphismAgentPolicyHead(params, \"prover\", device=device)\n",
    "verifier_policy_head = GraphIsomorphismAgentPolicyHead(\n",
    "    params, \"verifier\", device=device\n",
    ")\n",
    "prover_value_head = GraphIsomorphismAgentValueHead(params, \"prover\", device=device)\n",
    "verifier_value_head = GraphIsomorphismAgentValueHead(\n",
    "    params, \"verifier\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = GraphIsomorphismCombinedBody(prover_body, verifier_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_head = ProbabilisticActorDefaultInteractionType(\n",
    "    GraphIsomorphismCombinedPolicyHead(prover_policy_head, verifier_policy_head),\n",
    "    spec=env.action_spec,\n",
    "    distribution_class=CompositeCategoricalDistribution,\n",
    "    distribution_kwargs=dict(\n",
    "        key_transform=lambda x: (\"agents\", x),\n",
    "        log_prob_key=(\"agents\", \"sample_log_prob\"),\n",
    "    ),\n",
    "    in_keys=dict(\n",
    "        node_selected_logits=(\"agents\", \"node_selected_logits\"),\n",
    "        decision_logits=(\"agents\", \"decision_logits\"),\n",
    "    ),\n",
    "    out_keys=env.action_keys,\n",
    "    return_log_prob=True,\n",
    "    log_prob_key=(\"agents\", \"sample_log_prob\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_prob_module = SafeProbabilisticModule(\n",
    "#     spec=env.action_spec,\n",
    "#     distribution_class=CompositeCategoricalDistribution,\n",
    "#     in_keys=dict(\n",
    "#         node_selected_logits=(\"agents\", \"node_selected_logits\"),\n",
    "#         decision_logits=(\"agents\", \"decision_logits\"),\n",
    "#     ),\n",
    "#     out_keys=env.action_keys,\n",
    "#     return_log_prob=True,\n",
    "#     log_prob_key=(\"agents\", \"sample_log_prob\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_head = GraphIsomorphismCombinedValueHead(\n",
    "    prover_value_head, verifier_value_head\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = ActorValueOperator(body, policy_head, value_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = full_model.get_policy_operator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 2, 11, 11]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision: Tensor(shape=torch.Size([125, 2]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                decision_logits: Tensor(shape=torch.Size([125, 2, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                graph_level_repr: Tensor(shape=torch.Size([125, 2, 2, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                node_level_repr: Tensor(shape=torch.Size([125, 2, 2, 11, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                node_selected: Tensor(shape=torch.Size([125, 2]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                node_selected_logits: Tensor(shape=torch.Size([125, 2, 22]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                sample_log_prob: Tensor(shape=torch.Size([125, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "            batch_size=torch.Size([125]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        message: Tensor(shape=torch.Size([125]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        round: Tensor(shape=torch.Size([125]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        terminated: Tensor(shape=torch.Size([125]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        x: Tensor(shape=torch.Size([125, 2, 11, 8]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        y: Tensor(shape=torch.Size([125, 1]), device=cuda:0, dtype=torch.int32, is_shared=True)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 2, 11, 11]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                graph_level_repr: Tensor(shape=torch.Size([125, 2, 2, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                node_level_repr: Tensor(shape=torch.Size([125, 2, 2, 11, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                value: Tensor(shape=torch.Size([125, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "            batch_size=torch.Size([125]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([125]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        message: Tensor(shape=torch.Size([125]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        round: Tensor(shape=torch.Size([125]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        terminated: Tensor(shape=torch.Size([125]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        x: Tensor(shape=torch.Size([125, 2, 11, 8]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        y: Tensor(shape=torch.Size([125, 1]), device=cuda:0, dtype=torch.int32, is_shared=True)},\n",
       "    batch_size=torch.Size([125]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.get_value_operator()(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = ProbabilisticTensorDictSequential(full_model, policy_head, policy_prob_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReplayBuffer(storage=<torchrl.data.replay_buffers.storages.LazyTensorStorage object at 0x7f636612a3d0>, sampler=<torchrl.data.replay_buffers.samplers.SamplerWithoutReplacement object at 0x7f63760d6090>, writer=<torchrl.data.replay_buffers.writers.RoundRobinWriter object at 0x7f63760a7550>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(\n",
    "        params.ppo.frames_per_batch, device=device\n",
    "    ),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=params.ppo.minibatch_size,\n",
    ")\n",
    "replay_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    device=device,\n",
    "    storing_device=device,\n",
    "    frames_per_batch=params.ppo.frames_per_batch,\n",
    "    total_frames=params.ppo.frames_per_batch * params.ppo.num_iterations,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_module = ClipPPOLossMultipleActions(\n",
    "    actor=full_model.get_policy_operator(),\n",
    "    critic=full_model.get_value_operator(),\n",
    "    clip_epsilon=params.ppo.clip_epsilon,\n",
    "    entropy_coef=params.ppo.entropy_eps,\n",
    "    normalize_advantage=False,\n",
    ")\n",
    "loss_module.set_keys(\n",
    "    reward=env.reward_key,\n",
    "    action=env.action_keys,\n",
    "    sample_log_prob=(\"agents\", \"sample_log_prob\"),\n",
    "    value=(\"agents\", \"value\"),\n",
    "    done=(\"agents\", \"done\"),\n",
    "    terminated=(\"agents\", \"terminated\"),\n",
    ")\n",
    "\n",
    "\n",
    "loss_module.make_value_estimator(\n",
    "    ValueEstimators.GAE, gamma=params.ppo.gamma, lmbda=params.ppo.lmbda\n",
    ")\n",
    "gae = loss_module.value_estimator\n",
    "\n",
    "optimizer = torch.optim.Adam(loss_module.parameters(), params.ppo.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_head.prover_value_head.value_mlp.module[0].__dict__[\"_is_stateless\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rearrange('... pair d_in -> ... (pair d_in)')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_head.prover_value_head.value_mlp.module[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['training', '_parameters', '_buffers', '_non_persistent_buffers_set', '_backward_pre_hooks', '_backward_hooks', '_is_full_backward_hook', '_forward_hooks', '_forward_hooks_with_kwargs', '_forward_hooks_always_called', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_state_dict_hooks', '_state_dict_pre_hooks', '_load_state_dict_pre_hooks', '_load_state_dict_post_hooks', '_modules', 'pattern', 'axes_lengths', '_multirecipe', '_axes_lengths', '_functionalized', '_decorated_funs', 'forward', '_is_stateless'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_head.prover_value_head.value_mlp.module[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_head.prover_value_head.value_mlp.module[0].__dict__[\"_test\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean_rewards = (0, 0):   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/functional.py:5504: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::_scaled_dot_product_efficient_attention. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at ../aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "mean_rewards = (0.5613, 0.5281): 100%|| 8/8 [00:29<00:00,  3.56s/it]"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=params.ppo.num_iterations, desc=\"mean_rewards = (0, 0)\")\n",
    "\n",
    "log = []\n",
    "for tensordict_data in collector:\n",
    "    # Expand the done and terminated to match the reward shape (this is expected by the\n",
    "    # value estimator)\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"done\"),\n",
    "        tensordict_data.get((\"next\", \"done\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"terminated\"),\n",
    "        tensordict_data.get((\"next\", \"terminated\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "\n",
    "    # Compute the GAE\n",
    "    with torch.no_grad():\n",
    "        gae(\n",
    "            tensordict_data,\n",
    "            params=loss_module.critic_params,\n",
    "            target_params=loss_module.target_critic_params,\n",
    "        )\n",
    "\n",
    "    # Flatten the data and add it to the replay buffer\n",
    "    data_view = tensordict_data.reshape(-1)\n",
    "    replay_buffer.extend(data_view)\n",
    "\n",
    "    for _ in range(params.ppo.num_epochs):\n",
    "        for _ in range(params.ppo.frames_per_batch // params.ppo.minibatch_size):\n",
    "            # Sample a minibatch from the replay buffer\n",
    "            sub_data = replay_buffer.sample()\n",
    "\n",
    "            # Compute the loss\n",
    "            loss_vals = loss_module(sub_data)\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            # Take an optimization step\n",
    "            loss_value.backward()\n",
    "            clip_grad_norm_(loss_module.parameters(), params.ppo.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # Update the policy weights if the policy of the data collector and the trained\n",
    "    # policy live on different devices.\n",
    "    collector.update_policy_weights_()\n",
    "\n",
    "    # Compute the mean rewards for the done episodes\n",
    "    done = tensordict_data.get((\"next\", \"agents\", \"done\"))[..., VERIFIER_AGENT_NUM]\n",
    "    reward = tensordict_data.get((\"next\", \"agents\", \"reward\"))\n",
    "    mean_reward_prover = reward[..., PROVER_AGENT_NUM][done].mean().item()\n",
    "    mean_reward_verifier = reward[..., VERIFIER_AGENT_NUM][done].mean().item()\n",
    "\n",
    "    # Compute the average episode length\n",
    "    round = tensordict_data.get((\"next\", \"round\"))\n",
    "    mean_episode_length = round[done].float().mean().item()\n",
    "\n",
    "    # Record things to the log\n",
    "    log.append(\n",
    "        dict(\n",
    "            mean_reward_prover=mean_reward_prover,\n",
    "            mean_reward_verifier=mean_reward_verifier,\n",
    "            mean_episode_length=mean_episode_length,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update the progress bar\n",
    "    pbar.set_description(\n",
    "        f\"mean_rewards = ({mean_reward_prover:.4f}, {mean_reward_verifier:.4f})\",\n",
    "        refresh=False,\n",
    "    )\n",
    "    pbar.update()\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([125, 8, 2, 11, 11]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        advantage: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                decision_logits: Tensor(shape=torch.Size([125, 8, 2, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                graph_level_repr: Tensor(shape=torch.Size([125, 8, 2, 2, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                node_level_repr: Tensor(shape=torch.Size([125, 8, 2, 2, 11, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                node_selected: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                node_selected_logits: Tensor(shape=torch.Size([125, 8, 2, 22]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                sample_log_prob: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                value: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "            batch_size=torch.Size([125, 8]),\n",
       "            device=cuda,\n",
       "            is_shared=True),\n",
       "        collector: TensorDict(\n",
       "            fields={\n",
       "                traj_ids: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
       "            batch_size=torch.Size([125, 8]),\n",
       "            device=cuda,\n",
       "            is_shared=True),\n",
       "        done: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        message: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                adjacency: Tensor(shape=torch.Size([125, 8, 2, 11, 11]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        done: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                        reward: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                        terminated: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                        value: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "                    batch_size=torch.Size([125, 8]),\n",
       "                    device=cuda,\n",
       "                    is_shared=True),\n",
       "                done: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                message: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "                node_mask: Tensor(shape=torch.Size([125, 8, 2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                round: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "                terminated: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                x: Tensor(shape=torch.Size([125, 8, 2, 11, 8]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "            batch_size=torch.Size([125, 8]),\n",
       "            device=cuda,\n",
       "            is_shared=True),\n",
       "        node_mask: Tensor(shape=torch.Size([125, 8, 2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        round: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
       "        terminated: Tensor(shape=torch.Size([125, 8]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        value_target: Tensor(shape=torch.Size([125, 8, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        x: Tensor(shape=torch.Size([125, 8, 2, 11, 8]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        y: Tensor(shape=torch.Size([125, 8, 1]), device=cuda:0, dtype=torch.int32, is_shared=True)},\n",
       "    batch_size=torch.Size([125, 8]),\n",
       "    device=cuda,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sequential = {key:np.array([x[key] for x in log]) for key in log[0].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Prover",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          0.680272102355957,
          0.6601123809814453,
          0.6744186282157898,
          0.6134831309318542,
          0.6179775595664978,
          0.6353467702865601,
          0.57419353723526,
          0.5613305568695068
         ]
        },
        {
         "name": "Verifier",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          0.5,
          0.5280898809432983,
          0.4832041561603546,
          0.5460674166679382,
          0.4876404404640198,
          0.49888142943382263,
          0.5440860390663147,
          0.5280665159225464
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Mean Rewards"
        },
        "xaxis": {
         "title": {
          "text": "Iteration"
         }
        },
        "yaxis": {
         "title": {
          "text": "Mean Reward"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(log_sequential[\"mean_reward_prover\"])), y=log_sequential[\"mean_reward_prover\"], name=\"Prover\"))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(log_sequential[\"mean_reward_verifier\"])), y=log_sequential[\"mean_reward_verifier\"], name=\"Verifier\"))\n",
    "fig.update_layout(title=\"Mean Rewards\", xaxis_title=\"Iteration\", yaxis_title=\"Mean Reward\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Mean Episode Length",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          2.8979592323303223,
          2.8876404762268066,
          2.640826940536499,
          2.368539333343506,
          2.310112476348877,
          2.2192394733428955,
          2.1462366580963135,
          2.116424083709717
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Mean Episode Length"
        },
        "xaxis": {
         "title": {
          "text": "Iteration"
         }
        },
        "yaxis": {
         "title": {
          "text": "Mean Episode Length"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(log_sequential[\"mean_episode_length\"])), y=log_sequential[\"mean_episode_length\"], name=\"Mean Episode Length\"))\n",
    "fig.update_layout(title=\"Mean Episode Length\", xaxis_title=\"Iteration\", yaxis_title=\"Mean Episode Length\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvg-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
