{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph isomorphism PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_CPU = True\n",
    "\n",
    "SEED = 349287\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.tensordict import TensorDict, TensorDictBase\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.data.tensor_specs import (\n",
    "    CompositeSpec,\n",
    "    DiscreteTensorSpec,\n",
    "    BinaryDiscreteTensorSpec,\n",
    "    MultiDiscreteTensorSpec,\n",
    "    TensorSpec,\n",
    "    UnboundedContinuousTensorSpec,\n",
    "    Box,\n",
    ")\n",
    "from torchrl.envs import EnvBase\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from torchrl.modules import ProbabilisticActor\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "\n",
    "from torch_geometric.loader import DataLoader as GeometricDataLoader\n",
    "from torch_geometric.data import (\n",
    "    Batch as GeometricBatch,\n",
    "    Data as GeometricData\n",
    ")\n",
    "\n",
    "from jaxtyping import Float, Int, Bool\n",
    "\n",
    "from pvg.graph_isomorphism import (\n",
    "    GraphIsomorphismProver,\n",
    "    GraphIsomorphismVerifier,\n",
    "    GraphIsomorphismScenario,\n",
    ")\n",
    "from pvg.parameters import Parameters\n",
    "from pvg.graph_isomorphism.data import GraphIsomorphismData, GraphIsomorphismDataset\n",
    "from pvg.utils.data import gi_data_to_tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch_generator = torch.Generator().manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if not FORCE_CPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixBox(Box):\n",
    "    \"\"\"An abstract representation of the space of adjacency matrices.\"\"\"\n",
    "\n",
    "    def __init__(self, max_num_nodes: int):\n",
    "        self.max_num_nodes = max_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixSpec(TensorSpec):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_num_nodes: int,\n",
    "        shape: torch.Size | None = None,\n",
    "        device: Optional[torch.device | str | int] = None,\n",
    "        dtype: str | torch.dtype = torch.int32,\n",
    "    ):\n",
    "        self.max_num_nodes = max_num_nodes\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        if shape is None:\n",
    "            self.shape = torch.Size([max_num_nodes, max_num_nodes])\n",
    "        else:\n",
    "            if shape[-2:] != (max_num_nodes, max_num_nodes):\n",
    "                raise ValueError(\n",
    "                    f\"The last two dimensions of the shape must be {max_num_nodes}. \"\n",
    "                    f\"Got {shape[-2:]}.\"\n",
    "                )\n",
    "            self.shape = torch.Size(shape)\n",
    "            \n",
    "        self.space = AdjacencyMatrixBox(max_num_nodes)\n",
    "\n",
    "    def is_in(self, val: torch.Tensor) -> bool:\n",
    "        \"\"\"Check if a value is a valid adjacency matrix.\"\"\"\n",
    "\n",
    "        # Basic type checks\n",
    "        if not isinstance(val, torch.Tensor):\n",
    "            return False\n",
    "        if val.shape[-2:] != (self.max_num_nodes, self.max_num_nodes):\n",
    "            return False\n",
    "        if val.dtype != self.dtype:\n",
    "            return False\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        if not torch.all(torch.isin(val, torch.tensor([0, 1], device=self.device))):\n",
    "            return False\n",
    "\n",
    "        # Make sure the matrix is symmetric\n",
    "        if val.transpose(-1, -2) != val:\n",
    "            return False\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        if not torch.all(torch.isin(torch.diagonal(val), 0)):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def rand(self, shape: Optional[list[int] | torch.Size] = None) -> torch.Tensor:\n",
    "        \"\"\"Generate a random 1/2 Erdos-Renyi adjacency matrix.\"\"\"\n",
    "\n",
    "        if shape is None:\n",
    "            shape = shape = torch.Size([])\n",
    "\n",
    "        adjacency_values = torch.rand(*shape, *self.shape, device=device)\n",
    "        adjacency = (adjacency_values < 0.5).to(self.dtype)\n",
    "        adjacency = adjacency.triu(diagonal=1)\n",
    "        adjacency += adjacency.transpose(1, 2).clone()\n",
    "\n",
    "        return adjacency\n",
    "    \n",
    "    def _project(self, val: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Project a value to the space of valid adjacency matrices.\"\"\"\n",
    "\n",
    "        # Symmetrize the matrix\n",
    "        val = (val + val.transpose(1, 2)) / 2\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        val[..., torch.arange(self.max_num_nodes), torch.arange(self.max_num_nodes)] = 0\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        return torch.clamp(torch.round(val), min=0, max=1).to(self.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forgetful_cycle(iterable):\n",
    "    \"\"\"A version of cycle that doesn't save copies of the values\"\"\"\n",
    "    while True:\n",
    "        for i in iterable:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableGeometricDataCycler:\n",
    "    \"\"\"A loader that cycles through geometric data, but allows the batch size to vary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader : GeometricDataLoader\n",
    "        The base dataloader to use. This dataloader will be cycled through.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataloader: GeometricDataLoader):\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader_iter = iter(forgetful_cycle(self.dataloader))\n",
    "        self.remainder: Optional[Tensor] = None\n",
    "\n",
    "    def get_batch(self, batch_size: int) -> GeometricBatch:\n",
    "        \"\"\"Get a batch of data from the dataloader with the given batch size.\n",
    "\n",
    "        If the dataloader is exhausted, it will be reset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            The size of the batch to return.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        batch : Tensor\n",
    "            A batch of data with the given batch size.\n",
    "        \"\"\"\n",
    "\n",
    "        left_to_sample = batch_size\n",
    "        batch_components = []\n",
    "\n",
    "        # Start by sampling from the remainder from the previous sampling\n",
    "        if self.remainder is not None:\n",
    "            batch_components.extend(self.remainder[:left_to_sample])\n",
    "            if self.remainder.shape[0] <= left_to_sample:\n",
    "                left_to_sample -= self.remainder.shape[0]\n",
    "                self.remainder = None\n",
    "            else:\n",
    "                self.remainder = self.remainder[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Keep sampling batches until we have enough\n",
    "        while left_to_sample > 0:\n",
    "            batch = next(self.dataloader_iter)\n",
    "            batch_components.extend(batch[:left_to_sample])\n",
    "            if len(batch) <= left_to_sample:\n",
    "                left_to_sample -= len(batch)\n",
    "            else:\n",
    "                self.remainder = batch[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Concatenate the batch components into a single batch\n",
    "        batch = GeometricBatch.from_data_list(\n",
    "            batch_components, follow_batch=self.dataloader.follow_batch\n",
    "        )\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "class GraphIsomorphismEnv(EnvBase):\n",
    "    def __init__(self, params: Parameters, device: torch.device | str = device):\n",
    "        super().__init__(device=device)\n",
    "        self.params = params\n",
    "\n",
    "        # Create a random number generator\n",
    "        self.rng = torch.Generator(device=device)\n",
    "\n",
    "        # Load the dataset\n",
    "        self.dataset = GraphIsomorphismDataset(params)\n",
    "        self.data_cycler: Optional[VariableGeometricDataCycler] = None\n",
    "\n",
    "        # Compute the maximum number of nodes in the dataset\n",
    "        self.max_num_nodes = 0\n",
    "        for data in self.dataset:\n",
    "            self.max_num_nodes = max(\n",
    "                self.max_num_nodes, data.x_a.shape[0], data.x_b.shape[0]\n",
    "            )\n",
    "\n",
    "        # Set the environment shape to the batch size\n",
    "        self.batch_size = (params.batch_size,)\n",
    "\n",
    "        # The spec for the observation space: agents see the adjacency matrix and the\n",
    "        # messages sent so far\n",
    "        self.observation_spec = CompositeSpec(\n",
    "            adjacency=AdjacencyMatrixSpec(\n",
    "                self.max_num_nodes,\n",
    "                shape=(params.batch_size, 2, self.max_num_nodes, self.max_num_nodes),\n",
    "            ),\n",
    "            message=BinaryDiscreteTensorSpec(\n",
    "                params.max_message_rounds,\n",
    "                shape=(\n",
    "                    params.batch_size,\n",
    "                    2,\n",
    "                    self.max_num_nodes,\n",
    "                    params.max_message_rounds,\n",
    "                ),\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        )\n",
    "\n",
    "        # The spec for the state space: the true label and the round number\n",
    "        self.state_spec = CompositeSpec(\n",
    "            y=BinaryDiscreteTensorSpec(1, shape=(params.batch_size, 1)),\n",
    "            round=DiscreteTensorSpec(\n",
    "                params.max_message_rounds, shape=(params.batch_size,)\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        )\n",
    "\n",
    "        # The action space has shape (batch_size, num_agents, num_actions). Each agent\n",
    "        # chooses both a node and a decision (accept, reject or continue). We add a\n",
    "        # dummy node at the beginning (shifting the indices by 1) to represent the case\n",
    "        # where the agent does not choose any node (when it's not their turn).\n",
    "        self.action_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                action=MultiDiscreteTensorSpec(\n",
    "                    [self.max_num_nodes + 1, 3], shape=(params.batch_size, 2, 2)\n",
    "                ),\n",
    "                shape=(params.batch_size,),\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        )\n",
    "\n",
    "        self.reward_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                reward=UnboundedContinuousTensorSpec(shape=(params.batch_size, 2)),\n",
    "                shape=(params.batch_size,),\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        )\n",
    "\n",
    "        self.done_spec = CompositeSpec(\n",
    "            done=BinaryDiscreteTensorSpec(\n",
    "                params.batch_size, shape=(params.batch_size,), dtype=torch.bool\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        )\n",
    "\n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        \"\"\"Perform a step in the environment.\"\"\"\n",
    "        # Extract the tensors from the dict\n",
    "        y: Int[Tensor, \"batch\"] = tensordict[\"y\"]\n",
    "        message: Int[Tensor, \"batch graph node message_round\"] = tensordict[\"message\"]\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "        action: Int[Tensor, \"batch agent action\"] = tensordict[\"agents\", \"action\"]\n",
    "        done: Bool[Tensor, \"batch\"] = tensordict[\"done\"]\n",
    "        agent_index = round % 2\n",
    "        node_selected = action[..., 0]\n",
    "        decision = action[..., 1]\n",
    "\n",
    "        # Determine which graph contains the selected node and which node it is there\n",
    "        # (batch agent)\n",
    "        which_graph = node_selected < self.max_num_nodes\n",
    "        # (batch agent)\n",
    "        graph_node = torch.where(\n",
    "            which_graph, node_selected, node_selected - self.max_num_nodes\n",
    "        )\n",
    "\n",
    "        # Write the node selected by the agent whose turn it is as a (one-hot) message\n",
    "        message[\n",
    "            agent_index,\n",
    "            which_graph[torch.arange(which_graph.shape[0]), agent_index].int(),\n",
    "            graph_node[torch.arange(which_graph.shape[0]), agent_index],\n",
    "            round,\n",
    "        ] = 1\n",
    "\n",
    "        # If the verifier has made a guess, compute the reward and terminate the episode\n",
    "        verifier_decision_made = (agent_index == 0) & (decision[:, 0] != 0)\n",
    "        done = done | verifier_decision_made\n",
    "        reward_verifier = (done & decision[:, 0] == y).float()\n",
    "        reward_verifier = reward_verifier * self.params.verifier_reward\n",
    "        reward_prover = (done & decision[:, 0] == 1).float()\n",
    "        reward_prover = reward_prover * self.params.prover_reward\n",
    "\n",
    "        # If we reach the end of the episode and the verifier has not made a guess,\n",
    "        # terminate it with a negative reward for the verifier\n",
    "        done = done | (round >= self.params.max_message_rounds - 1)\n",
    "        reward_verifier[\n",
    "            (round >= self.params.max_message_rounds - 1) & ~verifier_decision_made\n",
    "        ] = self.params.verifier_terminated_penalty\n",
    "\n",
    "        # Stack the rewards for the two agents\n",
    "        reward = torch.stack([reward_verifier, reward_prover], dim=-1)\n",
    "\n",
    "        # Put everything together\n",
    "        out = TensorDict(\n",
    "            adjacency=tensordict[\"adjacency\"],\n",
    "            message=message,\n",
    "            y=y,\n",
    "            round=round + 1,\n",
    "            done=done,\n",
    "            reward=reward,\n",
    "        )\n",
    "        return out\n",
    "\n",
    "    def _reset(self, tensordict: Optional[TensorDictBase] = None) -> TensorDictBase:\n",
    "        \"\"\"(Partially) reset the environment.\n",
    "\n",
    "        For each episode which is done, takes a new sample from the dataset and resets\n",
    "        the episode.\n",
    "        \"\"\"\n",
    "\n",
    "        # If no tensordict is given, we're starting afresh\n",
    "        if tensordict is None:\n",
    "            tensordict = TensorDict(\n",
    "                dict(\n",
    "                    adjacency=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.max_num_nodes,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.int,\n",
    "                    ),\n",
    "                    message=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.params.max_message_rounds,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.int,\n",
    "                    ),\n",
    "                    y=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        1,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.int,\n",
    "                    ),\n",
    "                    round=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.int,\n",
    "                    ),\n",
    "                    done=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.bool,\n",
    "                    ),\n",
    "                ),\n",
    "                batch_size=self.batch_size,\n",
    "            )\n",
    "\n",
    "            new_mask = torch.ones(\n",
    "                *self.batch_size, dtype=torch.bool, device=self.device\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            new_mask = tensordict[\"done\"]\n",
    "\n",
    "        # If we don't have a data cycler yet, create one\n",
    "        if self.data_cycler is None:\n",
    "            dataloader = GeometricDataLoader(\n",
    "                self.dataset,\n",
    "                batch_size=self.params.batch_size,\n",
    "                follow_batch=[\"x_a\", \"x_b\"],\n",
    "                shuffle=True,\n",
    "                generator=self.rng,\n",
    "            )\n",
    "            self.data_cycler = VariableGeometricDataCycler(dataloader)\n",
    "\n",
    "        # Sample a new batch of data for the episodes that are done\n",
    "        batch = self.data_cycler.get_batch(new_mask.sum().item())\n",
    "        batch_tensordict = gi_data_to_tensordict(\n",
    "            batch, node_dim_size=self.max_num_nodes\n",
    "        )\n",
    "\n",
    "        # Copy the new data into the output\n",
    "        tensordict[\"adjacency\"][new_mask] = batch_tensordict[\"adjacency\"]\n",
    "        tensordict[\"message\"][new_mask] = torch.zeros_like(\n",
    "            tensordict[\"message\"][new_mask]\n",
    "        )\n",
    "        tensordict[\"y\"][new_mask] = (batch.wl_score == -1).int().unsqueeze(-1)\n",
    "        tensordict[\"round\"][new_mask] = 0\n",
    "        tensordict[\"done\"][new_mask] = False\n",
    "\n",
    "        return tensordict\n",
    "\n",
    "    def _set_seed(self, seed: int | None):\n",
    "        self.rng.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters(\n",
    "    scenario=\"graph_isomorphism\",\n",
    "    trainer=\"ppo\",\n",
    "    dataset=\"eru10000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphIsomorphismEnv(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [64, 64] at entry 0 and [64] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sam/Code/Projects/PVG Experiments/playground/gi_mappo.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m check_env_specs(env)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torchrl/envs/utils.py:435\u001b[0m, in \u001b[0;36mcheck_env_specs\u001b[0;34m(env, return_contiguous, check_dtype, seed)\u001b[0m\n\u001b[1;32m    432\u001b[0m     env\u001b[39m.\u001b[39mset_seed(seed)\n\u001b[1;32m    434\u001b[0m fake_tensordict \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mfake_tensordict()\n\u001b[0;32m--> 435\u001b[0m real_tensordict \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mrollout(\u001b[39m3\u001b[39;49m, return_contiguous\u001b[39m=\u001b[39;49mreturn_contiguous)\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m return_contiguous:\n\u001b[1;32m    438\u001b[0m     fake_tensordict \u001b[39m=\u001b[39m fake_tensordict\u001b[39m.\u001b[39munsqueeze(real_tensordict\u001b[39m.\u001b[39mbatch_dims \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torchrl/envs/common.py:1814\u001b[0m, in \u001b[0;36mEnvBase.rollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, return_contiguous, tensordict, out)\u001b[0m\n\u001b[1;32m   1804\u001b[0m kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1805\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtensordict\u001b[39m\u001b[39m\"\u001b[39m: tensordict,\n\u001b[1;32m   1806\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mauto_cast_to_device\u001b[39m\u001b[39m\"\u001b[39m: auto_cast_to_device,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcallback\u001b[39m\u001b[39m\"\u001b[39m: callback,\n\u001b[1;32m   1812\u001b[0m }\n\u001b[1;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m break_when_any_done:\n\u001b[0;32m-> 1814\u001b[0m     tensordicts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rollout_stop_early(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     tensordicts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rollout_nonstop(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torchrl/envs/common.py:1842\u001b[0m, in \u001b[0;36mEnvBase._rollout_stop_early\u001b[0;34m(self, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[39mif\u001b[39;00m auto_cast_to_device:\n\u001b[1;32m   1841\u001b[0m     tensordict \u001b[39m=\u001b[39m tensordict\u001b[39m.\u001b[39mto(env_device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1842\u001b[0m tensordict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(tensordict)\n\u001b[1;32m   1843\u001b[0m tensordicts\u001b[39m.\u001b[39mappend(tensordict\u001b[39m.\u001b[39mclone(\u001b[39mFalse\u001b[39;00m))\n\u001b[1;32m   1845\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m max_steps \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1846\u001b[0m     \u001b[39m# we don't truncated as one could potentially continue the run\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torchrl/envs/common.py:1313\u001b[0m, in \u001b[0;36mEnvBase.step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_tensordict_shape(tensordict)\n\u001b[1;32m   1311\u001b[0m next_preset \u001b[39m=\u001b[39m tensordict\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1313\u001b[0m next_tensordict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(tensordict)\n\u001b[1;32m   1314\u001b[0m next_tensordict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step_proc_data(next_tensordict)\n\u001b[1;32m   1315\u001b[0m \u001b[39mif\u001b[39;00m next_preset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[39m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m     \u001b[39m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m     \u001b[39m# the necessary keys\u001b[39;00m\n",
      "\u001b[1;32m/home/sam/Code/Projects/PVG Experiments/playground/gi_mappo.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m reward_verifier[\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m     (\u001b[39mround\u001b[39m \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mmax_message_rounds \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m~\u001b[39mverifier_decision_made\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m ] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mverifier_terminated_penalty\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m \u001b[39m# Stack the rewards for the two agents\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m reward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack([reward_verifier, reward_prover], dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39m# Put everything together\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m out \u001b[39m=\u001b[39m TensorDict(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m     adjacency\u001b[39m=\u001b[39mtensordict[\u001b[39m\"\u001b[39m\u001b[39madjacency\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m     message\u001b[39m=\u001b[39mmessage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     reward\u001b[39m=\u001b[39mreward,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sam/Code/Projects/PVG%20Experiments/playground/gi_mappo.ipynb#X22sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [64, 64] at entry 0 and [64] at entry 1"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvg-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
