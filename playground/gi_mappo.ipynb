{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph isomorphism PPO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_CPU = True\n",
    "\n",
    "SEED = 349287\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from tensordict.nn import (\n",
    "    TensorDictModule,\n",
    "    TensorDictModuleBase,\n",
    "    TensorDictSequential,\n",
    "    ProbabilisticTensorDictSequential,\n",
    ")\n",
    "from tensordict.nn.distributions import CompositeDistribution\n",
    "from tensordict.tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import InteractionType\n",
    "from torchrl.modules import ActorCriticOperator\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.data.tensor_specs import (\n",
    "    CompositeSpec,\n",
    "    DiscreteTensorSpec,\n",
    "    BinaryDiscreteTensorSpec,\n",
    "    MultiDiscreteTensorSpec,\n",
    "    TensorSpec,\n",
    "    UnboundedContinuousTensorSpec,\n",
    "    Box,\n",
    ")\n",
    "from torchrl.envs import EnvBase\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from torchrl.modules import ProbabilisticActor\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "\n",
    "from torch_geometric.loader import DataLoader as GeometricDataLoader\n",
    "from torch_geometric.data import Batch as GeometricBatch, Data as GeometricData\n",
    "\n",
    "from jaxtyping import Float, Int, Bool\n",
    "\n",
    "from pvg.graph_isomorphism import (\n",
    "    GraphIsomorphismAgentBody,\n",
    "    GraphIsomorphismAgentPolicyHead,\n",
    "    GraphIsomorphismAgentCriticHead,\n",
    ")\n",
    "from pvg.parameters import Parameters\n",
    "from pvg.graph_isomorphism.data import GraphIsomorphismData, GraphIsomorphismDataset\n",
    "from pvg.utils.data import gi_data_to_tensordict\n",
    "from pvg.constants import VERIFIER_AGENT_NUM, PROVER_AGENT_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch_generator = torch.Generator().manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if not FORCE_CPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixBox(Box):\n",
    "    \"\"\"An abstract representation of the space of adjacency matrices.\"\"\"\n",
    "\n",
    "    def __init__(self, max_num_nodes: int):\n",
    "        self.max_num_nodes = max_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrixSpec(TensorSpec):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_num_nodes: int,\n",
    "        shape: torch.Size | None = None,\n",
    "        device: Optional[torch.device | str | int] = None,\n",
    "        dtype: str | torch.dtype = torch.int32,\n",
    "    ):\n",
    "        self.max_num_nodes = max_num_nodes\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        if shape is None:\n",
    "            self.shape = torch.Size([max_num_nodes, max_num_nodes])\n",
    "        else:\n",
    "            if shape[-2:] != (max_num_nodes, max_num_nodes):\n",
    "                raise ValueError(\n",
    "                    f\"The last two dimensions of the shape must be {max_num_nodes}. \"\n",
    "                    f\"Got {shape[-2:]}.\"\n",
    "                )\n",
    "            self.shape = torch.Size(shape)\n",
    "\n",
    "        self.space = AdjacencyMatrixBox(max_num_nodes)\n",
    "\n",
    "    def is_in(self, val: torch.Tensor) -> bool:\n",
    "        \"\"\"Check if a value is a valid adjacency matrix.\"\"\"\n",
    "\n",
    "        # Basic type checks\n",
    "        if not isinstance(val, torch.Tensor):\n",
    "            return False\n",
    "        if val.shape[-2:] != (self.max_num_nodes, self.max_num_nodes):\n",
    "            return False\n",
    "        if val.dtype != self.dtype:\n",
    "            return False\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        if not torch.all(torch.isin(val, torch.tensor([0, 1], device=self.device))):\n",
    "            return False\n",
    "\n",
    "        # Make sure the matrix is symmetric\n",
    "        if not torch.all(val.transpose(-1, -2) == val):\n",
    "            return False\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        if not torch.all(torch.isin(torch.diagonal(val, dim1=-2, dim2=-1), 0)):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def rand(self, shape: Optional[list[int] | torch.Size] = None) -> torch.Tensor:\n",
    "        \"\"\"Generate a random 1/2 Erdos-Renyi adjacency matrix.\"\"\"\n",
    "\n",
    "        if shape is None:\n",
    "            shape = shape = torch.Size([])\n",
    "\n",
    "        adjacency_values = torch.rand(*shape, *self.shape, device=device)\n",
    "        adjacency = (adjacency_values < 0.5).to(self.dtype)\n",
    "        adjacency = adjacency.triu(diagonal=1)\n",
    "        adjacency += adjacency.transpose(1, 2).clone()\n",
    "\n",
    "        return adjacency\n",
    "\n",
    "    def _project(self, val: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Project a value to the space of valid adjacency matrices.\"\"\"\n",
    "\n",
    "        # Symmetrize the matrix\n",
    "        val = (val + val.transpose(1, 2)) / 2\n",
    "\n",
    "        # Make sure the diagonal is all zeros\n",
    "        val[..., torch.arange(self.max_num_nodes), torch.arange(self.max_num_nodes)] = 0\n",
    "\n",
    "        # Make sure the values are either 0 or 1\n",
    "        return torch.clamp(torch.round(val), min=0, max=1).to(self.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forgetful_cycle(iterable):\n",
    "    \"\"\"A version of cycle that doesn't save copies of the values\"\"\"\n",
    "    while True:\n",
    "        for i in iterable:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableGeometricDataCycler:\n",
    "    \"\"\"A loader that cycles through geometric data, but allows the batch size to vary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader : GeometricDataLoader\n",
    "        The base dataloader to use. This dataloader will be cycled through.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataloader: GeometricDataLoader):\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader_iter = iter(forgetful_cycle(self.dataloader))\n",
    "        self.remainder: Optional[list] = None\n",
    "\n",
    "    def get_batch(self, batch_size: int) -> GeometricBatch:\n",
    "        \"\"\"Get a batch of data from the dataloader with the given batch size.\n",
    "\n",
    "        If the dataloader is exhausted, it will be reset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            The size of the batch to return.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        batch : Tensor\n",
    "            A batch of data with the given batch size.\n",
    "        \"\"\"\n",
    "\n",
    "        left_to_sample = batch_size\n",
    "        batch_components = []\n",
    "\n",
    "        # Start by sampling from the remainder from the previous sampling\n",
    "        if self.remainder is not None:\n",
    "            batch_components.extend(self.remainder[:left_to_sample])\n",
    "            if len(self.remainder) <= left_to_sample:\n",
    "                left_to_sample -= len(self.remainder)\n",
    "                self.remainder = None\n",
    "            else:\n",
    "                self.remainder = self.remainder[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Keep sampling batches until we have enough\n",
    "        while left_to_sample > 0:\n",
    "            batch = next(self.dataloader_iter)\n",
    "            batch_components.extend(batch[:left_to_sample])\n",
    "            if len(batch) <= left_to_sample:\n",
    "                left_to_sample -= len(batch)\n",
    "            else:\n",
    "                self.remainder = batch[left_to_sample:]\n",
    "                left_to_sample = 0\n",
    "\n",
    "        # Concatenate the batch components into a single batch\n",
    "        batch = GeometricBatch.from_data_list(\n",
    "            batch_components, follow_batch=self.dataloader.follow_batch\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.dataloader!r})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "class GraphIsomorphismEnv(EnvBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: Parameters,\n",
    "        device: torch.device | str = device,\n",
    "        int_dtype: torch.dtype = torch.int,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.params = params\n",
    "        self.int_dtype = int_dtype\n",
    "\n",
    "        # Create a random number generator\n",
    "        self.rng = torch.Generator(device=device)\n",
    "\n",
    "        # Load the dataset\n",
    "        self.dataset = GraphIsomorphismDataset(params)\n",
    "        self.data_cycler: Optional[VariableGeometricDataCycler] = None\n",
    "\n",
    "        # Compute the maximum number of nodes in the dataset\n",
    "        self.max_num_nodes = 0\n",
    "        for data in self.dataset:\n",
    "            self.max_num_nodes = max(\n",
    "                self.max_num_nodes, data.x_a.shape[0], data.x_b.shape[0]\n",
    "            )\n",
    "\n",
    "        # Set the environment shape to the batch size\n",
    "        self.batch_size = (params.batch_size,)\n",
    "\n",
    "        # The spec for the observation space: agents see the adjacency matrix and the\n",
    "        # messages sent so far. The \"message\" field contains the most recent message.\n",
    "        self.observation_spec = CompositeSpec(\n",
    "            adjacency=AdjacencyMatrixSpec(\n",
    "                self.max_num_nodes,\n",
    "                shape=(params.batch_size, 2, self.max_num_nodes, self.max_num_nodes),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            x=BinaryDiscreteTensorSpec(\n",
    "                params.max_message_rounds,\n",
    "                shape=(\n",
    "                    params.batch_size,\n",
    "                    2,\n",
    "                    self.max_num_nodes,\n",
    "                    params.max_message_rounds,\n",
    "                ),\n",
    "                dtype=torch.float,\n",
    "            ),\n",
    "            node_mask=BinaryDiscreteTensorSpec(\n",
    "                self.max_num_nodes,\n",
    "                shape=(\n",
    "                    params.batch_size,\n",
    "                    2,\n",
    "                    self.max_num_nodes,\n",
    "                ),\n",
    "                dtype=torch.bool,\n",
    "            ),\n",
    "            message=DiscreteTensorSpec(\n",
    "                2 * self.max_num_nodes,\n",
    "                shape=(params.batch_size,),\n",
    "                dtype=torch.long,\n",
    "            ),\n",
    "            round=DiscreteTensorSpec(\n",
    "                params.max_message_rounds,\n",
    "                shape=(params.batch_size,),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # The spec for the state space: the true label and the round number\n",
    "        self.state_spec = CompositeSpec(\n",
    "            y=BinaryDiscreteTensorSpec(\n",
    "                1,\n",
    "                shape=(params.batch_size, 1),\n",
    "                dtype=self.int_dtype,\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Each action space has shape (batch_size, num_agents). Each agent chooses both\n",
    "        # a node and a decision: reject, accept or continue (represented as 0, 1 or 2).\n",
    "        # The node is is a number between 0 and 2 * max_num_nodes - 1. If it is less\n",
    "        # than max_num_nodes, it is a node in the first graph, otherwise it is a node in\n",
    "        # the second graph. The verifier is agent 0 and the prover is agent 1.\n",
    "        self.action_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                node_selected=DiscreteTensorSpec(\n",
    "                    2 * self.max_num_nodes,\n",
    "                    shape=(params.batch_size, 2),\n",
    "                    dtype=self.int_dtype,\n",
    "                ),\n",
    "                decision=DiscreteTensorSpec(\n",
    "                    3,\n",
    "                    shape=(params.batch_size, 2),\n",
    "                    dtype=self.int_dtype,\n",
    "                ),\n",
    "                shape=(params.batch_size,),\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.reward_spec = CompositeSpec(\n",
    "            agents=CompositeSpec(\n",
    "                reward=UnboundedContinuousTensorSpec(shape=(params.batch_size, 2)),\n",
    "                shape=(params.batch_size,),\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.done_spec = CompositeSpec(\n",
    "            done=BinaryDiscreteTensorSpec(\n",
    "                params.batch_size, shape=(params.batch_size,), dtype=torch.bool\n",
    "            ),\n",
    "            shape=(params.batch_size,),\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        \"\"\"Perform a step in the environment.\"\"\"\n",
    "\n",
    "        # Extract the tensors from the dict\n",
    "        y: Int[Tensor, \"batch\"] = tensordict[\"y\"]\n",
    "        x: Float[Tensor, \"batch graph node message_round\"] = tensordict[\"x\"]\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "        node_selected: Int[Tensor, \"batch agent\"] = tensordict[\n",
    "            \"agents\", \"node_selected\"\n",
    "        ]\n",
    "        decision: Int[Tensor, \"batch agent\"] = tensordict[\"agents\", \"decision\"]\n",
    "        done: Bool[Tensor, \"batch\"] = tensordict[\"done\"]\n",
    "\n",
    "        # Compute index of the agent whose turn it is\n",
    "        agent_index: Int[Tensor, \"batch\"] = round % 2\n",
    "        if PROVER_AGENT_NUM == 0:\n",
    "            agent_index = 1 - agent_index\n",
    "\n",
    "        # Determine which graph contains the selected node and which node it is there\n",
    "        # (batch agent)\n",
    "        which_graph = node_selected >= self.max_num_nodes\n",
    "        # (batch agent)\n",
    "        graph_node = torch.where(\n",
    "            which_graph, node_selected - self.max_num_nodes, node_selected\n",
    "        )\n",
    "\n",
    "        # Write the node selected by the agent whose turn it is as a (one-hot) message\n",
    "        x[\n",
    "            torch.arange(x.shape[0]),\n",
    "            which_graph[torch.arange(which_graph.shape[0]), agent_index].int(),\n",
    "            graph_node[torch.arange(which_graph.shape[0]), agent_index],\n",
    "            round,\n",
    "        ] = 1\n",
    "\n",
    "        # Set the node selected by the agent whose turn it is as the message\n",
    "        message = node_selected[\n",
    "            torch.arange(node_selected.shape[0]), agent_index\n",
    "        ].long()\n",
    "\n",
    "        # If the verifier has made a guess, compute the reward and terminate the episode\n",
    "        verifier_decision_made = (agent_index == VERIFIER_AGENT_NUM) & (\n",
    "            decision[:, VERIFIER_AGENT_NUM] != 2\n",
    "        )\n",
    "        done = done | verifier_decision_made\n",
    "        reward_verifier = (\n",
    "            verifier_decision_made & (decision[:, VERIFIER_AGENT_NUM] == y.squeeze())\n",
    "        ).float()\n",
    "        reward_verifier = reward_verifier * self.params.verifier_reward\n",
    "        reward_prover = (\n",
    "            verifier_decision_made & (decision[:, VERIFIER_AGENT_NUM] == 1)\n",
    "        ).float()\n",
    "        reward_prover = reward_prover * self.params.prover_reward\n",
    "\n",
    "        # If we reach the end of the episode and the verifier has not made a guess,\n",
    "        # terminate it with a negative reward for the verifier\n",
    "        done = done | (round >= self.params.max_message_rounds - 1)\n",
    "        reward_verifier[\n",
    "            (round >= self.params.max_message_rounds - 1) & ~verifier_decision_made\n",
    "        ] = self.params.verifier_terminated_penalty\n",
    "\n",
    "        # Stack the rewards for the two agents\n",
    "        reward = torch.stack([reward_verifier, reward_prover], dim=-1)\n",
    "\n",
    "        # Put everything together\n",
    "        next = TensorDict(\n",
    "            dict(\n",
    "                adjacency=tensordict[\"adjacency\"],\n",
    "                x=x,\n",
    "                node_mask=tensordict[\"node_mask\"],\n",
    "                message=message,\n",
    "                round=round + 1,\n",
    "                done=done,\n",
    "                agents=TensorDict(dict(reward=reward), batch_size=self.batch_size),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        return next\n",
    "\n",
    "    def _reset(self, tensordict: Optional[TensorDictBase] = None) -> TensorDictBase:\n",
    "        \"\"\"(Partially) reset the environment.\n",
    "\n",
    "        For each episode which is done, takes a new sample from the dataset and resets\n",
    "        the episode.\n",
    "        \"\"\"\n",
    "\n",
    "        # If no tensordict is given, we're starting afresh\n",
    "        if tensordict is None:\n",
    "            tensordict = TensorDict(\n",
    "                dict(\n",
    "                    adjacency=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.max_num_nodes,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    x=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        self.params.max_message_rounds,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.float,\n",
    "                    ),\n",
    "                    node_mask=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        2,\n",
    "                        self.max_num_nodes,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.bool,\n",
    "                    ),\n",
    "                    message=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.long,\n",
    "                    ),\n",
    "                    y=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        1,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    round=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=self.int_dtype,\n",
    "                    ),\n",
    "                    done=torch.empty(\n",
    "                        *self.batch_size,\n",
    "                        device=self.device,\n",
    "                        dtype=torch.bool,\n",
    "                    ),\n",
    "                ),\n",
    "                batch_size=self.batch_size,\n",
    "            )\n",
    "\n",
    "            new_mask = torch.ones(\n",
    "                *self.batch_size, dtype=torch.bool, device=self.device\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            new_mask = tensordict[\"done\"]\n",
    "            tensordict = tensordict.clone()\n",
    "\n",
    "        # If we don't have a data cycler yet, create one\n",
    "        if self.data_cycler is None:\n",
    "            dataloader = GeometricDataLoader(\n",
    "                self.dataset,\n",
    "                batch_size=self.params.batch_size,\n",
    "                follow_batch=[\"x_a\", \"x_b\"],\n",
    "                shuffle=True,\n",
    "                generator=self.rng,\n",
    "            )\n",
    "            self.data_cycler = VariableGeometricDataCycler(dataloader)\n",
    "\n",
    "        # Sample a new batch of data for the episodes that are done\n",
    "        batch = self.data_cycler.get_batch(new_mask.sum().item())\n",
    "        batch_tensordict = gi_data_to_tensordict(\n",
    "            batch, node_dim_size=self.max_num_nodes\n",
    "        )\n",
    "\n",
    "        # Copy the new data into the output\n",
    "        tensordict[\"adjacency\"][new_mask] = batch_tensordict[\"adjacency\"]\n",
    "        tensordict[\"x\"][new_mask] = torch.zeros_like(tensordict[\"x\"][new_mask])\n",
    "        tensordict[\"node_mask\"][new_mask] = batch_tensordict[\"node_mask\"]\n",
    "        tensordict[\"message\"][new_mask] = 0\n",
    "        tensordict[\"y\"][new_mask] = (batch.wl_score == -1).int().unsqueeze(-1)\n",
    "        tensordict[\"round\"][new_mask] = 0\n",
    "        tensordict[\"done\"][new_mask] = False\n",
    "\n",
    "        return tensordict\n",
    "\n",
    "    def _set_seed(self, seed: int | None):\n",
    "        self.rng.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters(\n",
    "    scenario=\"graph_isomorphism\",\n",
    "    trainer=\"ppo\",\n",
    "    dataset=\"eru10000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphIsomorphismEnv(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] y: 0 P: ( 5)  0.0 V: ( 8,   2)  0.0  | [0] y: 1 P: ( 4)  0.0 V: (16,   2)  0.0 \n",
      "[1] y: 0 P: ( 1)  0.0 V: ( 5,   0)  0.0  | [1] y: 1 P: (12)  0.0 V: ( 2,   1)  0.0 \n",
      "[2] y: 0 P: (15)  1.0 V: (14,   1)  0.0  | [2] y: 1 P: ( 8)  1.0 V: (18,   1)  1.0 \n",
      "[0] y: 1 P: ( 5)  0.0 V: (10,   2)  0.0  | [0] y: 0 P: ( 6)  0.0 V: ( 9,   0)  1.0 \n",
      "[1] y: 1 P: ( 6)  0.0 V: ( 4,   0)  0.0  | [0] y: 0 P: (20)  0.0 V: (16,   0)  1.0 \n",
      "[2] y: 1 P: ( 1)  0.0 V: (12,   2)  0.0  | [0] y: 1 P: ( 3)  0.0 V: (21,   2)  0.0 \n",
      "[3] y: 1 P: ( 7)  0.0 V: ( 8,   1)  0.0  | [1] y: 1 P: ( 0)  0.0 V: (10,   1)  0.0 \n",
      "[4] y: 1 P: ( 7)  1.0 V: (10,   1)  1.0  | [2] y: 1 P: ( 4)  0.0 V: (11,   2)  0.0 \n",
      "[0] y: 1 P: (16)  0.0 V: ( 8,   0)  0.0  | [3] y: 1 P: ( 4)  0.0 V: ( 2,   2)  0.0 \n",
      "[0] y: 1 P: (11)  1.0 V: (16,   1)  1.0  | [4] y: 1 P: (11)  0.0 V: ( 0,   2)  0.0 \n",
      "[0] y: 1 P: ( 1)  0.0 V: (17,   0)  0.0  | [5] y: 1 P: ( 1)  0.0 V: ( 7,   0)  0.0 \n",
      "[0] y: 0 P: ( 8)  0.0 V: ( 0,   2)  0.0  | [6] y: 1 P: ( 8)  0.0 V: ( 0,   0)  0.0 \n",
      "[1] y: 0 P: (14)  0.0 V: ( 4,   2)  0.0  | [0] y: 0 P: (15)  0.0 V: (14,   0)  1.0 \n",
      "[2] y: 0 P: (15)  0.0 V: (17,   2)  0.0  | [0] y: 1 P: ( 3)  1.0 V: (17,   1)  1.0 \n",
      "[3] y: 0 P: (13)  0.0 V: ( 2,   1)  0.0  | [0] y: 0 P: (19)  1.0 V: (13,   1)  0.0 \n",
      "[4] y: 0 P: ( 0)  1.0 V: (12,   1)  0.0  | [0] y: 1 P: ( 9)  0.0 V: (19,   0)  0.0 \n",
      "[0] y: 1 P: ( 0)  0.0 V: (12,   0)  0.0  | [0] y: 0 P: ( 0)  0.0 V: (18,   2)  0.0 \n",
      "[0] y: 0 P: (14)  0.0 V: (16,   0)  1.0  | [1] y: 0 P: (15)  0.0 V: (16,   2)  0.0 \n",
      "[0] y: 0 P: ( 6)  0.0 V: ( 2,   2)  0.0  | [2] y: 0 P: ( 5)  1.0 V: (13,   1)  0.0 \n",
      "[1] y: 0 P: (16)  0.0 V: ( 3,   1)  0.0  | [0] y: 1 P: ( 5)  1.0 V: ( 3,   1)  1.0 \n",
      "[2] y: 0 P: (21)  1.0 V: ( 4,   1)  0.0  | [0] y: 0 P: (21)  0.0 V: ( 8,   2)  0.0 \n",
      "[0] y: 0 P: (14)  0.0 V: (14,   2)  0.0  | [1] y: 0 P: ( 4)  0.0 V: (13,   0)  0.0 \n",
      "[1] y: 0 P: ( 9)  0.0 V: (20,   1)  0.0  | [2] y: 0 P: ( 5)  0.0 V: ( 0,   2)  0.0 \n",
      "[2] y: 0 P: ( 4)  1.0 V: ( 8,   1)  0.0  | [3] y: 0 P: ( 0)  0.0 V: (19,   2)  0.0 \n",
      "[0] y: 1 P: (12)  1.0 V: ( 6,   1)  1.0  | [4] y: 0 P: ( 3)  0.0 V: (20,   0)  1.0 \n",
      "[0] y: 0 P: ( 6)  0.0 V: ( 8,   2)  0.0  | [0] y: 1 P: (10)  0.0 V: ( 6,   2)  0.0 \n",
      "[1] y: 0 P: ( 9)  0.0 V: ( 6,   0)  0.0  | [1] y: 1 P: ( 1)  0.0 V: (19,   0)  0.0 \n",
      "[2] y: 0 P: ( 2)  0.0 V: (13,   0)  1.0  | [2] y: 1 P: ( 1)  0.0 V: ( 9,   0)  0.0 \n",
      "[0] y: 0 P: (18)  0.0 V: (10,   0)  1.0  | [0] y: 0 P: ( 4)  1.0 V: (10,   1)  0.0 \n",
      "[0] y: 0 P: (18)  0.0 V: (21,   0)  1.0  | [0] y: 1 P: ( 6)  0.0 V: (21,   2)  0.0 \n",
      "[0] y: 0 P: ( 9)  0.0 V: ( 3,   2)  0.0  | [1] y: 1 P: (16)  0.0 V: ( 0,   2)  0.0 \n",
      "[1] y: 0 P: (11)  0.0 V: ( 7,   2)  0.0  | [2] y: 1 P: (20)  0.0 V: ( 3,   2)  0.0 \n",
      "[2] y: 0 P: ( 2)  1.0 V: ( 3,   1)  0.0  | [3] y: 1 P: (20)  0.0 V: (17,   1)  0.0 \n",
      "[0] y: 1 P: (14)  0.0 V: ( 4,   0)  0.0  | [4] y: 1 P: (16)  1.0 V: ( 8,   1)  1.0 \n",
      "[0] y: 0 P: ( 4)  1.0 V: (17,   1)  0.0  | [0] y: 0 P: ( 8)  0.0 V: (16,   2)  0.0 \n",
      "[0] y: 1 P: ( 0)  0.0 V: (11,   2)  0.0  | [1] y: 0 P: (11)  0.0 V: ( 7,   1)  0.0 \n",
      "[1] y: 1 P: ( 2)  0.0 V: ( 3,   0)  0.0  | [2] y: 0 P: (19)  0.0 V: (20,   0)  1.0 \n",
      "[2] y: 1 P: ( 8)  1.0 V: (19,   1)  1.0  | [0] y: 0 P: (16)  1.0 V: (16,   1)  0.0 \n",
      "[0] y: 1 P: ( 6)  1.0 V: (12,   1)  1.0  | [0] y: 1 P: (21)  0.0 V: (18,   2)  0.0 \n"
     ]
    }
   ],
   "source": [
    "def printer(env, tensordict):\n",
    "    to_print = []\n",
    "    for i in range(2):\n",
    "        to_print.append(\n",
    "            f\"[{tensordict['round'][i].item()}] \"\n",
    "            f\"y: {tensordict['y'][i].item()} \"\n",
    "            f\"P: ({tensordict['agents', 'node_selected'][i, 1].item():>2}) \"\n",
    "            f\" {tensordict['next', 'agents', 'reward'][i, 1].item():>2} \"\n",
    "            f\"V: ({tensordict['agents', 'node_selected'][i, 0].item():>2}, \"\n",
    "            f\" {tensordict['agents', 'decision'][i, 0].item():>2}) \"\n",
    "            f\" {tensordict['next', 'agents', 'reward'][i, 0].item():>2} \"\n",
    "        )\n",
    "    print(\" | \".join(to_print))\n",
    "    # print(tensordict[\"message\"][:2, ..., :3].transpose(-1, -2))\n",
    "    # print(tensordict[\"message\"][:2, ..., :3])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = env.rollout(\n",
    "        max_steps=40,\n",
    "        callback=printer,\n",
    "        auto_cast_to_device=True,\n",
    "        break_when_any_done=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        adjacency: Tensor(shape=torch.Size([64, 40, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                decision: Tensor(shape=torch.Size([64, 40, 2]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                node_selected: Tensor(shape=torch.Size([64, 40, 2]), device=cpu, dtype=torch.int32, is_shared=False)},\n",
       "            batch_size=torch.Size([64, 40]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([64, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        message: Tensor(shape=torch.Size([64, 40]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                adjacency: Tensor(shape=torch.Size([64, 40, 2, 11, 11]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        reward: Tensor(shape=torch.Size([64, 40, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                    batch_size=torch.Size([64, 40]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([64, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                message: Tensor(shape=torch.Size([64, 40]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                node_mask: Tensor(shape=torch.Size([64, 40, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                round: Tensor(shape=torch.Size([64, 40]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([64, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                x: Tensor(shape=torch.Size([64, 40, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([64, 40]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        node_mask: Tensor(shape=torch.Size([64, 40, 2, 11]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        round: Tensor(shape=torch.Size([64, 40]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([64, 40]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        x: Tensor(shape=torch.Size([64, 40, 2, 11, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        y: Tensor(shape=torch.Size([64, 40, 1]), device=cpu, dtype=torch.int32, is_shared=False)},\n",
       "    batch_size=torch.Size([64, 40]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy and critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedBody(TensorDictModuleBase):\n",
    "    in_keys = (\"round\", \"x\", \"adjacency\", \"message\")\n",
    "    out_keys = (\"round\", \"node_level_repr\", \"graph_level_repr\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_body: GraphIsomorphismAgentBody,\n",
    "        verifier_body: GraphIsomorphismAgentBody,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.prover_body = prover_body\n",
    "        self.verifier_body = verifier_body\n",
    "\n",
    "    def forward(self, tensordict: TensorDictBase) -> TensorDict:\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "\n",
    "        # Compute the index of the agent whose turn it is\n",
    "        prover_turn: Int[Tensor, \"batch\"] = round % 2 == 0\n",
    "\n",
    "        batch_size = tensordict.batch_size[0]\n",
    "\n",
    "        # Build tensordicts to feed to each agent when it's their turn\n",
    "        input_prover_dict = {}\n",
    "        input_verifier_dict = {}\n",
    "        for key in self.prover_body.in_keys:\n",
    "            if key == \"ignore_message\":\n",
    "                input_prover_dict[key] = torch.zeros(\n",
    "                    prover_turn.sum().item(), device=tensordict.device, dtype=torch.bool\n",
    "                )\n",
    "                input_verifier_dict[key] = round[~prover_turn] == 0\n",
    "            else:\n",
    "                input_prover_dict[key] = tensordict[key][prover_turn]\n",
    "                input_verifier_dict[key] = tensordict[key][~prover_turn]\n",
    "        input_prover = TensorDict(\n",
    "            input_prover_dict,\n",
    "            batch_size=(prover_turn.sum().item()),\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            input_verifier_dict,\n",
    "            batch_size=((~prover_turn).sum().item()),\n",
    "        )\n",
    "\n",
    "        # Run the prover and verifier on the inputs to get the hidden representations\n",
    "        out_prover = self.prover_body(input_prover)\n",
    "        out_verifier = self.verifier_body(input_verifier)\n",
    "\n",
    "        # Combine the representations of the two agents\n",
    "        node_level_repr = torch.zeros(\n",
    "            batch_size,\n",
    "            *out_prover[\"node_level_repr\"].shape[1:],\n",
    "            dtype=out_prover[\"node_level_repr\"].dtype,\n",
    "            device=out_prover[\"node_level_repr\"].device,\n",
    "        )\n",
    "        node_level_repr[prover_turn] = out_prover[\"node_level_repr\"]\n",
    "        node_level_repr[~prover_turn] = out_verifier[\"node_level_repr\"]\n",
    "        graph_level_repr = torch.zeros(\n",
    "            batch_size,\n",
    "            *out_prover[\"graph_level_repr\"].shape[1:],\n",
    "            dtype=out_prover[\"graph_level_repr\"].dtype,\n",
    "            device=out_prover[\"graph_level_repr\"].device,\n",
    "        )\n",
    "        graph_level_repr[prover_turn] = out_prover[\"graph_level_repr\"]\n",
    "        graph_level_repr[~prover_turn] = out_verifier[\"graph_level_repr\"]\n",
    "\n",
    "        # Update the tensordict with the combined representations\n",
    "        tensordict.update(\n",
    "            dict(node_level_repr=node_level_repr, graph_level_repr=graph_level_repr)\n",
    "        )\n",
    "\n",
    "        return tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedPolicyHead(TensorDictModuleBase):\n",
    "    in_keys = (\"round\", \"node_level_repr\", \"graph_level_repr\")\n",
    "    out_keys = ((\"agents\", \"node_selected_logits\"), (\"agents\", \"decision_logits\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_policy_head: GraphIsomorphismAgentPolicyHead,\n",
    "        verifier_policy_head: GraphIsomorphismAgentPolicyHead,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prover_policy_head = prover_policy_head\n",
    "        self.verifier_policy_head = verifier_policy_head\n",
    "\n",
    "    def forward(self, tensordict: TensorDictBase) -> TensorDict:\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "        batch_size = round.shape[0]\n",
    "\n",
    "        # Compute the index of the agent whose turn it is\n",
    "        prover_turn: Int[Tensor, \"batch\"] = (round % 2 == 0)\n",
    "\n",
    "        # Build tensordicts to feed to each agent when it's their turn\n",
    "        input_prover = TensorDict(\n",
    "            {\n",
    "                key: tensordict[key][prover_turn]\n",
    "                for key in self.prover_policy_head.in_keys\n",
    "            },\n",
    "            batch_size=(prover_turn.sum().item()),\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            {\n",
    "                key: tensordict[key][~prover_turn]\n",
    "                for key in self.verifier_policy_head.in_keys\n",
    "            },\n",
    "            batch_size=((~prover_turn).sum().item()),\n",
    "        )\n",
    "\n",
    "        # Run the policy heads to obtain the probability distributions\n",
    "        out_prover = self.prover_policy_head(input_prover)\n",
    "        out_verifier = self.verifier_policy_head(input_verifier)\n",
    "\n",
    "        # The combined action distribution logits of the two agents, which defaults to\n",
    "        # zeros\n",
    "        node_selected_logits = torch.zeros(\n",
    "            batch_size,\n",
    "            2,\n",
    "            *out_prover[\"node_selected\"].shape[1:],\n",
    "            dtype=out_prover.dtype,\n",
    "            device=out_prover.device,\n",
    "        )\n",
    "        decision_logits = torch.zeros(\n",
    "            batch_size,\n",
    "            2,\n",
    "            *out_verifier[\"decision\"].shape[1:],\n",
    "            dtype=out_prover.dtype,\n",
    "            device=out_prover.device,\n",
    "        )\n",
    "\n",
    "        # Inset the agents' action distributions into the combined action distribution\n",
    "        # logits\n",
    "        node_selected_logits[prover_turn, PROVER_AGENT_NUM] = out_prover[\n",
    "            \"node_selected_logits\"\n",
    "        ]\n",
    "        node_selected_logits[~prover_turn, VERIFIER_AGENT_NUM] = out_verifier[\n",
    "            \"node_selected_logits\"\n",
    "        ]\n",
    "        decision_logits[~prover_turn, VERIFIER_AGENT_NUM] = out_verifier[\n",
    "            \"decision_logits\"\n",
    "        ]\n",
    "\n",
    "        return TensorDict(\n",
    "            dict(\n",
    "                agents=TensorDict(\n",
    "                    dict(\n",
    "                        node_selected_logits=node_selected_logits,\n",
    "                        decision_logits=decision_logits,\n",
    "                    ),\n",
    "                    batch_size=tensordict.batch_size,\n",
    "                )\n",
    "            ),\n",
    "            batch_size=tensordict.batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphIsomorphismCombinedCriticHead(TensorDictModuleBase):\n",
    "    in_keys = (\"round\", \"node_level_repr\", \"graph_level_repr\")\n",
    "    out_keys = ((\"agents\", \"value\"), )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prover_critic_head: GraphIsomorphismAgentCriticHead,\n",
    "        verifier_critic_head: GraphIsomorphismAgentCriticHead,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prover_critic_head = prover_critic_head\n",
    "        self.verifier_critic_head = verifier_critic_head\n",
    "\n",
    "    def forward(self, tensordict: TensorDictBase) -> TensorDict:\n",
    "        round: Int[Tensor, \"batch\"] = tensordict[\"round\"]\n",
    "        batch_size = round.shape[0]\n",
    "\n",
    "        # Compute the index of the agent whose turn it is\n",
    "        prover_turn: Int[Tensor, \"batch\"] = (round % 2 == 1)\n",
    "\n",
    "        # Build tensordicts to feed to each agent when it's their turn\n",
    "        input_prover = TensorDict(\n",
    "            {\n",
    "                key: tensordict[key][prover_turn]\n",
    "                for key in self.prover_critic_head.in_keys\n",
    "            },\n",
    "            batch_size=(prover_turn.sum().item()),\n",
    "        )\n",
    "        input_verifier = TensorDict(\n",
    "            {\n",
    "                key: tensordict[key][~prover_turn]\n",
    "                for key in self.verifier_critic_head.in_keys\n",
    "            },\n",
    "            batch_size=((~prover_turn).sum().item()),\n",
    "        )\n",
    "\n",
    "        # Run the critic heads to obtain the probability distributions\n",
    "        out_prover = self.prover_critic_head(input_prover)\n",
    "        out_verifier = self.verifier_critic_head(input_verifier)\n",
    "\n",
    "        # # If we don't have a cached value, or if the batch size is different, initialise\n",
    "        # # a new one with zeros.\n",
    "        # if self.value_cache is None or self.value_cache.shape[0] != batch_size:\n",
    "        #     self.value_cache = torch.zeros(\n",
    "        #         batch_size,\n",
    "        #         2,\n",
    "        #         dtype=out_prover.dtype,\n",
    "        #         device=out_prover.device,\n",
    "        #     )\n",
    "\n",
    "        value = torch.zeros(\n",
    "            batch_size,\n",
    "            2,\n",
    "            dtype=out_prover.dtype,\n",
    "            device=out_prover.device,\n",
    "        )\n",
    "\n",
    "        # Inset the agents' values when it's their turn\n",
    "        value[prover_turn, PROVER_AGENT_NUM] = out_prover[\"value\"]\n",
    "        value[~prover_turn, VERIFIER_AGENT_NUM] = out_verifier[\"value\"]\n",
    "\n",
    "        return TensorDict(\n",
    "            dict(\n",
    "                agents=TensorDict(\n",
    "                    dict(value=value),\n",
    "                    batch_size=tensordict.batch_size,\n",
    "                )\n",
    "            ),\n",
    "            batch_size=tensordict.batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeCategoricalDistribution(CompositeDistribution):\n",
    "    def __init__(self, **categorical_params):\n",
    "        # Collect all the categorical keyword parameters\n",
    "        composite_params = {}\n",
    "        cat_param_kwargs_names = (\"logits\", \"probs\")\n",
    "        for name, param in categorical_params.items():\n",
    "            for kwarg_name in cat_param_kwargs_names:\n",
    "                if name.endswith(\"_\" + kwarg_name):\n",
    "                    composite_params[name[: -len(kwarg_name) - 1]] = {kwarg_name: param}\n",
    "\n",
    "        super().__init__(\n",
    "            params=composite_params,\n",
    "            distribution_map={key: Categorical for key in composite_params},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prover_body = GraphIsomorphismAgentBody(params, \"prover\", device=device)\n",
    "verifier_body = GraphIsomorphismAgentBody(params, \"verifier\", device=device)\n",
    "prover_policy_head = GraphIsomorphismAgentPolicyHead(params, \"prover\", device=device)\n",
    "verifier_policy_head = GraphIsomorphismAgentPolicyHead(\n",
    "    params, \"verifier\", device=device\n",
    ")\n",
    "prover_critic_head = GraphIsomorphismAgentCriticHead(params, \"prover\", device=device)\n",
    "verifier_critic_head = GraphIsomorphismAgentCriticHead(\n",
    "    params, \"verifier\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = GraphIsomorphismCombinedBody(prover_body, verifier_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_head = ProbabilisticActor(\n",
    "    module=GraphIsomorphismCombinedPolicyHead(prover_policy_head, verifier_policy_head),\n",
    "    spec=env.action_spec,\n",
    "    distribution_class=CompositeDistribution,\n",
    "    in_keys=dict(\n",
    "        node_selected_logits=(\"agents\", \"node_selected_logits\"),\n",
    "        decision_logits=(\"agents\", \"decision_logits\"),\n",
    "    ),\n",
    "    out_keys=env.action_keys,\n",
    "    default_interaction_type=InteractionType.RANDOM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_head = GraphIsomorphismCombinedCriticHead(\n",
    "    prover_critic_head, verifier_critic_head\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = ActorCriticOperator(body, policy_head, critic_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:562: UserWarning: You are passing a tensordict/tensorclass instance to a module that does not inherit from TensorDictModuleBase. This may lead to unexpected behaviours with functional calls.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [0, 4, -1, 24] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_policy_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:588\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    590\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/common.py:282\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/_contextlib.py:126\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/utils.py:254\u001b[0m, in \u001b[0;36mset_skip_existing.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    249\u001b[0m     skip_existing()\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m out_keys)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m out_keys \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m in_keys)\n\u001b[1;32m    252\u001b[0m ):\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensordict\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/probabilistic.py:549\u001b[0m, in \u001b[0;36mProbabilisticTensorDictSequential.forward\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m(auto_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    542\u001b[0m \u001b[38;5;129m@set_skip_existing\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    548\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorDictBase:\n\u001b[0;32m--> 549\u001b[0m     tensordict_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dist_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](tensordict_out, _requires_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_sample)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/probabilistic.py:515\u001b[0m, in \u001b[0;36mProbabilisticTensorDictSequential.get_dist_params\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdefault_interaction_type\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_interaction_type(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:588\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    590\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/common.py:282\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/_contextlib.py:126\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/utils.py:254\u001b[0m, in \u001b[0;36mset_skip_existing.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    249\u001b[0m     skip_existing()\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m out_keys)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m out_keys \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m in_keys)\n\u001b[1;32m    252\u001b[0m ):\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensordict\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/sequence.py:426\u001b[0m, in \u001b[0;36mTensorDictSequential.forward\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs):\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule:\n\u001b[0;32m--> 426\u001b[0m         tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorDictSequential does not support keyword arguments other than \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensordict_out\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or in_keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/sequence.py:407\u001b[0m, in \u001b[0;36mTensorDictSequential._run_module\u001b[0;34m(self, module, tensordict, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_module\u001b[39m(\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    400\u001b[0m     module: TensorDictModule,\n\u001b[1;32m    401\u001b[0m     tensordict: TensorDictBase,\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    403\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    405\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(include_nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39min_keys\n\u001b[1;32m    406\u001b[0m     ):\n\u001b[0;32m--> 407\u001b[0m         tensordict \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sub_td \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mtensordicts:\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:588\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    590\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[15], line 45\u001b[0m, in \u001b[0;36mGraphIsomorphismCombinedBody.forward\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Run the prover and verifier on the inputs to get the hidden representations\u001b[39;00m\n\u001b[1;32m     44\u001b[0m out_prover \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprover_body(input_prover)\n\u001b[0;32m---> 45\u001b[0m out_verifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverifier_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_verifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Combine the representations of the two agents\u001b[39;00m\n\u001b[1;32m     48\u001b[0m node_level_repr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m     49\u001b[0m     batch_size,\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;241m*\u001b[39mout_prover[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_level_repr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m     51\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mout_prover[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_level_repr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m     52\u001b[0m     device\u001b[38;5;241m=\u001b[39mout_prover[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_level_repr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:588\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    590\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Code/Projects/PVG Experiments/pvg/graph_isomorphism/agents.py:390\u001b[0m, in \u001b[0;36mGraphIsomorphismAgentBody.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    386\u001b[0m src_mask[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m max_num_nodes :, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m max_num_nodes :] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Compute the transformer output\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# (batch, 2 + 2 * max_nodes, d_transformer)\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m transformer_output_flatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# Extract the graph-level representations and rearrange the rest to have two\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# batch dims\u001b[39;00m\n\u001b[1;32m    399\u001b[0m graph_level_repr \u001b[38;5;241m=\u001b[39m transformer_output_flatter[:, :\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:588\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    590\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:588\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    590\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/transformer.py:707\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/tensordict/nn/functional_modules.py:588\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    590\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.virtualenvs/pvg-experiments/lib/python3.11/site-packages/torch/nn/functional.py:5434\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5432\u001b[0m         attn_mask \u001b[38;5;241m=\u001b[39m attn_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   5433\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5434\u001b[0m         attn_mask \u001b[38;5;241m=\u001b[39m \u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbsz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5436\u001b[0m q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, tgt_len, head_dim)\n\u001b[1;32m   5437\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [0, 4, -1, 24] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "full_model.get_policy_operator()(env.reset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvg-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
