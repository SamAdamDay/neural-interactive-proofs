{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPS Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "# This seems to do something weirdly inefficient\n",
    "# datasets = {x: load_dataset(\"codeparrot/apps\", trust_remote_code=True, split=\"test\", difficulties=[x]) for x in [\"introductory\", \"interview\", \"competition\"]}\n",
    "\n",
    "def get_dataset(difficulty):\n",
    "    return load_dataset(\"codeparrot/apps\", trust_remote_code=True, split=\"test\", difficulties=[difficulty])\n",
    "\n",
    "metric = load('codeparrot/apps_metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "OPENROUTER_API_KEY = \"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\"\n",
    "\n",
    "MODELS = [\"openai/gpt-4o-mini\",\n",
    "          \"meta-llama/llama-3.1-8b-instruct\", \n",
    "          \"deepseek/deepseek-coder\",\n",
    "          \"mistralai/codestral-mamba\"]\n",
    "\n",
    "def get_responses(model, messages):\n",
    "    \"\"\"\n",
    "    Sends a POST request to the OpenRouter API to get responses from a chat model.\n",
    "\n",
    "    Parameters:\n",
    "    - model (str): The name of the chat model to use.\n",
    "    - messages (list): A list of dictionaries representing the chat messages. Each dictionary should have a \"role\" key with the value \"user\" or \"assistant\", and a \"content\" key with the content of the message.\n",
    "\n",
    "    Returns:\n",
    "    - response (Response): The response object returned by the API.\n",
    "\n",
    "    Raises:\n",
    "    - requests.exceptions.RequestException: If there was an error sending the request.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(\n",
    "    url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "    headers={ \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\"},\n",
    "    data=json.dumps({\"model\": model, \"messages\": messages}))\n",
    "\n",
    "    return response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers(answers, model, difficulty):\n",
    "    \n",
    "    model_name = model.split('/')[-1]\n",
    "    file_path = f\"apps/generations/{model_name}_{difficulty}.json\"\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(answers, f, indent=4)\n",
    "\n",
    "def save_results(results):\n",
    "    \n",
    "    with open(\"apps/results.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"Answer the following question by providing Python code. Do NOT include any explanation or natural language text, ONLY the code. Your code should be concise and should not include any comments.\\n\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, attempts):\n",
    "\n",
    "    answers = {}\n",
    "\n",
    "    for j in range(len(data)):\n",
    "\n",
    "        problem_id = data[j]['problem_id']\n",
    "        answers[problem_id] = []\n",
    "\n",
    "        for _ in range(attempts):\n",
    "\n",
    "            messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": data[j]['question']}]\n",
    "            response = get_responses(model, messages)\n",
    "            answers[problem_id].append(response)\n",
    "\n",
    "    return answers\n",
    "\n",
    "def run(models, difficulties, attempts=1):\n",
    "\n",
    "    results = {}\n",
    "    for d in difficulties:\n",
    "        data = get_dataset(d)\n",
    "        for m in models:\n",
    "            answers = evaluate(m, data, attempts)\n",
    "            save_answers(answers, m, d)\n",
    "            results[m][d] = metric.compute(predictions=answers, level=d)\n",
    "\n",
    "    save_results(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ QUESTION ================\n",
      "An accordion is a string (yes, in the real world accordions are musical instruments, but let's forget about it for a while) which can be represented as a concatenation of: an opening bracket (ASCII code $091$), a colon (ASCII code $058$), some (possibly zero) vertical line characters (ASCII code $124$), another colon, and a closing bracket (ASCII code $093$). The length of the accordion is the number of characters in it.\n",
      "\n",
      "For example, [::], [:||:] and [:|||:] are accordions having length $4$, $6$ and $7$. (:|:), {:||:}, [:], ]:||:[ are not accordions. \n",
      "\n",
      "You are given a string $s$. You want to transform it into an accordion by removing some (possibly zero) characters from it. Note that you may not insert new characters or reorder existing ones. Is it possible to obtain an accordion by removing characters from $s$, and if so, what is the maximum possible length of the result?\n",
      "\n",
      "\n",
      "-----Input-----\n",
      "\n",
      "The only line contains one string $s$ ($1 \\le |s| \\le 500000$). It consists of lowercase Latin letters and characters [, ], : and |.\n",
      "\n",
      "\n",
      "-----Output-----\n",
      "\n",
      "If it is not possible to obtain an accordion by removing some characters from $s$, print $-1$. Otherwise print maximum possible length of the resulting accordion.\n",
      "\n",
      "\n",
      "-----Examples-----\n",
      "Input\n",
      "|[a:b:|]\n",
      "\n",
      "Output\n",
      "4\n",
      "\n",
      "Input\n",
      "|]:[|:]\n",
      "\n",
      "Output\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(\"================ QUESTION ================\")\n",
    "all_data = get_dataset(\"introductory\")\n",
    "data = all_data[0]\n",
    "print(data[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ ANSWER ================\n",
      "```python\n",
      "s = input()\n",
      "l, r = -1, -1\n",
      "for i in range(len(s)):\n",
      "    if s[i] == '[':\n",
      "        l = i\n",
      "    if s[i] == ']':\n",
      "        r = i\n",
      "if l == -1 or r == -1 or l > r:\n",
      "    print(-1)\n",
      "else:\n",
      "    colons = s[l:r].count(':')\n",
      "    if colons < 2:\n",
      "        print(-1)\n",
      "    else:\n",
      "        vertical_lines = s[l:r].count('|')\n",
      "        print(4 + vertical_lines)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "model = \"openai/gpt-4o-mini\"\n",
    "print(\"================ ANSWER ================\")\n",
    "answers = evaluate(model, [data], 1)\n",
    "print(answers[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = input()\n",
      "l, r = -1, -1\n",
      "for i in range(len(s)):\n",
      "    if s[i] == '[':\n",
      "        l = i\n",
      "    if s[i] == ']':\n",
      "        r = i\n",
      "if l == -1 or r == -1 or l > r:\n",
      "    print(-1)\n",
      "else:\n",
      "    colons = s[l:r].count(':')\n",
      "    if colons < 2:\n",
      "        print(-1)\n",
      "    else:\n",
      "        vertical_lines = s[l:r].count('|')\n",
      "        print(4 + vertical_lines)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = answers[0][0][10:-3]\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ RESULTS ================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m================ RESULTS ================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43manswers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintroductory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/evaluate/module.py:467\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {input_name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed):\n\u001b[0;32m--> 467\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/codeparrot--apps_metric/309860cfcc955c009fe597c9a7f874cec1c45bd996149294d439587703e4d595/apps_metric.py:81\u001b[0m, in \u001b[0;36mapps_metric._compute\u001b[0;34m(self, predictions, k_list, count_errors, level, debug)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute\u001b[39m(\u001b[38;5;28mself\u001b[39m, predictions, k_list\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m], count_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the scores\"\"\"\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/codeparrot--apps_metric/309860cfcc955c009fe597c9a7f874cec1c45bd996149294d439587703e4d595/utils.py:207\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(generations, level, k_list, count_errors, debug)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(generations, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, k_list\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m], count_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return metrics for the given generations.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m        generations: list of code generations for each problem (each generation is a list of generations)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    {'avg_accuracy': None, 'strict_accuracy': None, 'pass_at_k': {'pass@1': 1.0, 'pass@2': 1.0, 'pass@3': 1.0}}\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_generations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m get_results(results, count_errors\u001b[38;5;241m=\u001b[39mcount_errors, k_list\u001b[38;5;241m=\u001b[39mk_list)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/codeparrot--apps_metric/309860cfcc955c009fe597c9a7f874cec1c45bd996149294d439587703e4d595/utils.py:61\u001b[0m, in \u001b[0;36mevaluate_generations\u001b[0;34m(generations, level, debug)\u001b[0m\n\u001b[1;32m     59\u001b[0m curr_res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     curr_res \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_correctness\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTIMEOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSuccessful compilation of task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/codeparrot--apps_metric/309860cfcc955c009fe597c9a7f874cec1c45bd996149294d439587703e4d595/utils.py:19\u001b[0m, in \u001b[0;36mcheck_correctness\u001b[0;34m(sample, generation, timeout, debug)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_temp_run\u001b[39m(sample, generation, debug, result):\n\u001b[1;32m     17\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(run_test(sample, test\u001b[38;5;241m=\u001b[39mgeneration, debug\u001b[38;5;241m=\u001b[39mdebug))\n\u001b[0;32m---> 19\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m result \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mlist()\n\u001b[1;32m     21\u001b[0m p \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mProcess(target\u001b[38;5;241m=\u001b[39m_temp_run, args\u001b[38;5;241m=\u001b[39m(sample, generation, debug, result))\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/context.py:57\u001b[0m, in \u001b[0;36mBaseContext.Manager\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanagers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SyncManager\n\u001b[1;32m     56\u001b[0m m \u001b[38;5;241m=\u001b[39m SyncManager(ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_context())\n\u001b[0;32m---> 57\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/managers.py:566\u001b[0m, in \u001b[0;36mBaseManager.start\u001b[0;34m(self, initializer, initargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# get address of server\u001b[39;00m\n\u001b[1;32m    565\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_address \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m reader\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# register a finalizer\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"================ RESULTS ================\")\n",
    "results = metric.compute(predictions=[[answers[0][0][10:-3]]], level=\"introductory\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
